{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos Customizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# loading fashion mnist\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data normalization\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000].copy(), y_train_full[5000:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_classes = ['T-shirt/top', 'Trouser/pants', 'Pullover shirt', 'Dress', \n",
    "                 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_d = tf.constant(pd.get_dummies(y_valid).values, tf.float32)\n",
    "y_train_d = tf.constant(pd.get_dummies(y_train).values, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1, shape=(55000, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input = keras.layers.Input(shape=[28, 28])\n",
    "\n",
    "h0    = keras.layers.Flatten()(X_input)\n",
    "h1    = keras.layers.Dense(300, activation=\"relu\")(h0)\n",
    "h2    = keras.layers.Dense(200, activation=\"relu\")(h1)\n",
    "h3    = keras.layers.Dense(100, activation=\"relu\")(h2)\n",
    "h4    = keras.layers.Dense( 50, activation=\"relu\")(h3)\n",
    "yhat  = keras.layers.Dense( 10, activation=\"sigmoid\")(h4)\n",
    "model = keras.models.Model(inputs=[X_input], outputs=[yhat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções de perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qd usa batch norm, essa loss n funciona bem, pelo menos, nas 1as poucas epocas\n",
    "def cosine_loss(v1, v2):\n",
    "    # y_true, y_pred\n",
    "    norm_v1 = tf.nn.l2_normalize(v1, 1)        \n",
    "    norm_v2 = tf.nn.l2_normalize(v2, 1)\n",
    "    return 1 - tf.matmul(norm_v1, norm_v2, transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss = cosine_loss, optimizer = sgd, metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0923 12:53:29.738394 4619273664 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0923 12:53:30.013667 4619273664 deprecation.py:323] From /Users/marcocristo/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1393: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0923 12:53:30.059385 4619273664 deprecation.py:323] From /Users/marcocristo/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:468: BaseResourceVariable.constraint (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Apply a constraint manually following the optimizer update step.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 7s 125us/sample - loss: 0.6838 - accuracy: 0.3071 - val_loss: 0.6838 - val_accuracy: 0.3940\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 6s 110us/sample - loss: 0.6835 - accuracy: 0.5658 - val_loss: 0.6836 - val_accuracy: 0.6090\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 6s 111us/sample - loss: 0.6833 - accuracy: 0.6143 - val_loss: 0.6835 - val_accuracy: 0.6140\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 7s 121us/sample - loss: 0.6833 - accuracy: 0.6609 - val_loss: 0.6832 - val_accuracy: 0.6812\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 7s 118us/sample - loss: 0.6832 - accuracy: 0.6853 - val_loss: 0.6831 - val_accuracy: 0.7098\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.6832 - accuracy: 0.7114 - val_loss: 0.6832 - val_accuracy: 0.7618\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 6s 115us/sample - loss: 0.6832 - accuracy: 0.7404 - val_loss: 0.6831 - val_accuracy: 0.7460\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 7s 124us/sample - loss: 0.6831 - accuracy: 0.7428 - val_loss: 0.6831 - val_accuracy: 0.7502\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 7s 121us/sample - loss: 0.6831 - accuracy: 0.7577 - val_loss: 0.6832 - val_accuracy: 0.7698\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 7s 123us/sample - loss: 0.6831 - accuracy: 0.7563 - val_loss: 0.6834 - val_accuracy: 0.7370\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(X_train, y_train_d, epochs = 10, shuffle = True,\n",
    "             validation_data = (X_valid, y_valid_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salvando função de perda customizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_cosine_loss.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Na hora de ler, voce precisa forncecer um dicionario custom_objects com a funcao de perda\n",
    "model = keras.models.load_model(\"model_cosine_loss.h5\", \n",
    "                                custom_objects = {\"cosine_loss\": cosine_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções de perda com parâmetro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gere_cosine_loss(classw = tf.constant(1, shape = (10,), dtype = tf.float32)):\n",
    "    def cosine_loss(v1, v2):\n",
    "        # y_true, y_pred\n",
    "        v2 = classw * v2\n",
    "        norm_v1 = tf.nn.l2_normalize(v1, 1)        \n",
    "        norm_v2 = tf.nn.l2_normalize(v2, 1)\n",
    "        return 1 - tf.matmul(norm_v1, norm_v2, transpose_b=True)\n",
    "    return cosine_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = gere_cosine_loss(), optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0923 12:54:35.504133 4619273664 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 8s 140us/sample - loss: 0.6834 - accuracy: 0.5756 - val_loss: 0.6833 - val_accuracy: 0.7272\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 7s 136us/sample - loss: 0.6831 - accuracy: 0.7064 - val_loss: 0.6832 - val_accuracy: 0.7338\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 7s 126us/sample - loss: 0.6831 - accuracy: 0.7297 - val_loss: 0.6830 - val_accuracy: 0.7742\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 7s 130us/sample - loss: 0.6830 - accuracy: 0.7409 - val_loss: 0.6830 - val_accuracy: 0.7780\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 7s 130us/sample - loss: 0.6830 - accuracy: 0.7605 - val_loss: 0.6830 - val_accuracy: 0.7948\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 7s 126us/sample - loss: 0.6830 - accuracy: 0.7695 - val_loss: 0.6829 - val_accuracy: 0.7860\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 7s 129us/sample - loss: 0.6830 - accuracy: 0.7894 - val_loss: 0.6830 - val_accuracy: 0.7974\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 7s 127us/sample - loss: 0.6830 - accuracy: 0.7881 - val_loss: 0.6830 - val_accuracy: 0.8100\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 7s 132us/sample - loss: 0.6829 - accuracy: 0.7966 - val_loss: 0.6830 - val_accuracy: 0.8082\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 7s 134us/sample - loss: 0.6829 - accuracy: 0.7950 - val_loss: 0.6831 - val_accuracy: 0.8186\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(X_train, y_train_d, epochs = 10, \n",
    "             validation_data = (X_valid, y_valid_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_cosine_loss.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Na hora de ler, voce precisa forncecer um dicionario custom_objects com a funcao de perda\n",
    "model = keras.models.load_model(\"model_cosine_loss.h5\", \n",
    "                                custom_objects = {\"cosine_loss\": gere_cosine_loss()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que a função salva foi a usada no modelo mas não a configurável! Logo, o parâmetro não foi salvo. Para contornar isso, é melhor usar uma classe:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salvando função de perda customizada definida usando classe Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineLoss(keras.losses.Loss):\n",
    "    \n",
    "    def __init__(self, classw = np.ones((10,)), **kwargs):\n",
    "        self.classw = classw\n",
    "        super().__init__(**kwargs) \n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        # fazer a conversao aki eh pessima ideia, mas necessario na versao beta do tf2/keras2\n",
    "        # que ainda nao eh capaz de salvar parametros que sejam tensores\n",
    "        v2 = K.constant(self.classw, dtype = tf.float32) * y_pred\n",
    "        norm_v1 = tf.nn.l2_normalize(y_true, 1)        \n",
    "        norm_v2 = tf.nn.l2_normalize(v2, 1)\n",
    "        return 1 - tf.matmul(norm_v1, norm_v2, transpose_b=True) \n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"classw\": self.classw}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Model(inputs=[X_input], outputs=[yhat])\n",
    "\n",
    "model.compile(loss = CosineLoss(), optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0923 13:18:20.133491 4619273664 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000/55000 [==============================] - 7s 136us/sample - loss: 0.6828 - accuracy: 0.8182 - val_loss: 0.6831 - val_accuracy: 0.8080\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(X_train, y_train_d, epochs = 1, \n",
    "             validation_data = (X_valid, y_valid_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_cosine_loss_class.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown loss function: CosineLoss",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-0a7189e848c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# para ler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model = keras.models.load_model(\"model_cosine_loss_class.h5\",\n\u001b[0;32m----> 3\u001b[0;31m                                 custom_objects = {\"CosineLoss\": CosineLoss})\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    141\u001b[0m   if (h5py is not None and (\n\u001b[1;32m    142\u001b[0m       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;31m# Compile model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       model.compile(**saving_utils.compile_args_from_training_config(\n\u001b[0;32m--> 178\u001b[0;31m           training_config, custom_objects))\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0;31m# Set optimizer weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36mcompile_args_from_training_config\u001b[0;34m(training_config, custom_objects)\u001b[0m\n\u001b[1;32m    220\u001b[0m   \u001b[0mloss_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Deserialize loss class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'class_name'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0mloss_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m   loss = nest.map_structure(\n\u001b[1;32m    224\u001b[0m       lambda obj: custom_objects.get(obj, obj), loss_config)\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/losses.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/losses.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(name, custom_objects)\u001b[0m\n\u001b[1;32m   1155\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m       printable_module_name='loss function')\n\u001b[0m\u001b[1;32m   1158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     (cls, cls_config) = class_and_config_for_serialized_keras_object(\n\u001b[0;32m--> 180\u001b[0;31m         config, module_objects, custom_objects, printable_module_name)\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[0;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprintable_module_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown loss function: CosineLoss"
     ]
    }
   ],
   "source": [
    "# para ler\n",
    "model = keras.models.load_model(\"model_cosine_loss_class.h5\",\n",
    "                                custom_objects = {\"CosineLoss\": CosineLoss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camadas e Loss: um autocodificador variacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imagens/VAE-ammd2-2019.png\" alt=\"drawing\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Amostragem(keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_media, z_log_var = inputs\n",
    "        batch = tf.shape(z_media)[0]\n",
    "        dim = tf.shape(z_media)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_media + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Codificador(keras.models.Model):\n",
    "    def __init__(self, latent_dim=32, inter_dim=64,\n",
    "               name='codificador', **kwargs):\n",
    "        super(Codificador, self).__init__(name=name, **kwargs)\n",
    "        self.dense_proj = keras.layers.Dense(inter_dim, activation='relu')\n",
    "        self.dense_mean = keras.layers.Dense(latent_dim)\n",
    "        self.dense_log_var = keras.layers.Dense(latent_dim)\n",
    "        self.amostragem = Amostragem()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_proj(inputs)\n",
    "        z_media = self.dense_mean(x)\n",
    "        z_log_var = self.dense_log_var(x)\n",
    "        z = self.amostragem((z_media, z_log_var))\n",
    "        return z_media, z_log_var, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decodificador(keras.models.Model):\n",
    "    def __init__(self, original_dim, inter_dim=64,\n",
    "               name='decodificador', **kwargs):\n",
    "        super(Decodificador, self).__init__(name=name, **kwargs)\n",
    "        self.dense_proj = keras.layers.Dense(inter_dim, activation='relu')\n",
    "        self.dense_output = keras.layers.Dense(original_dim, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_proj(inputs)\n",
    "        return self.dense_output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutocodificadorVariacional(keras.Model):\n",
    "    \"\"\"Combines the encoder and decoder into an end-to-end model for training.\"\"\"\n",
    "\n",
    "    def __init__(self, original_dim, inter_dim=64,\n",
    "               latent_dim=32, name='autoencoder', **kwargs):\n",
    "        super(AutocodificadorVariacional, self).__init__(name=name, **kwargs)\n",
    "        self.original_dim = original_dim\n",
    "        self.codificador = Codificador(latent_dim=latent_dim, inter_dim=inter_dim)\n",
    "        self.decodificador = Decodificador(original_dim, inter_dim=inter_dim)\n",
    "        self.opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_media, z_log_var, z = self.codificador(inputs)\n",
    "        rec = self.decodificador(z)\n",
    "        # Add KL divergence regularization loss.\n",
    "        kl_loss = - 0.5 * tf.reduce_mean(z_log_var - tf.square(z_media) - tf.exp(z_log_var) + 1)\n",
    "        self.add_loss(kl_loss)\n",
    "        return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flat = X_train.reshape(-1, 784)\n",
    "X_valid_flat = X_valid.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = AutocodificadorVariacional(784, 64, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0925 14:02:09.559137 4619273664 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 0.0265 - val_loss: 0.0178\n",
      "Epoch 2/8\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.0163 - val_loss: 0.0151\n",
      "Epoch 3/8\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.0144 - val_loss: 0.0139\n",
      "Epoch 4/8\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 5/8\n",
      "55000/55000 [==============================] - 4s 69us/sample - loss: 0.0127 - val_loss: 0.0123\n",
      "Epoch 6/8\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.0122 - val_loss: 0.0120\n",
      "Epoch 7/8\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.0119 - val_loss: 0.0117\n",
      "Epoch 8/8\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.0116 - val_loss: 0.0114\n"
     ]
    }
   ],
   "source": [
    "h = vae.fit(X_train_flat, X_train_flat, \n",
    "           epochs = 8, shuffle=True,\n",
    "           validation_data = (X_valid_flat, X_valid_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutocodificadorVariacional(keras.Model):\n",
    "    \"\"\"Combines the encoder and decoder into an end-to-end model for training.\"\"\"\n",
    "\n",
    "    def __init__(self, original_dim, inter_dim=64,\n",
    "               latent_dim=32, name='autoencoder', **kwargs):\n",
    "        super(AutocodificadorVariacional, self).__init__(name=name, **kwargs)\n",
    "        self.original_dim = original_dim\n",
    "        self.codificador = Codificador(latent_dim=latent_dim, inter_dim=inter_dim)\n",
    "        self.decodificador = Decodificador(original_dim, inter_dim=inter_dim)\n",
    "        self.opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "        self.mse_loss = keras.losses.MeanSquaredError()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_media, z_log_var, z = self.codificador(inputs)\n",
    "        rec = self.decodificador(z)\n",
    "        # Add KL divergence regularization loss.\n",
    "        kl_loss = - 0.5 * tf.reduce_mean(z_log_var - tf.square(z_media) - tf.exp(z_log_var) + 1)\n",
    "        self.add_loss(kl_loss + self.mse_loss(inputs, rec))\n",
    "        return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = AutocodificadorVariacional(784, 64, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer='adam', loss = lambda y_true, y_pred: tf.constant(0, dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0923 12:43:15.622452 4634867136 training_utils.py:1211] When passing input data as arrays, do not specify `steps_per_epoch`/`steps` argument. Please use `batch_size` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "55000/55000 [==============================] - 6s 112us/sample - loss: 0.0898 - val_loss: 0.0883\n",
      "Epoch 2/8\n",
      "55000/55000 [==============================] - 4s 73us/sample - loss: 0.0874 - val_loss: 0.0881\n",
      "Epoch 3/8\n",
      "55000/55000 [==============================] - 4s 75us/sample - loss: 0.0873 - val_loss: 0.0879\n",
      "Epoch 4/8\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.0873 - val_loss: 0.0878\n",
      "Epoch 5/8\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.0872 - val_loss: 0.0878\n",
      "Epoch 6/8\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.0872 - val_loss: 0.0879\n",
      "Epoch 7/8\n",
      "55000/55000 [==============================] - 4s 77us/sample - loss: 0.0872 - val_loss: 0.0878\n",
      "Epoch 8/8\n",
      "55000/55000 [==============================] - 4s 73us/sample - loss: 0.0871 - val_loss: 0.0878\n"
     ]
    }
   ],
   "source": [
    "h = vae.fit(X_train_flat, X_train_flat, \n",
    "           epochs = 8, shuffle=True,\n",
    "           validation_data = (X_valid_flat, X_valid_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'autoencoder/add_1:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
