{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tqdm==4.28.1\n",
    "# !pip install -U gast==0.2.2\n",
    "# !pip install gdown\n",
    "\n",
    "# !gdown https://drive.google.com/uc?id=14CB3Vw4jPf-8-DAriB9XDq4mfbs4o747\n",
    "# !mkdir datasets\n",
    "# !tar -C datasets -xzf airport-alunos.tgz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "4.28.1\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf; print(tf.__version__)\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_sample_image;\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tqdm; print(tqdm.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "USM43pOIGCw2",
    "outputId": "0c9ddb6e-2d96-4ae8-a360-cdd3ccd5c200"
   },
   "outputs": [],
   "source": [
    "def scatter(x, labels, subtitle='None'):\n",
    "    # We choose a color palette with seaborn.\n",
    "    palette_size = len(np.unique(labels))\n",
    "    palette = np.array(sns.color_palette(\"hls\", palette_size))\n",
    "    \n",
    "    color_map = dict({})\n",
    "    color_count = 0\n",
    "    for l in labels:\n",
    "        if l not in color_map:\n",
    "            color_map[l] = color_count\n",
    "            color_count = color_count + 1\n",
    "    \n",
    "    def get_color_idx(label):\n",
    "        return color_map[label]\n",
    "        \n",
    "    def get_colores_idx(labels_):\n",
    "        return np.array([get_color_idx(l) for l in labels_])\n",
    "        \n",
    "    # We create a scatter plot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40,\n",
    "                    c=palette[get_colores_idx(labels)])\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "\n",
    "    # We add the labels for each digit.\n",
    "    txts = []\n",
    "    for l, i in zip(labels, range(len(labels))):\n",
    "        # Position of each label.\n",
    "        xtext, ytext = np.median(x[labels == l, :], axis=0)\n",
    "        txt = ax.text(xtext, ytext, labels[i], fontsize=16, \n",
    "                      color = palette[get_color_idx(l)]) #, bbox=dict(alpha=0.5))\n",
    "        txt.set_path_effects([\n",
    "            PathEffects.Stroke(linewidth=5, foreground=\"yellow\"),\n",
    "            PathEffects.Normal()])\n",
    "        txts.append(txt)\n",
    "        \n",
    "    if subtitle != None:\n",
    "        plt.suptitle(subtitle)\n",
    "        \n",
    "    plt.savefig(subtitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_model(input_shape):\n",
    "    input_layer = Input(shape = input_shape)\n",
    "    \n",
    "    model = Conv2D(8, (3, 3), activation = None, padding='same')(input_layer)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "    model = Conv2D(16, (3, 3), activation = None, padding='same')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "    model = Conv2D(32, (3, 3), activation = None, padding='same')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "    model = Conv2D(64, (3, 3), activation = None, padding='same')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "    model = Flatten()(model)\n",
    "    model = Dense(64, activation='relu')(model)\n",
    "    model = Lambda(lambda inp: K.l2_normalize(inp, axis=-1))(model)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=model)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_autoencoder(input_shape):\n",
    "    input_layer = Input(shape = input_shape)\n",
    "    \n",
    "    model = Dense(64, activation='relu')(input_layer)\n",
    "    model = Dense(32, activation='relu')(model)\n",
    "    model = Dense(16, activation='relu')(model)\n",
    "    model = Dense(32, activation='relu')(model)\n",
    "    model = Dense(64, activation='relu')(model)\n",
    "    model = Lambda(lambda inp: K.l2_normalize(inp, axis=-1))(model)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=model)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "class TripletLossLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(TripletLossLayer, self).__init__()\n",
    "    \n",
    "    def euclidean_distance(self, vects):\n",
    "        x, y = vects\n",
    "        x = tf.cast(x, 'float32')\n",
    "        y = tf.cast(y, 'float32')\n",
    "\n",
    "        return K.mean(K.sum(K.square(x-y),axis=1))\n",
    "    \n",
    "    def call(self, inputs=None):\n",
    "        #     Calcule triplet loss \n",
    "        #     loss = max(dist(a, p) - dist(a, n) + margin, 0)\n",
    "        self.margin = tf.constant(0.4 , dtype='float32')\n",
    "        a, p, n = inputs\n",
    "        a = tf.cast(a, 'float32')\n",
    "        p = tf.cast(p, 'float32')\n",
    "        n = tf.cast(n, 'float32')\n",
    "        \n",
    "        # Calcule triplet loss \n",
    "        subt_ = tf.subtract(self.euclidean_distance([a, p]) , self.euclidean_distance([a, n]))\n",
    "        sum_ = tf.add(subt_, self.margin)\n",
    "        \n",
    "        loss = K.maximum(sum_, 0.0)\n",
    "        # add in model loss\n",
    "        self.add_loss(loss)\n",
    "    \n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "\n",
    "# input_shape = (28, 28, 1)\n",
    "input_shape = (128, 64, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "oeSbaC8eGCw9",
    "outputId": "d0544b8b-1e33-4c06-8327-36bc58211ca6"
   },
   "outputs": [],
   "source": [
    "base_network_s1 = create_base_model(input_shape)\n",
    "\n",
    "input_anchor = Input(shape=input_shape)\n",
    "input_positive = Input(shape=input_shape)\n",
    "input_negative = Input(shape=input_shape)\n",
    "\n",
    "processed_a = base_network_s1(input_anchor)\n",
    "processed_p = base_network_s1(input_positive)\n",
    "processed_n = base_network_s1(input_negative)\n",
    "\n",
    "loss_layer_s1 = TripletLossLayer()([processed_a, processed_p, processed_n])\n",
    "\n",
    "s1 = Model([input_anchor, input_positive, input_negative], loss_layer_s1)\n",
    "\n",
    "s1.compile(optimizer=adam, loss=(lambda y_true, ypred: 0.0))\n",
    "\n",
    "s1_embs_model = base_network_s1\n",
    "s1_embs_model.compile(loss=(lambda y_true, ypred: 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_network_s2 = create_base_model(input_shape)\n",
    "autoencoder_s2 = create_autoencoder((64,))\n",
    "\n",
    "d = Dense(64, activation='relu')(base_network_s2.output)\n",
    "middle_model_s2 = Model(base_network_s2.input, d)\n",
    "\n",
    "connect = autoencoder_s2(middle_model_s2.output)\n",
    "middle_model_s2 = Model(base_network_s2.input, connect)\n",
    "\n",
    "input_anchor_s2 = Input(shape=input_shape)\n",
    "input_positive_s2 = Input(shape=input_shape)\n",
    "input_negative_s2 = Input(shape=input_shape)\n",
    "\n",
    "processed_a_s2 = middle_model_s2(input_anchor_s2)\n",
    "processed_p_s2 = middle_model_s2(input_positive_s2)\n",
    "processed_n_s2 = middle_model_s2(input_negative_s2)\n",
    "\n",
    "loss_layer_s2 = TripletLossLayer()([processed_a_s2, processed_p_s2, processed_n_s2])\n",
    "\n",
    "s2 = Model([input_anchor_s2, input_positive_s2, input_negative_s2], \n",
    "           loss_layer_s2)\n",
    "s2.compile(optimizer=adam, loss=(lambda y_true, ypred: 0.0))\n",
    "\n",
    "s2_embs_model = base_network_s2\n",
    "s2_embs_model.compile(loss=(lambda y_true, ypred: 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_network_s3 = create_base_model(input_shape)\n",
    "autoencoder_s3 = create_autoencoder((64,))\n",
    "\n",
    "d = Dense(64, activation='relu')(base_network_s3.output)\n",
    "middle_model_s3 = Model(base_network_s3.input, d)\n",
    "\n",
    "connect3 = autoencoder_s3(middle_model_s3.output)\n",
    "middle_model_s3 = Model(base_network_s3.input, connect3)\n",
    "\n",
    "input_anchor_s3 = Input(shape=input_shape)\n",
    "input_positive_s3 = Input(shape=input_shape)\n",
    "input_negative_s3 = Input(shape=input_shape)\n",
    "\n",
    "processed_a_s3 = middle_model_s3(input_anchor_s3)\n",
    "processed_p_s3 = middle_model_s3(input_positive_s3)\n",
    "processed_n_s3 = middle_model_s3(input_negative_s3)\n",
    "\n",
    "loss_layer_s3 = TripletLossLayer()([processed_a_s3, processed_p_s3, processed_n_s3])\n",
    "\n",
    "s3 = Model([input_anchor_s3, input_positive_s3, input_negative_s3], \n",
    "           loss_layer_s3)\n",
    "s3.compile(optimizer=adam, loss=(lambda y_true, ypred: 0.0))\n",
    "\n",
    "s3_embs_model = base_network_s3\n",
    "s3_embs_model.compile(loss=(lambda y_true, ypred: 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v3b_n2GaP-3H"
   },
   "source": [
    "## Experiments with MNIST (IGNORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data(path='mnist.npz')\n",
    "x_train = x_train.reshape((60000, 28, 28, 1)).astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show TSNE Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "embs = embs_model.predict(x_train[:512])\n",
    "labels = y_train[:512]\n",
    "embs_2d = TSNE().fit_transform(embs)\n",
    "scatter(embs_2d, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hc66zI_QGCxB"
   },
   "outputs": [],
   "source": [
    "def create_triplets(num_batches, batch_size):\n",
    "    for _ in range(num_batches):\n",
    "#     while True:\n",
    "        batch = []\n",
    "        clazz = []\n",
    "        for _ in range(batch_size):\n",
    "            grps_number = [1, 2, 3, 4, 5 ,6, 7, 8, 9, 0]\n",
    "            \n",
    "            grp = random.choice(grps_number)\n",
    "            grps_number.remove(grp)\n",
    "            img_a = x_train[y_train==grp][np.random.randint(x_train[y_train==grp].shape[0])]\n",
    "            img_p = x_train[y_train==grp][np.random.randint(x_train[y_train==grp].shape[0])]\n",
    "            \n",
    "            grp_2 = random.choice(grps_number)\n",
    "            img_n = x_train[y_train==grp_2][np.random.randint(x_train[y_train==grp_2].shape[0])]\n",
    "            \n",
    "            batch.append([img_a, img_p, img_n])\n",
    "        out = np.array(batch)\n",
    "        yield [out[:, i] for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "for inp_ in create_triplets(3000, 4):\n",
    "    print(np.array(inp_).shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 3, 128, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(X_train).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 8s 249ms/sample - loss: 0.7618 - val_loss: 0.0376\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0555\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0522\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.3959 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 4s 132ms/sample - loss: 0.7998 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1213 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 4s 120ms/sample - loss: 0.3601 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0108\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.4273 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 4s 114ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0720 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 4s 119ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 9ms/sample - loss: 0.3782 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3956 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.4401\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1136 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1287 - val_loss: 0.7262\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2024 - val_loss: 0.6795\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.7367\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.7894\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 10ms/sample - loss: 0.0000e+00 - val_loss: 0.8299\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.8726\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.9015\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2075\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1164 - val_loss: 0.4035\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1649 - val_loss: 0.5691\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.5432\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1659 - val_loss: 0.6810\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.6807\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1417 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0987 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.5486 - val_loss: 0.4764\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.4944\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.5031\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.4938\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.4853\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1365 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1362 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0112 - val_loss: 0.5114\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2660 - val_loss: 0.3214\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0781 - val_loss: 0.1641\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1167\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0753\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0559\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0335\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0435\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0521\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0590\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0671\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2741 - val_loss: 0.0156\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0193\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0176\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0289\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0261\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0268\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3799 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0560 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.7537\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.6801\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.6342\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.5901\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.5604\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.5341\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2685 - val_loss: 0.0764\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0606\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0429\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0273\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0104\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0023\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.5707 - val_loss: 0.0000e+00\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.7027 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.4655 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2477 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2799 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0324 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0951 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0152 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0148 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0021 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.5258 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0507 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2760 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0394 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0718\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0540\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0491\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.7576 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2950\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3177\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3388\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3528\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3714\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3866\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1267\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1432 - val_loss: 0.1867\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1576\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1322\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1114\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0959\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0809\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0721\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0661\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0643\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0571\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0527\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0527\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0491\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0490\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0454\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0444\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0464\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0458\n",
      "Epoch 20/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0452\n",
      "Epoch 21/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0427\n",
      "Epoch 22/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0436\n",
      "Epoch 23/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0440\n",
      "Epoch 24/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0432\n",
      "Epoch 25/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0402\n",
      "Epoch 26/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0405\n",
      "Epoch 27/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0388\n",
      "Epoch 28/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0395\n",
      "Epoch 29/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0401\n",
      "Epoch 30/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0386\n",
      "Epoch 31/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1614 - val_loss: 0.0040\n",
      "Epoch 32/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0267\n",
      "Epoch 33/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0445\n",
      "Epoch 34/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0593\n",
      "Epoch 35/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0683\n",
      "Epoch 36/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0808\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0983 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0708 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0037\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3329 - val_loss: 0.1730\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1909\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2046\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2147\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2240\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1435 - val_loss: 0.0879\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0232 - val_loss: 0.1909\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1862\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1875\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1850\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1782\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.6773 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1438\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1083 - val_loss: 0.2949\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1652 - val_loss: 0.1755\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1829\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1909\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1960\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2139 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0922 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0651 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1446 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0203 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1626 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1793 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0761 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.6268 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.5523 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3733 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 15ms/sample - loss: 0.0000e+00 - val_loss: 0.0771\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0746\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0687\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0706\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0670\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0667\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0508 - val_loss: 0.0000e+00\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0024\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0038\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0053\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0347\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0472\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0556\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0626\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0689\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1557 - val_loss: 0.0612\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0425 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0657 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.6399 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0342 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3070 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0308 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3527 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0153 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3355 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0868 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0112 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0444 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0038 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.5580 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1587 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2699 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1219\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1222\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1225\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1177\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1175 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.7430 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0599 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0131 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1976 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1547 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0072 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0863 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0211 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0608 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0443 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0258 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1618 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2381 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3272 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.7296 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2629 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3747 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2696\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2614\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.3572 - val_loss: 0.4381\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.4329\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.4291\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0519 - val_loss: 0.1732\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1692\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1690\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1673\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1664\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1656\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1639\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1627\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1623\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1617\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1634\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1639\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1635\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1645\n",
      "Epoch 20/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1634\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2028 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1652 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2857 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0933 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0852\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0807\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0776\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0775\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0772\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0759\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0748\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0726\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0706\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0706\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0685\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0690\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0691\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0686\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0690\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0673\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0394 - val_loss: 0.0000e+00\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0883 - val_loss: 0.0000e+00\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 20/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 21/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 22/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1048\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1101\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1137\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1185\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1213\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1231\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1892 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0372\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0349\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0367\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0397\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0377\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0396\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0413\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1371 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1526 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0543 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.5762 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0559 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 13ms/sample - loss: 0.0000e+00 - val_loss: 0.1562\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1526\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0427 - val_loss: 0.1466\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1530\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1564\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1585\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1618\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1648\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3828\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3826\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3837\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3875\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3897\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3934\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3952\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0057\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0136\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0219\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 6.4691e-04 - val_loss: 0.2938\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3287\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3624\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2373 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1624 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0234 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0655 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0858 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1425 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1589 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1255 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0852\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0807\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0773\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0740\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0694\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0688\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0635\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0593\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0579\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0562\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0575\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0548\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0540\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0522\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0520\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0489\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0488\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0483\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1281 - val_loss: 0.0000e+00\n",
      "Epoch 20/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 21/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 22/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 23/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 24/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1131 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1185 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0376 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0244 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0666 - val_loss: 0.1930\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1869\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0616 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1190 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2598 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2615 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0125 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0734 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0405 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.3232 - val_loss: 0.2307\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2121\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1915\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1788\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1707\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1634\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1621\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.1554\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1516\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1492\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1486\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1474\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1469\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1456\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1448\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1445\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1445\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1427\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1418\n",
      "Epoch 20/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1405\n",
      "Epoch 21/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1413\n",
      "Epoch 22/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1406\n",
      "Epoch 23/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1414\n",
      "Epoch 24/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1406\n",
      "Epoch 25/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1405\n",
      "Epoch 26/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1420\n",
      "Epoch 27/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1423\n",
      "Epoch 28/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1422\n",
      "Epoch 29/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1399\n",
      "Epoch 30/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1401\n",
      "Epoch 31/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1397\n",
      "Epoch 32/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1395\n",
      "Epoch 33/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1400\n",
      "Epoch 34/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1401\n",
      "Epoch 35/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1403\n",
      "Epoch 36/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1410\n",
      "Epoch 37/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1407\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 2s 63ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 9ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0254\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0205\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0190\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0168\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0151\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0126\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0127\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0114\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0122\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0105\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0102\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0324 - val_loss: 0.0000e+00\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1106 - val_loss: 0.3391\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3435\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3446\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3429\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3417\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0257\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0262\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0255\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0256\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0250\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0246\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0018 - val_loss: 0.0725\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0724\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0715\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0701\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0683\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 1s 38ms/sample - loss: 0.0000e+00 - val_loss: 0.0320\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0348\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0361\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0381\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0396\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0400\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2088 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0903 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1845 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1222\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1238\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 1s 28ms/sample - loss: 0.0000e+00 - val_loss: 0.1210\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.1177\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1205\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1190\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1176\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1155\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1162\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1152\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1131\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1131\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1137\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1096\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1129\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1168\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1182\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1136\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1158\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0316 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2670 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0216 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0930\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0957\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0210 - val_loss: 0.3506\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3533\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3566\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3577\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2475 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0382 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0131 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.5350 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1163 - val_loss: 0.0920\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1054\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1138\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1136\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1125\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1090\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0527\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0611\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0647\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0677\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0708\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0740\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.1878 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3711 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.4112 - val_loss: 0.0996\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0938\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0869\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0773\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0678\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.4167 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0098 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2225 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0836 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0093\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0117\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2334 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0519 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2518 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.3325\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3277\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3221\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3188\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.3172\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3154\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3134\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3114\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3104\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3087\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3069\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3052\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3045\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.3037\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3030\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3034\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3037\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3047\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3046\n",
      "Epoch 20/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3060\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0472\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0501\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0516\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0545\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0561\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1063 - val_loss: 0.0000e+00\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0085 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1061 - val_loss: 0.0382\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0458\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0504\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0551\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0601\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0623\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3366\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3420\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3463\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3503\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3550\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3581\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.3284 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1572 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0509 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0096 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1536 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 9ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.2965\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2912\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2898\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2890\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2865\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2852\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2824\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2780\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2770\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1096 - val_loss: 0.3404\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3368\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3307\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3270\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3215\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1811 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0540 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0410 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3734\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.3627 - val_loss: 0.1306\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1580\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1793\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1951\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2015\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2075\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0799 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2833 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.4813 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0309 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0219 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0744 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3730 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 12ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0268\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0302\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0342\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0359\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0364\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0372\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0131 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0351 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1458 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.4776 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3002\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2949\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2899\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2856\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2828\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2808\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2798\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2780\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2773\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2767\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2761\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2753\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2772\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2765\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2763\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2753\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2751\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2752\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2750\n",
      "Epoch 20/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2741\n",
      "Epoch 21/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2752\n",
      "Epoch 22/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2749\n",
      "Epoch 23/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2747\n",
      "Epoch 24/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2741\n",
      "Epoch 25/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2733\n",
      "Epoch 26/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2721\n",
      "Epoch 27/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2727\n",
      "Epoch 28/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2730\n",
      "Epoch 29/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2733\n",
      "Epoch 30/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2743\n",
      "Epoch 31/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2750\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0712 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0561 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.3378 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1133 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.5004 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3385 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1753 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1930 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0624\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0543\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0169 - val_loss: 0.3568\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3497\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3454\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3441\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3432\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1596 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0236 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0594 - val_loss: 0.0804\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.4096 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2309 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0113 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1797 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1165\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1151\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1131\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1118\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1117\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1105\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1103\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1094\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1103\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1102\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1106\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1108\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1104\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0921 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0950\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0987\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1023\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1055\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1083\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1123\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0801 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 12ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0107 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2159 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3385\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3381\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3366\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3360\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3350\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3350\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3379\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3387\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3370\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3413\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1642 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0862 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3482\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0784 - val_loss: 0.2676\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3030\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3254\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3577\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3832\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3939\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0302 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1810\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1848\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1882\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2136 - val_loss: 0.1415\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1439\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1474\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1497\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0407 - val_loss: 0.2031\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2011\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1653 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0241 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0239\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0228\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0205\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0206\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0212\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0205\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0216\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0469 - val_loss: 0.0274\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0303\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0309\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0302\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3372\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3354\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3342\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3294\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3343\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3389\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3347\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3343\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3325\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2229\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2105\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2017\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1958\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1915\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1867\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1840\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1799\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1765\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1769\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1743\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.1731\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1742\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1726\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1738\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1734\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1749\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1729\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1728\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1877 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 10ms/sample - loss: 0.0000e+00 - val_loss: 0.0066\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0089\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1897 - val_loss: 0.0352\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0380\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0391\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0383\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3033 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0020\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0055\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0098\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0123\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3402 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 1s 29ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2191 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1105 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1739\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1735\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1728\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1727\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1744\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1763\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1765\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1762\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1741\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3993 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0410 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2337 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0887 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0014\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0014\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0024\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.3727 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0340 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2432\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2418\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2424\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2476\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2522\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2593\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2576\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 9ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2440 - val_loss: 0.0932\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1038\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1142\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1219\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0064\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0050\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0021\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 5.5524e-04\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2149 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2230 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0555 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1751\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1763\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1767\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1750\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1749\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1732\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.1754\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1760\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1752\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1742\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1764\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 1s 37ms/sample - loss: 0.0000e+00 - val_loss: 0.0280\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0285\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0283\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0284\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0289\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0285\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0334 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0360 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0997 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 11ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2322\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2335\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2357\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2363\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2382\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2384\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2956 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1913 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0960 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0694 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2307 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2115 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0142\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0247\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0338\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0405\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0059 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0021\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0029\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0040\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0029\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0024\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0502 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.4352 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0072 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0194 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1815 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0460 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0629 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0440 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.7168\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.7196\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.7242\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.7260\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.7282\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.7270\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0225\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0132 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0213 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 3s 101ms/sample - loss: 0.0197 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.4743 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0281 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.1684 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1994 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2922 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0143\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0162\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0164\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0178\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0189\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0185\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1657 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0130\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0147\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0158\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0176\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0178\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0190\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0549 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3728 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1672 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2624\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2583\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2555\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2129 - val_loss: 0.4113\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.4058\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3987\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3954\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3909\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0893\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0884\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0891\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0891\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0867\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0854\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0850\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0828\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0846\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0809\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0797\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0810\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0836\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0995 - val_loss: 0.4063\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.4164\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.4242\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1769 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1289 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0707 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1519 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0656 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1729 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1035 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.4244 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.1297 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0479 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3453 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0891 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0263 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2580 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0064 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1256 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2222\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2105\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2030\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1979\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1947\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1898\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1870\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1862\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1850\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1854\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1833\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1824\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1804\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1809\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1791\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1772\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1771\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1780\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1776\n",
      "Epoch 20/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1787\n",
      "Epoch 21/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1789\n",
      "Epoch 22/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1768\n",
      "Epoch 23/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1750\n",
      "Epoch 24/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1761\n",
      "Epoch 25/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1766\n",
      "Epoch 26/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1770\n",
      "Epoch 27/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1763\n",
      "Epoch 28/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1760\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1439 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3428 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1165 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 6.7037e-04 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 2s 68ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 13ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1579 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1201 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0575 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.4913 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0553 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0182 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0496\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0276 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0222 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1502 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0528 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2081\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2124\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2159\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2172\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2203\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2222\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1781 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0803 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0395 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0332 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2494 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 3.3459e-04 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0417\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.4047 - val_loss: 0.0433\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0330\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0226\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0121\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0031\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0552 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2919 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1327 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2906 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0759 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0476 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.2525 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0666 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0497 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0892 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1379 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0589 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 1s 32ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1681 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1783\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1759\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1779\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1755\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1760\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1758\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1785\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0555 - val_loss: 0.0000e+00\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0249 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 3s 86ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1157 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.1745 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1022 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1518 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.7418 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 1s 40ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2219 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0888 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0011 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1261 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0275 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0045 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0603 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1332\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1323\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1307\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1288\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1270\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1279\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1276\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1284\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1285\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1283\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0836 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1163 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1624 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0505 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1131 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1674 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0653\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0670\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0660\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0657\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0659\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0663\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.2446 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 4s 124ms/sample - loss: 0.2201 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 10ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.3369 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0856 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3302 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0036 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1874 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 1s 26ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0515 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0525\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0525\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0525\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0529\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0528\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0530\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2512 - val_loss: 0.0000e+00\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1812 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0499 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 4s 125ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 3s 97ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 2s 74ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0578 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0744 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0946 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0109 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1545\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1532\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1554\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1530\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1557\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1592\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1564\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1585\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1537\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0633 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.6201 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1665 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 1s 25ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1091 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 3.3882e-04 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0729\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0750\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0750\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0751\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0766\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0757\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0889 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0212 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0241 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1169 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1175 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0156 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0650 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0727 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1437 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1598 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0908 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1102 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0222 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.3105 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1153 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0789 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0481 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0842 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0139 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0429 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.4043\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.4053\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.4069\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.4076\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.4075\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.4096\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2582 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1555 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0267\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0289\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0297\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0300\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0293\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0302\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1582 - val_loss: 0.0900\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0893\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0907\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1223 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0069\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0064\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0066\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0065\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0071\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0086\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0089\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1176 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0802 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0261 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.4507 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0093\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0119\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0131\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0140\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0149\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0153\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3341 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.3156 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 11ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0531 - val_loss: 0.0140\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.4909 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.3800\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3829\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3842\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3902\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3936\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.3956\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1768 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1405 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0221\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0249\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0262\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0274\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0286\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0300\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 1s 26ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0981\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0968\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0949\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0937\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0933\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0955\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0933\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0913\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0900\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0917\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0912\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0898\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0898\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0896\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0868\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0873\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0860\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0843\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0843\n",
      "Epoch 20/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0867\n",
      "Epoch 21/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0884\n",
      "Epoch 22/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0880\n",
      "Epoch 23/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0894\n",
      "Epoch 24/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0887\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0186 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 9ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1123 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.1650\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.1640\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1627\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1625\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1627\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1624\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.1609\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1609\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1611\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.1629\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1607\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1606\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.1599\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.1583\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1578\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0755 - val_loss: 0.0320\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0319\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0320\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0315\n",
      "Epoch 20/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0321\n",
      "Epoch 21/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0310\n",
      "Epoch 22/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0321\n",
      "Epoch 23/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.2223 - val_loss: 0.0811\n",
      "Epoch 24/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0839\n",
      "Epoch 25/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0866\n",
      "Epoch 26/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0895\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0805\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0765\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0739\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0715\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0696\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0685\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0668\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0648\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0637\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0650\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0641\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0634\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0628\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0632\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0626\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0623\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0522 - val_loss: 0.0511\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0530\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0491\n",
      "Epoch 20/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0444\n",
      "Epoch 21/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0408\n",
      "Epoch 22/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0381\n",
      "Epoch 23/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0369\n",
      "Epoch 24/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0360\n",
      "Epoch 25/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0352\n",
      "Epoch 26/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0341\n",
      "Epoch 27/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0340\n",
      "Epoch 28/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0331\n",
      "Epoch 29/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0322\n",
      "Epoch 30/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0320\n",
      "Epoch 31/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0313\n",
      "Epoch 32/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0314\n",
      "Epoch 33/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0312\n",
      "Epoch 34/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0308\n",
      "Epoch 35/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0304\n",
      "Epoch 36/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0300\n",
      "Epoch 37/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0299\n",
      "Epoch 38/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0308\n",
      "Epoch 39/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0306\n",
      "Epoch 40/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0305\n",
      "Epoch 41/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0325\n",
      "Epoch 42/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0321\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.3456\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3435\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.3452\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3447\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3427\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.3442\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.3431\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3439\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.3440\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.3454\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.3195 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0164 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0051 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0131 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0058 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0386 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 10ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2590 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 2s 74ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 2s 63ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 15ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1292\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1303+0\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1314\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1331\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.1364\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1373\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0581\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0589\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0593\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0588\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0591\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0587\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0444 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0495 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.3019 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.3923 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2420 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0157 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.1873 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0576 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 10ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0180 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0850 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1207 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0160 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.3173 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.7814 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3f8546649308>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                          verbose=0, restore_best_weights=True)\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0minp_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcreate_triplets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-36a5968630f6>\u001b[0m in \u001b[0;36mcreate_triplets\u001b[0;34m(num_batches, batch_size)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mgrp_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrps_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mimg_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mgrp_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mgrp_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "y_true = np.array([[0.0 for _ in range(64)] for _ in range(batch_size)])\n",
    "\n",
    "\n",
    "early_stopping =  tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, min_delta=0,\n",
    "                                                         verbose=0, restore_best_weights=True)\n",
    "\n",
    "for inp_ in create_triplets(3000, batch_size):\n",
    "    model.fit(inp_ , y_true, batch_size=5, epochs=1000000, callbacks=[early_stopping], shuffle=True, validation_split=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show TSNE After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "embs = embs_model.predict(x_train[:512])\n",
    "labels = y_train[:512]\n",
    "embs_2d = TSNE().fit_transform(embs)\n",
    "scatter(embs_2d, labels, subtitle=\"After-training3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments With Real Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tripplet_data import *\n",
    "\n",
    "def map_person_to_filepaths(folder='treino'):\n",
    "    path = 'datasets/airport-alunos/' + folder + '/'\n",
    "    images_per_person = {}\n",
    "    \n",
    "    for i in range(2):\n",
    "        for (person, person_path) in map_person_files(path + str(i) +'/').items():\n",
    "            for pp in person_path:\n",
    "                if person not in images_per_person:\n",
    "                    images_per_person[person] = []\n",
    "\n",
    "                for img in list_person_files(pp):\n",
    "                    images_per_person[person].append(pp + img)\n",
    "            \n",
    "    return images_per_person \n",
    "\n",
    "def create_embeddings(map_files, embs_model, debbug=False):\n",
    "    embeddings_per_person = {}\n",
    "    images_per_person = {}\n",
    "\n",
    "    total = len(map_files)\n",
    "    count = 1\n",
    "    for (person, images_path) in map_files.items():\n",
    "        np_images = []\n",
    "        for ip in images_path:\n",
    "            np_image = img_to_array(load_img(ip))\n",
    "            np_images.append(np_image)\n",
    "        \n",
    "        if debbug:\n",
    "            print(\"(\" + str(count)+ \"/\" + str(total) +\") predicting to person \"+ person)\n",
    "            \n",
    "        count = count + 1\n",
    "        embs_output = embs_model.predict(np.array(np_images))\n",
    "        \n",
    "        images_per_person[person] = np_images\n",
    "        embeddings_per_person[person] = embs_output\n",
    "    \n",
    "    return embeddings_per_person, images_per_person\n",
    "\n",
    "\n",
    "def create_triplets(number_of_triples, embeddings_map, images_map):\n",
    "    while True:\n",
    "        def get_distance(emb1, emb2):\n",
    "            return np.sqrt(np.sum(np.power((emb1 - emb2), 2)))\n",
    "        persons = np.array([name for (name, _) in embeddings_map.items()])\n",
    "\n",
    "        anchors = np.zeros(shape=(0,128, 64, 3))\n",
    "        positives = np.zeros(shape=(0,128, 64, 3))\n",
    "        negatives = np.zeros(shape=(0,128, 64, 3))\n",
    "\n",
    "        for _ in range(number_of_triples):\n",
    "            anchor_person = random.choice(persons)\n",
    "            neg_person = anchor_person\n",
    "            while anchor_person == neg_person:\n",
    "                neg_person = random.choice(persons)\n",
    "\n",
    "            anchor_idx = np.random.randint(len(embeddings_map[anchor_person]))\n",
    "            anchor_emb = embeddings_map[anchor_person][anchor_idx]\n",
    "            anchor_img = images_map[anchor_person][anchor_idx]\n",
    "\n",
    "            # Select the farthest on as positive\n",
    "            positive_img = random.choice(images_map[anchor_person])\n",
    "\n",
    "            # Select the nearst on as negative\n",
    "            negative_img = random.choice(images_map[neg_person])\n",
    "\n",
    "            anchors = np.append( anchors,  np.expand_dims(anchor_img, axis=0), axis=0)\n",
    "            positives = np.append( positives,  np.expand_dims(positive_img, axis=0), axis=0)\n",
    "            negatives = np.append( negatives,  np.expand_dims(negative_img, axis=0), axis=0)\n",
    "\n",
    "        y_true = np.array([[0.0 for _ in range(64)] for _ in range(number_of_triples)])\n",
    "\n",
    "        yield [anchors, positives, negatives], y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show TSNE Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/50) predicting to person 235\n",
      "(2/50) predicting to person 207\n",
      "(3/50) predicting to person 230\n",
      "(4/50) predicting to person 237\n",
      "(5/50) predicting to person 247\n",
      "(6/50) predicting to person 228\n",
      "(7/50) predicting to person 210\n",
      "(8/50) predicting to person 222\n",
      "(9/50) predicting to person 227\n",
      "(10/50) predicting to person 206\n",
      "(11/50) predicting to person 249\n",
      "(12/50) predicting to person 244\n",
      "(13/50) predicting to person 202\n",
      "(14/50) predicting to person 205\n",
      "(15/50) predicting to person 232\n",
      "(16/50) predicting to person 239\n",
      "(17/50) predicting to person 203\n",
      "(18/50) predicting to person 214\n",
      "(19/50) predicting to person 231\n",
      "(20/50) predicting to person 240\n",
      "(21/50) predicting to person 246\n",
      "(22/50) predicting to person 213\n",
      "(23/50) predicting to person 223\n",
      "(24/50) predicting to person 234\n",
      "(25/50) predicting to person 248\n",
      "(26/50) predicting to person 229\n",
      "(27/50) predicting to person 209\n",
      "(28/50) predicting to person 221\n",
      "(29/50) predicting to person 200\n",
      "(30/50) predicting to person 242\n",
      "(31/50) predicting to person 212\n",
      "(32/50) predicting to person 201\n",
      "(33/50) predicting to person 233\n",
      "(34/50) predicting to person 204\n",
      "(35/50) predicting to person 217\n",
      "(36/50) predicting to person 224\n",
      "(37/50) predicting to person 219\n",
      "(38/50) predicting to person 226\n",
      "(39/50) predicting to person 245\n",
      "(40/50) predicting to person 241\n",
      "(41/50) predicting to person 208\n",
      "(42/50) predicting to person 243\n",
      "(43/50) predicting to person 211\n",
      "(44/50) predicting to person 236\n",
      "(45/50) predicting to person 218\n",
      "(46/50) predicting to person 225\n",
      "(47/50) predicting to person 215\n",
      "(48/50) predicting to person 220\n",
      "(49/50) predicting to person 238\n",
      "(50/50) predicting to person 216\n"
     ]
    }
   ],
   "source": [
    "embeddings, images = create_embeddings(map_person_to_filepaths('val'), s1_embs_model, debbug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_embs = np.zeros(shape=(0,64))\n",
    "labels = np.zeros(shape=(0,1))\n",
    "count = 1\n",
    "for (person, embs) in embeddings.items():\n",
    "    combined_embs = np.append( combined_embs,  embs, axis=0)\n",
    "    l = np.zeros((len(embs), 1)) + count\n",
    "    labels = np.append( labels,  l, axis=0)\n",
    "    count = count + 1\n",
    "    if count>10:\n",
    "        break\n",
    "\n",
    "labels = labels.flatten()\n",
    "embs_2d = TSNE().fit_transform(combined_embs)\n",
    "scatter(embs_2d, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/50 [======>.......................] - ETA: 1:47 - loss: 0.1764"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-4d711dbaba0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_triplets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ammd/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/ammd/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ammd/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m~/anaconda3/envs/ammd/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ammd/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ammd/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    266\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backwards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m           \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m           if isinstance(model.optimizer,\n\u001b[1;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n",
      "\u001b[0;32m~/anaconda3/envs/ammd/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ammd/lib/python3.6/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ammd/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ammd/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_FusedBatchNormV3Grad\u001b[0;34m(op, *grad)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegisterGradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FusedBatchNormV3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_FusedBatchNormV3Grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_BaseFusedBatchNormGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ammd/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_BaseFusedBatchNormGrad\u001b[0;34m(op, version, *grad)\u001b[0m\n\u001b[1;32m    888\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reserve_space_3\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    891\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0mpop_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ammd/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mfused_batch_norm_grad_v3\u001b[0;34m(y_backprop, x, scale, reserve_space_1, reserve_space_2, reserve_space_3, epsilon, data_format, is_training, name)\u001b[0m\n\u001b[1;32m   4325\u001b[0m         \u001b[0my_backprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreserve_space_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreserve_space_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4326\u001b[0m         \u001b[0mreserve_space_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"epsilon\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4327\u001b[0;31m         \"is_training\", is_training)\n\u001b[0m\u001b[1;32m   4328\u001b[0m       \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FusedBatchNormGradV3Output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4329\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "s1.fit_generator(create_triplets(50, embeddings, images), epochs=1000, steps_per_epoch=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show TSNE After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ec7JVXihGCxZ"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "embs = embs_model.predict(X_val[0])\n",
    "labels = Y_val[:, 0].astype(int)\n",
    "\n",
    "embs_2d = TSNE().fit_transform(embs)\n",
    "scatter(embs_2d, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t83rwHU-GCxd"
   },
   "source": [
    "## Evaluation of model\n",
    "\n",
    "* Get Embeddings\n",
    "* Create a shallow neural network\n",
    "* Train this network to decide if two embs is from the same person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_anchor_val = embs_model.predict(X_val[0])\n",
    "embs_pos_val = embs_model.predict(X_val[1])\n",
    "embs_neg_val = embs_model.predict(X_val[2])\n",
    "\n",
    "embs_anchor_train = embs_model.predict(X_train[0])\n",
    "embs_pos_train = embs_model.predict(X_train[1])\n",
    "embs_neg_train = embs_model.predict(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128)          0           input_11[0][0]                   \n",
      "                                                                 input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           8256        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           2080        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            33          dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 10,369\n",
      "Trainable params: 10,369\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pred_model_inp_a = Input(shape=(64,))\n",
    "pred_model_inp_b = Input(shape=(64,))\n",
    "\n",
    "pred_model = Dense(64, activation='relu')(tf.keras.layers.concatenate([pred_model_inp_a, pred_model_inp_b]))\n",
    "pred_model = Dense(32, activation='relu')(pred_model)\n",
    "pred_model_output = Dense(1, activation='sigmoid')(pred_model)\n",
    "\n",
    "pred_model = Model(inputs=[pred_model_inp_a, pred_model_inp_b], outputs=pred_model_output)\n",
    "\n",
    "pred_model.compile(loss='binary_crossentropy')\n",
    "pred_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000 samples\n",
      "Epoch 1/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4496\n",
      "Epoch 2/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4410\n",
      "Epoch 3/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4366\n",
      "Epoch 4/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4307\n",
      "Epoch 5/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4283\n",
      "Epoch 6/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.4245\n",
      "Epoch 7/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.4216\n",
      "Epoch 8/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4188\n",
      "Epoch 9/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4162\n",
      "Epoch 10/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4131\n",
      "Epoch 11/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.4106\n",
      "Epoch 12/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4080\n",
      "Epoch 13/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4059\n",
      "Epoch 14/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4053\n",
      "Epoch 15/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.4024\n",
      "Epoch 16/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3992\n",
      "Epoch 17/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3965\n",
      "Epoch 18/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3948\n",
      "Epoch 19/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3937\n",
      "Epoch 20/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3922\n",
      "Epoch 21/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3901\n",
      "Epoch 22/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3900\n",
      "Epoch 23/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3872\n",
      "Epoch 24/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3857\n",
      "Epoch 25/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3839\n",
      "Epoch 26/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3835\n",
      "Epoch 27/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3837\n",
      "Epoch 28/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3828\n",
      "Epoch 29/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3813\n",
      "Epoch 30/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3802\n",
      "Epoch 31/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3786\n",
      "Epoch 32/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3772\n",
      "Epoch 33/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3767\n",
      "Epoch 34/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3765\n",
      "Epoch 35/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3744\n",
      "Epoch 36/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3741\n",
      "Epoch 37/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3726\n",
      "Epoch 38/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3727\n",
      "Epoch 39/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3719\n",
      "Epoch 40/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3710\n",
      "Epoch 41/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3705\n",
      "Epoch 42/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3690\n",
      "Epoch 43/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3690\n",
      "Epoch 44/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3687\n",
      "Epoch 45/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3676\n",
      "Epoch 46/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3680\n",
      "Epoch 47/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3662\n",
      "Epoch 48/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3671\n",
      "Epoch 49/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3655\n",
      "Epoch 50/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3651\n",
      "Epoch 51/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3643\n",
      "Epoch 52/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3644\n",
      "Epoch 53/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3635\n",
      "Epoch 54/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3622\n",
      "Epoch 55/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3624\n",
      "Epoch 56/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3612\n",
      "Epoch 57/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3614\n",
      "Epoch 58/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3611\n",
      "Epoch 59/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3615\n",
      "Epoch 60/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3612\n",
      "Epoch 61/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3590\n",
      "Epoch 62/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3595\n",
      "Epoch 63/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3589\n",
      "Epoch 64/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3584\n",
      "Epoch 65/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3580\n",
      "Epoch 66/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3579\n",
      "Epoch 67/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3578\n",
      "Epoch 68/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3564\n",
      "Epoch 69/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3565\n",
      "Epoch 70/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3567\n",
      "Epoch 71/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3566\n",
      "Epoch 72/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3568\n",
      "Epoch 73/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3550\n",
      "Epoch 74/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3559\n",
      "Epoch 75/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3549\n",
      "Epoch 76/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3537\n",
      "Epoch 77/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3536\n",
      "Epoch 78/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3540\n",
      "Epoch 79/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3547\n",
      "Epoch 80/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3545\n",
      "Epoch 81/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3543\n",
      "Epoch 82/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3519\n",
      "Epoch 83/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3537\n",
      "Epoch 84/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3529\n",
      "Epoch 85/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3523\n",
      "Epoch 86/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3527\n",
      "Epoch 87/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3521\n",
      "Epoch 00087: early stopping\n",
      "Train on 100000 samples\n",
      "Epoch 1/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4177\n",
      "Epoch 2/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.4079\n",
      "Epoch 3/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4011\n",
      "Epoch 4/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3987\n",
      "Epoch 5/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3954\n",
      "Epoch 6/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3919\n",
      "Epoch 7/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3915\n",
      "Epoch 8/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3895\n",
      "Epoch 9/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3868\n",
      "Epoch 10/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3860\n",
      "Epoch 11/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3858\n",
      "Epoch 12/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3834\n",
      "Epoch 13/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3830\n",
      "Epoch 14/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3803\n",
      "Epoch 15/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3804\n",
      "Epoch 16/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3788\n",
      "Epoch 17/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3789\n",
      "Epoch 18/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3770\n",
      "Epoch 19/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3766\n",
      "Epoch 20/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3762\n",
      "Epoch 21/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3742\n",
      "Epoch 22/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3742\n",
      "Epoch 23/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3736\n",
      "Epoch 24/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3733\n",
      "Epoch 25/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3729\n",
      "Epoch 26/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3714\n",
      "Epoch 27/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3723\n",
      "Epoch 28/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3694\n",
      "Epoch 29/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3707\n",
      "Epoch 30/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3686\n",
      "Epoch 31/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3684\n",
      "Epoch 32/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3681\n",
      "Epoch 33/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3679\n",
      "Epoch 34/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3669\n",
      "Epoch 35/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3664\n",
      "Epoch 36/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3651\n",
      "Epoch 37/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3654\n",
      "Epoch 38/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3657\n",
      "Epoch 39/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3650\n",
      "Epoch 40/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3643\n",
      "Epoch 41/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3650\n",
      "Epoch 42/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3636\n",
      "Epoch 43/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3634\n",
      "Epoch 44/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3647\n",
      "Epoch 45/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3639\n",
      "Epoch 46/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3628\n",
      "Epoch 47/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3627\n",
      "Epoch 48/5000\n",
      "100000/100000 [==============================] - 9s 95us/sample - loss: 0.3615\n",
      "Epoch 49/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3604\n",
      "Epoch 50/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3611\n",
      "Epoch 51/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3612\n",
      "Epoch 52/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3604\n",
      "Epoch 53/5000\n",
      "100000/100000 [==============================] - 10s 99us/sample - loss: 0.3606\n",
      "Epoch 54/5000\n",
      "100000/100000 [==============================] - 10s 96us/sample - loss: 0.3593\n",
      "Epoch 55/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3596\n",
      "Epoch 56/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3591\n",
      "Epoch 57/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3590\n",
      "Epoch 58/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3578\n",
      "Epoch 59/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3579\n",
      "Epoch 60/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3590\n",
      "Epoch 61/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3575\n",
      "Epoch 62/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3563\n",
      "Epoch 63/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3570\n",
      "Epoch 64/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3567\n",
      "Epoch 65/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3578\n",
      "Epoch 66/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3573\n",
      "Epoch 67/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3569\n",
      "Epoch 00067: early stopping\n",
      "Train on 100000 samples\n",
      "Epoch 1/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4150\n",
      "Epoch 2/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4050\n",
      "Epoch 3/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.4009\n",
      "Epoch 4/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3955\n",
      "Epoch 5/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3934\n",
      "Epoch 6/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3914\n",
      "Epoch 7/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3903\n",
      "Epoch 8/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3881\n",
      "Epoch 9/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3861\n",
      "Epoch 10/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3839\n",
      "Epoch 11/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3843\n",
      "Epoch 12/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3824\n",
      "Epoch 13/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3799\n",
      "Epoch 14/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3806\n",
      "Epoch 15/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3785\n",
      "Epoch 16/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3782\n",
      "Epoch 17/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3763\n",
      "Epoch 18/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3776\n",
      "Epoch 19/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3748\n",
      "Epoch 20/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3745\n",
      "Epoch 21/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3736\n",
      "Epoch 22/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3735\n",
      "Epoch 23/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3724\n",
      "Epoch 24/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3713\n",
      "Epoch 25/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3717\n",
      "Epoch 26/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3716\n",
      "Epoch 27/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3704\n",
      "Epoch 28/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3705\n",
      "Epoch 29/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3697\n",
      "Epoch 30/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3697\n",
      "Epoch 31/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3688\n",
      "Epoch 32/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3680\n",
      "Epoch 33/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3669\n",
      "Epoch 34/5000\n",
      "100000/100000 [==============================] - 9s 95us/sample - loss: 0.3681\n",
      "Epoch 35/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3675\n",
      "Epoch 36/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3656\n",
      "Epoch 37/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3651\n",
      "Epoch 38/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3651\n",
      "Epoch 39/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3647\n",
      "Epoch 40/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3652\n",
      "Epoch 41/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3641\n",
      "Epoch 42/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3639\n",
      "Epoch 43/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3636\n",
      "Epoch 44/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3634\n",
      "Epoch 45/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3637\n",
      "Epoch 46/5000\n",
      "100000/100000 [==============================] - 9s 95us/sample - loss: 0.3627\n",
      "Epoch 47/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3623\n",
      "Epoch 48/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3633\n",
      "Epoch 49/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3618\n",
      "Epoch 50/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3616\n",
      "Epoch 51/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3625\n",
      "Epoch 52/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3605\n",
      "Epoch 53/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3606\n",
      "Epoch 54/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3602\n",
      "Epoch 55/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3609\n",
      "Epoch 56/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3603\n",
      "Epoch 57/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3601\n",
      "Epoch 58/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3601\n",
      "Epoch 59/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3599\n",
      "Epoch 60/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3583\n",
      "Epoch 61/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3592\n",
      "Epoch 62/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3592\n",
      "Epoch 63/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3603\n",
      "Epoch 64/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3574\n",
      "Epoch 65/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3576\n",
      "Epoch 66/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3572\n",
      "Epoch 67/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3575\n",
      "Epoch 68/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3571\n",
      "Epoch 69/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3569\n",
      "Epoch 70/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3568\n",
      "Epoch 71/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3558\n",
      "Epoch 72/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3563\n",
      "Epoch 73/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3569\n",
      "Epoch 74/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3565\n",
      "Epoch 75/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3576\n",
      "Epoch 76/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3550\n",
      "Epoch 77/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3568\n",
      "Epoch 78/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3563\n",
      "Epoch 79/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3551\n",
      "Epoch 80/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3556\n",
      "Epoch 81/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3568\n",
      "Epoch 00081: early stopping\n",
      "Train on 100000 samples\n",
      "Epoch 1/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.4220\n",
      "Epoch 2/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.4109\n",
      "Epoch 3/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4072\n",
      "Epoch 4/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4019\n",
      "Epoch 5/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3973\n",
      "Epoch 6/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3947\n",
      "Epoch 7/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3940\n",
      "Epoch 8/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3921\n",
      "Epoch 9/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3907\n",
      "Epoch 10/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3884\n",
      "Epoch 11/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3873\n",
      "Epoch 12/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3862\n",
      "Epoch 13/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3838\n",
      "Epoch 14/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3850\n",
      "Epoch 15/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3822\n",
      "Epoch 16/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3824\n",
      "Epoch 17/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3802\n",
      "Epoch 18/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3805\n",
      "Epoch 19/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3800\n",
      "Epoch 20/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3790\n",
      "Epoch 21/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3789\n",
      "Epoch 22/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3781\n",
      "Epoch 23/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3774\n",
      "Epoch 24/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3773\n",
      "Epoch 25/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3749\n",
      "Epoch 26/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3755\n",
      "Epoch 27/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3741\n",
      "Epoch 28/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3740\n",
      "Epoch 29/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3729\n",
      "Epoch 30/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3727\n",
      "Epoch 31/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3729\n",
      "Epoch 32/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3746\n",
      "Epoch 33/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3713\n",
      "Epoch 34/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3721\n",
      "Epoch 35/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3715\n",
      "Epoch 36/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3712\n",
      "Epoch 37/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3696\n",
      "Epoch 38/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3709\n",
      "Epoch 39/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3691\n",
      "Epoch 40/5000\n",
      "100000/100000 [==============================] - 9s 89us/sample - loss: 0.3696\n",
      "Epoch 41/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3684\n",
      "Epoch 42/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3684\n",
      "Epoch 43/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3690\n",
      "Epoch 44/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3683\n",
      "Epoch 45/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3670\n",
      "Epoch 46/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3670\n",
      "Epoch 47/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3675\n",
      "Epoch 48/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3663\n",
      "Epoch 49/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3643\n",
      "Epoch 50/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3668\n",
      "Epoch 51/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3647\n",
      "Epoch 52/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3653\n",
      "Epoch 53/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3639\n",
      "Epoch 54/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3635\n",
      "Epoch 55/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3647\n",
      "Epoch 56/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3636\n",
      "Epoch 57/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3636\n",
      "Epoch 58/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3647\n",
      "Epoch 59/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3635\n",
      "Epoch 60/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3634\n",
      "Epoch 61/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3629\n",
      "Epoch 62/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3632\n",
      "Epoch 63/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3628\n",
      "Epoch 64/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3633\n",
      "Epoch 65/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3628\n",
      "Epoch 66/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3629\n",
      "Epoch 67/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3617\n",
      "Epoch 68/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3611\n",
      "Epoch 69/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3619\n",
      "Epoch 70/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3632\n",
      "Epoch 71/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3598\n",
      "Epoch 72/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3619\n",
      "Epoch 73/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3617\n",
      "Epoch 74/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3610\n",
      "Epoch 75/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3608\n",
      "Epoch 76/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3607\n",
      "Epoch 00076: early stopping\n",
      "Train on 100000 samples\n",
      "Epoch 1/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.4182\n",
      "Epoch 2/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.4105\n",
      "Epoch 3/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4054\n",
      "Epoch 4/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.4014\n",
      "Epoch 5/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3975\n",
      "Epoch 6/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3959\n",
      "Epoch 7/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3927\n",
      "Epoch 8/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3908\n",
      "Epoch 9/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3896\n",
      "Epoch 10/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3886\n",
      "Epoch 11/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3876\n",
      "Epoch 12/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3857\n",
      "Epoch 13/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3848\n",
      "Epoch 14/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3825\n",
      "Epoch 15/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3830\n",
      "Epoch 16/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3817\n",
      "Epoch 17/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3801\n",
      "Epoch 18/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3790\n",
      "Epoch 19/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3787\n",
      "Epoch 20/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3784\n",
      "Epoch 21/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3761\n",
      "Epoch 22/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3779\n",
      "Epoch 23/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3764\n",
      "Epoch 24/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3738\n",
      "Epoch 25/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3745\n",
      "Epoch 26/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3749\n",
      "Epoch 27/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3729\n",
      "Epoch 28/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3722\n",
      "Epoch 29/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3725\n",
      "Epoch 30/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3729\n",
      "Epoch 31/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3724\n",
      "Epoch 32/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3725\n",
      "Epoch 33/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3710\n",
      "Epoch 34/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3710\n",
      "Epoch 35/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3702\n",
      "Epoch 36/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3710\n",
      "Epoch 37/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3704\n",
      "Epoch 38/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3701\n",
      "Epoch 39/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3700\n",
      "Epoch 40/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3696\n",
      "Epoch 41/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3691\n",
      "Epoch 42/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3691\n",
      "Epoch 43/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3685\n",
      "Epoch 44/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3674\n",
      "Epoch 45/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3666\n",
      "Epoch 46/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3666\n",
      "Epoch 47/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3668\n",
      "Epoch 48/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3660\n",
      "Epoch 49/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3659\n",
      "Epoch 50/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3646\n",
      "Epoch 51/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3653\n",
      "Epoch 52/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3652\n",
      "Epoch 53/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3654\n",
      "Epoch 54/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3647\n",
      "Epoch 55/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3654\n",
      "Epoch 00055: early stopping\n",
      "Train on 100000 samples\n",
      "Epoch 1/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.4153\n",
      "Epoch 2/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4100\n",
      "Epoch 3/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4050\n",
      "Epoch 4/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4030\n",
      "Epoch 5/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3992\n",
      "Epoch 6/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3957\n",
      "Epoch 7/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3967\n",
      "Epoch 8/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3925\n",
      "Epoch 9/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3938\n",
      "Epoch 10/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3913\n",
      "Epoch 11/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3914\n",
      "Epoch 12/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3869\n",
      "Epoch 13/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3859\n",
      "Epoch 14/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3864\n",
      "Epoch 15/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3856\n",
      "Epoch 16/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3830\n",
      "Epoch 17/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3835\n",
      "Epoch 18/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3828\n",
      "Epoch 19/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3834\n",
      "Epoch 20/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3803\n",
      "Epoch 21/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3810\n",
      "Epoch 22/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3794\n",
      "Epoch 23/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3776\n",
      "Epoch 24/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3785\n",
      "Epoch 25/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3774\n",
      "Epoch 26/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3770\n",
      "Epoch 27/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3785\n",
      "Epoch 28/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3756\n",
      "Epoch 29/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3749\n",
      "Epoch 30/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3754\n",
      "Epoch 31/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3747\n",
      "Epoch 32/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3740\n",
      "Epoch 33/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3736\n",
      "Epoch 34/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3734\n",
      "Epoch 35/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3730\n",
      "Epoch 36/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3728\n",
      "Epoch 37/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3739\n",
      "Epoch 38/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3703\n",
      "Epoch 39/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3704\n",
      "Epoch 40/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3725\n",
      "Epoch 41/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3728\n",
      "Epoch 42/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3711\n",
      "Epoch 43/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3699\n",
      "Epoch 44/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3717\n",
      "Epoch 45/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3710\n",
      "Epoch 46/5000\n",
      "100000/100000 [==============================] - 10s 95us/sample - loss: 0.3699\n",
      "Epoch 47/5000\n",
      "100000/100000 [==============================] - 10s 96us/sample - loss: 0.3694\n",
      "Epoch 48/5000\n",
      "100000/100000 [==============================] - 10s 96us/sample - loss: 0.3691\n",
      "Epoch 49/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3680\n",
      "Epoch 50/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3687\n",
      "Epoch 51/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3690\n",
      "Epoch 52/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3701\n",
      "Epoch 53/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3668\n",
      "Epoch 54/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3678\n",
      "Epoch 55/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3664\n",
      "Epoch 56/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3662\n",
      "Epoch 57/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3653\n",
      "Epoch 58/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3648\n",
      "Epoch 59/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3673\n",
      "Epoch 60/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3641\n",
      "Epoch 61/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3642\n",
      "Epoch 62/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3650\n",
      "Epoch 63/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3663\n",
      "Epoch 64/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3654\n",
      "Epoch 65/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3654\n",
      "Epoch 00065: early stopping\n",
      "Train on 100000 samples\n",
      "Epoch 1/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.4236\n",
      "Epoch 2/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4150\n",
      "Epoch 3/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4103\n",
      "Epoch 4/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4084\n",
      "Epoch 5/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.4019\n",
      "Epoch 6/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4005\n",
      "Epoch 7/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3970\n",
      "Epoch 8/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3959\n",
      "Epoch 9/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3957\n",
      "Epoch 10/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3921\n",
      "Epoch 11/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3907\n",
      "Epoch 12/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3895\n",
      "Epoch 13/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3906\n",
      "Epoch 14/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3887\n",
      "Epoch 15/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3891\n",
      "Epoch 16/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3912\n",
      "Epoch 17/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3832\n",
      "Epoch 18/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3872\n",
      "Epoch 19/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3840\n",
      "Epoch 20/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3841\n",
      "Epoch 21/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3838\n",
      "Epoch 22/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3824\n",
      "Epoch 23/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3828\n",
      "Epoch 24/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3803\n",
      "Epoch 25/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3830\n",
      "Epoch 26/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3781\n",
      "Epoch 27/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3804\n",
      "Epoch 28/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3835\n",
      "Epoch 29/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3794\n",
      "Epoch 30/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3801\n",
      "Epoch 31/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3766\n",
      "Epoch 32/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3783\n",
      "Epoch 33/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3786\n",
      "Epoch 34/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3757\n",
      "Epoch 35/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3759\n",
      "Epoch 36/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3778\n",
      "Epoch 37/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3741\n",
      "Epoch 38/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3764\n",
      "Epoch 39/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3762\n",
      "Epoch 40/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3780\n",
      "Epoch 41/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3771\n",
      "Epoch 42/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3753\n",
      "Epoch 00042: early stopping\n",
      "Train on 100000 samples\n",
      "Epoch 1/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4175\n",
      "Epoch 2/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4118\n",
      "Epoch 3/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4064\n",
      "Epoch 4/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4058\n",
      "Epoch 5/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4017\n",
      "Epoch 6/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.4041\n",
      "Epoch 7/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3977\n",
      "Epoch 8/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3960\n",
      "Epoch 9/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3947\n",
      "Epoch 10/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3935\n",
      "Epoch 11/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3942\n",
      "Epoch 12/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3920\n",
      "Epoch 13/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3931\n",
      "Epoch 14/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3917\n",
      "Epoch 15/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3884\n",
      "Epoch 16/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3896\n",
      "Epoch 17/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3854\n",
      "Epoch 18/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3862\n",
      "Epoch 19/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3883\n",
      "Epoch 20/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3833\n",
      "Epoch 21/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3863\n",
      "Epoch 22/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3823\n",
      "Epoch 23/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3824\n",
      "Epoch 24/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3839\n",
      "Epoch 25/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3861\n",
      "Epoch 26/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3814\n",
      "Epoch 27/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3824\n",
      "Epoch 28/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3842\n",
      "Epoch 29/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3829\n",
      "Epoch 30/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3797\n",
      "Epoch 31/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3826\n",
      "Epoch 32/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3805\n",
      "Epoch 33/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3814\n",
      "Epoch 34/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3791\n",
      "Epoch 35/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3795\n",
      "Epoch 36/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3787\n",
      "Epoch 37/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3794\n",
      "Epoch 38/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3771\n",
      "Epoch 39/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3767\n",
      "Epoch 40/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3765\n",
      "Epoch 41/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3763\n",
      "Epoch 42/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3759\n",
      "Epoch 43/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3780\n",
      "Epoch 44/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3770\n",
      "Epoch 45/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3733\n",
      "Epoch 46/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3792\n",
      "Epoch 47/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3771\n",
      "Epoch 48/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3775\n",
      "Epoch 49/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3772\n",
      "Epoch 50/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3779\n",
      "Epoch 00050: early stopping\n",
      "Train on 100000 samples\n",
      "Epoch 1/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.4193\n",
      "Epoch 2/5000\n",
      "100000/100000 [==============================] - 10s 95us/sample - loss: 0.4113\n",
      "Epoch 3/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.4076\n",
      "Epoch 4/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4053\n",
      "Epoch 5/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3988\n",
      "Epoch 6/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3983\n",
      "Epoch 7/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3963\n",
      "Epoch 8/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3962\n",
      "Epoch 9/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3932\n",
      "Epoch 10/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3959\n",
      "Epoch 11/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3925\n",
      "Epoch 12/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3891\n",
      "Epoch 13/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3892\n",
      "Epoch 14/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3894\n",
      "Epoch 15/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3852\n",
      "Epoch 16/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3870\n",
      "Epoch 17/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3844\n",
      "Epoch 18/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3878\n",
      "Epoch 19/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3857\n",
      "Epoch 20/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3835\n",
      "Epoch 21/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3868\n",
      "Epoch 22/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3806\n",
      "Epoch 23/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3880\n",
      "Epoch 24/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3868\n",
      "Epoch 25/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3852\n",
      "Epoch 26/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3789\n",
      "Epoch 27/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3825\n",
      "Epoch 28/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3789\n",
      "Epoch 29/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3778\n",
      "Epoch 30/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3797\n",
      "Epoch 31/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3779\n",
      "Epoch 32/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3760\n",
      "Epoch 33/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3801\n",
      "Epoch 34/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3786\n",
      "Epoch 35/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3781\n",
      "Epoch 36/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3786\n",
      "Epoch 37/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3780\n",
      "Epoch 00037: early stopping\n",
      "Train on 100000 samples\n",
      "Epoch 1/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4307\n",
      "Epoch 2/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4296\n",
      "Epoch 3/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4196\n",
      "Epoch 4/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4169\n",
      "Epoch 5/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.4171\n",
      "Epoch 6/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4116\n",
      "Epoch 7/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4072\n",
      "Epoch 8/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.4109\n",
      "Epoch 9/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.4060\n",
      "Epoch 10/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4030\n",
      "Epoch 11/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4027\n",
      "Epoch 12/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4026\n",
      "Epoch 13/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3979\n",
      "Epoch 14/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4026\n",
      "Epoch 15/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3977\n",
      "Epoch 16/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3986\n",
      "Epoch 17/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3955\n",
      "Epoch 18/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3955\n",
      "Epoch 19/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3972\n",
      "Epoch 20/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3937\n",
      "Epoch 21/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3907\n",
      "Epoch 22/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3922\n",
      "Epoch 23/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3965\n",
      "Epoch 24/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3931\n",
      "Epoch 25/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3918\n",
      "Epoch 26/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3923\n",
      "Epoch 00026: early stopping\n"
     ]
    }
   ],
   "source": [
    "early_stopping =  tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5, min_delta=0,\n",
    "                                                         verbose=1)\n",
    "for _ in range(10):\n",
    "    person_1 = []\n",
    "    person_2 = []\n",
    "    y_true = []\n",
    "    for i in range(100000):\n",
    "        person_idx = np.random.randint(embs_anchor_train.shape[0])\n",
    "        person_1.append(embs_anchor_train[person_idx])\n",
    "        \n",
    "        if random.random()>.5: # same person\n",
    "            person_2.append(embs_pos_train[person_idx])\n",
    "            y_true.append(1)\n",
    "        else: # different person\n",
    "            person_2.append(embs_neg_train[person_idx])\n",
    "            y_true.append(0)\n",
    "\n",
    "    pred_model.fit([np.array(person_1), np.array(person_2)], np.array(y_true), \n",
    "                   epochs=5000, callbacks=[early_stopping])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.38\n"
     ]
    }
   ],
   "source": [
    "person_1 = []\n",
    "person_2 = []\n",
    "y_true = []\n",
    "for i in range(10000):\n",
    "    person_idx = np.random.randint(embs_anchor_val.shape[0])\n",
    "    person_1.append(embs_anchor_val[person_idx])\n",
    "\n",
    "    if random.random()>.5: # same person\n",
    "        person_2.append(embs_pos_val[person_idx])\n",
    "        y_true.append(1)\n",
    "    else: # different person\n",
    "        person_2.append(embs_neg_val[person_idx])\n",
    "        y_true.append(0)\n",
    "\n",
    "y_pred = (pred_model.predict([np.array(person_1), np.array(person_2)]) > .5).flatten()\n",
    "y_true = np.array(y_true) > .5\n",
    "accuracy = np.sum(y_pred==y_true)/len(y_true)*100\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model.save('pred_model.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "AMMD2 - Siamesas 01.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
