{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tqdm==4.28.1\n",
    "# !pip install -U gast==0.2.2\n",
    "# !pip install gdown\n",
    "\n",
    "# !gdown https://drive.google.com/uc?id=14CB3Vw4jPf-8-DAriB9XDq4mfbs4o747\n",
    "# !mkdir datasets\n",
    "# !tar -C datasets -xzf airport-alunos.tgz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "4.28.1\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf; print(tf.__version__)\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_sample_image;\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tqdm; print(tqdm.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "USM43pOIGCw2",
    "outputId": "0c9ddb6e-2d96-4ae8-a360-cdd3ccd5c200"
   },
   "outputs": [],
   "source": [
    "def scatter(x, labels, subtitle='None'):\n",
    "    # We choose a color palette with seaborn.\n",
    "    palette_size = len(np.unique(labels))\n",
    "    palette = np.array(sns.color_palette(\"hls\", palette_size))\n",
    "    \n",
    "    color_map = dict({})\n",
    "    color_count = 0\n",
    "    for l in labels:\n",
    "        if l not in color_map:\n",
    "            color_map[l] = color_count\n",
    "            color_count = color_count + 1\n",
    "    \n",
    "    def get_color_idx(label):\n",
    "        return color_map[label]\n",
    "        \n",
    "    def get_colores_idx(labels_):\n",
    "        return np.array([get_color_idx(l) for l in labels_])\n",
    "        \n",
    "    # We create a scatter plot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40,\n",
    "                    c=palette[get_colores_idx(labels)])\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "\n",
    "    # We add the labels for each digit.\n",
    "    txts = []\n",
    "    for l, i in zip(labels, range(len(labels))):\n",
    "        # Position of each label.\n",
    "        xtext, ytext = np.median(x[labels == l, :], axis=0)\n",
    "        txt = ax.text(xtext, ytext, labels[i], fontsize=16, \n",
    "                      color = palette[get_color_idx(l)]) #, bbox=dict(alpha=0.5))\n",
    "        txt.set_path_effects([\n",
    "            PathEffects.Stroke(linewidth=5, foreground=\"yellow\"),\n",
    "            PathEffects.Normal()])\n",
    "        txts.append(txt)\n",
    "        \n",
    "    if subtitle != None:\n",
    "        plt.suptitle(subtitle)\n",
    "        \n",
    "    plt.savefig(subtitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_model(input_shape):\n",
    "    input_layer = Input(shape = input_shape)\n",
    "    \n",
    "    model = Conv2D(8, (3, 3), activation = None, padding='same')(input_layer)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "    model = Conv2D(16, (3, 3), activation = None, padding='same')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "    model = Conv2D(32, (3, 3), activation = None, padding='same')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "    model = Conv2D(64, (3, 3), activation = None, padding='same')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D((2, 2))(model)\n",
    "    \n",
    "    model = Flatten()(model)\n",
    "    model = Dense(64, activation='relu')(model)\n",
    "    model = Lambda(lambda inp: K.l2_normalize(inp, axis=-1))(model)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=model)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_autoencoder(input_shape):\n",
    "    input_layer = Input(shape = input_shape)\n",
    "    \n",
    "    model = Dense(64, activation='relu')(input_layer)\n",
    "    model = Dense(32, activation='relu')(model)\n",
    "    model = Dense(16, activation='relu')(model)\n",
    "    model = Dense(32, activation='relu')(model)\n",
    "    model = Dense(64, activation='relu')(model)\n",
    "    model = Lambda(lambda inp: K.l2_normalize(inp, axis=-1))(model)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=model)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "class TripletLossLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(TripletLossLayer, self).__init__()\n",
    "    \n",
    "    def euclidean_distance(self, vects):\n",
    "        x, y = vects\n",
    "        x = tf.cast(x, 'float32')\n",
    "        y = tf.cast(y, 'float32')\n",
    "\n",
    "        return K.mean(K.sum(K.square(x-y),axis=1))\n",
    "    \n",
    "    def call(self, inputs=None):\n",
    "        #     Calcule triplet loss \n",
    "        #     loss = max(dist(a, p) - dist(a, n) + margin, 0)\n",
    "        self.margin = tf.constant(0.4 , dtype='float32')\n",
    "        a, p, n = inputs\n",
    "        a = tf.cast(a, 'float32')\n",
    "        p = tf.cast(p, 'float32')\n",
    "        n = tf.cast(n, 'float32')\n",
    "        \n",
    "        # Calcule triplet loss \n",
    "        subt_ = tf.subtract(self.euclidean_distance([a, p]) , self.euclidean_distance([a, n]))\n",
    "        sum_ = tf.add(subt_, self.margin)\n",
    "        \n",
    "        loss = K.maximum(sum_, 0.0)\n",
    "        # add in model loss\n",
    "        self.add_loss(loss)\n",
    "    \n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "\n",
    "# input_shape = (28, 28, 1)\n",
    "input_shape = (128, 64, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "oeSbaC8eGCw9",
    "outputId": "d0544b8b-1e33-4c06-8327-36bc58211ca6"
   },
   "outputs": [],
   "source": [
    "base_network_s1 = create_base_model(input_shape)\n",
    "\n",
    "input_anchor = Input(shape=input_shape)\n",
    "input_positive = Input(shape=input_shape)\n",
    "input_negative = Input(shape=input_shape)\n",
    "\n",
    "processed_a = base_network_s1(input_anchor)\n",
    "processed_p = base_network_s1(input_positive)\n",
    "processed_n = base_network_s1(input_negative)\n",
    "\n",
    "loss_layer_s1 = TripletLossLayer()([processed_a, processed_p, processed_n])\n",
    "\n",
    "s1 = Model([input_anchor, input_positive, input_negative], loss_layer_s1)\n",
    "\n",
    "s1.compile(optimizer=adam, loss=(lambda y_true, ypred: 0.0))\n",
    "\n",
    "s1_embs_model = base_network_s1\n",
    "s1_embs_model.compile(loss=(lambda y_true, ypred: 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_network_s2 = create_base_model(input_shape)\n",
    "autoencoder_s2 = create_autoencoder((64,))\n",
    "\n",
    "d = Dense(64, activation='relu')(base_network_s2.output)\n",
    "middle_model_s2 = Model(base_network_s2.input, d)\n",
    "\n",
    "connect = autoencoder_s2(middle_model_s2.output)\n",
    "middle_model_s2 = Model(base_network_s2.input, connect)\n",
    "\n",
    "input_anchor_s2 = Input(shape=input_shape)\n",
    "input_positive_s2 = Input(shape=input_shape)\n",
    "input_negative_s2 = Input(shape=input_shape)\n",
    "\n",
    "processed_a_s2 = middle_model_s2(input_anchor_s2)\n",
    "processed_p_s2 = middle_model_s2(input_positive_s2)\n",
    "processed_n_s2 = middle_model_s2(input_negative_s2)\n",
    "\n",
    "loss_layer_s2 = TripletLossLayer()([processed_a_s2, processed_p_s2, processed_n_s2])\n",
    "\n",
    "s2 = Model([input_anchor_s2, input_positive_s2, input_negative_s2], \n",
    "           loss_layer_s2)\n",
    "s2.compile(optimizer=adam, loss=(lambda y_true, ypred: 0.0))\n",
    "\n",
    "s2_embs_model = base_network_s2\n",
    "s2_embs_model.compile(loss=(lambda y_true, ypred: 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_network_s3 = create_base_model(input_shape)\n",
    "autoencoder_s3 = create_autoencoder((64,))\n",
    "\n",
    "d = Dense(64, activation='relu')(base_network_s3.output)\n",
    "middle_model_s3 = Model(base_network_s3.input, d)\n",
    "\n",
    "connect3 = autoencoder_s3(middle_model_s3.output)\n",
    "middle_model_s3 = Model(base_network_s3.input, connect3)\n",
    "\n",
    "input_anchor_s3 = Input(shape=input_shape)\n",
    "input_positive_s3 = Input(shape=input_shape)\n",
    "input_negative_s3 = Input(shape=input_shape)\n",
    "\n",
    "processed_a_s3 = middle_model_s3(input_anchor_s3)\n",
    "processed_p_s3 = middle_model_s3(input_positive_s3)\n",
    "processed_n_s3 = middle_model_s3(input_negative_s3)\n",
    "\n",
    "loss_layer_s3 = TripletLossLayer()([processed_a_s3, processed_p_s3, processed_n_s3])\n",
    "\n",
    "s3 = Model([input_anchor_s3, input_positive_s3, input_negative_s3], \n",
    "           loss_layer_s3)\n",
    "s3.compile(optimizer=adam, loss=(lambda y_true, ypred: 0.0))\n",
    "\n",
    "s3_embs_model = base_network_s3\n",
    "s3_embs_model.compile(loss=(lambda y_true, ypred: 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v3b_n2GaP-3H"
   },
   "source": [
    "## Experiments with MNIST (IGNORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data(path='mnist.npz')\n",
    "x_train = x_train.reshape((60000, 28, 28, 1)).astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show TSNE Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "embs = embs_model.predict(x_train[:512])\n",
    "labels = y_train[:512]\n",
    "embs_2d = TSNE().fit_transform(embs)\n",
    "scatter(embs_2d, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hc66zI_QGCxB"
   },
   "outputs": [],
   "source": [
    "def create_triplets(num_batches, batch_size):\n",
    "    for _ in range(num_batches):\n",
    "#     while True:\n",
    "        batch = []\n",
    "        clazz = []\n",
    "        for _ in range(batch_size):\n",
    "            grps_number = [1, 2, 3, 4, 5 ,6, 7, 8, 9, 0]\n",
    "            \n",
    "            grp = random.choice(grps_number)\n",
    "            grps_number.remove(grp)\n",
    "            img_a = x_train[y_train==grp][np.random.randint(x_train[y_train==grp].shape[0])]\n",
    "            img_p = x_train[y_train==grp][np.random.randint(x_train[y_train==grp].shape[0])]\n",
    "            \n",
    "            grp_2 = random.choice(grps_number)\n",
    "            img_n = x_train[y_train==grp_2][np.random.randint(x_train[y_train==grp_2].shape[0])]\n",
    "            \n",
    "            batch.append([img_a, img_p, img_n])\n",
    "        out = np.array(batch)\n",
    "        yield [out[:, i] for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "for inp_ in create_triplets(3000, 4):\n",
    "    print(np.array(inp_).shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 3, 128, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(X_train).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 8s 249ms/sample - loss: 0.7618 - val_loss: 0.0376\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0555\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0522\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.3959 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 4s 132ms/sample - loss: 0.7998 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1213 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 4s 120ms/sample - loss: 0.3601 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0108\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.4273 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 4s 114ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0720 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 4s 119ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 9ms/sample - loss: 0.3782 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3956 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.4401\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1136 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1287 - val_loss: 0.7262\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2024 - val_loss: 0.6795\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.7367\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.7894\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 10ms/sample - loss: 0.0000e+00 - val_loss: 0.8299\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.8726\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.9015\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2075\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1164 - val_loss: 0.4035\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1649 - val_loss: 0.5691\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.5432\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1659 - val_loss: 0.6810\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.6807\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1417 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0987 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.5486 - val_loss: 0.4764\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.4944\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.5031\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.4938\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.4853\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1365 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1362 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0112 - val_loss: 0.5114\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2660 - val_loss: 0.3214\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0781 - val_loss: 0.1641\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1167\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0753\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0559\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0335\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0435\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0521\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0590\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0671\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2741 - val_loss: 0.0156\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0193\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0176\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0289\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0261\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0268\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3799 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0560 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.7537\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.6801\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.6342\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.5901\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.5604\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.5341\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2685 - val_loss: 0.0764\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0606\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0429\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0273\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0104\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0023\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.5707 - val_loss: 0.0000e+00\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.7027 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.4655 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2477 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2799 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0324 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0951 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0152 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0148 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0021 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.5258 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0507 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2760 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0394 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0718\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0540\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0491\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.7576 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2950\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3177\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3388\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3528\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3714\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3866\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1267\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1432 - val_loss: 0.1867\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1576\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1322\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1114\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0959\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0809\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0721\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0661\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0643\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0571\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0527\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0527\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0491\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0490\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0454\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0444\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0464\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0458\n",
      "Epoch 20/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0452\n",
      "Epoch 21/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0427\n",
      "Epoch 22/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0436\n",
      "Epoch 23/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0440\n",
      "Epoch 24/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0432\n",
      "Epoch 25/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0402\n",
      "Epoch 26/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0405\n",
      "Epoch 27/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0388\n",
      "Epoch 28/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0395\n",
      "Epoch 29/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0401\n",
      "Epoch 30/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0386\n",
      "Epoch 31/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1614 - val_loss: 0.0040\n",
      "Epoch 32/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0267\n",
      "Epoch 33/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0445\n",
      "Epoch 34/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0593\n",
      "Epoch 35/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0683\n",
      "Epoch 36/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0808\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0983 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0708 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0037\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3329 - val_loss: 0.1730\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1909\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2046\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2147\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2240\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1435 - val_loss: 0.0879\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0232 - val_loss: 0.1909\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1862\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1875\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1850\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1782\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.6773 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1438\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1083 - val_loss: 0.2949\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1652 - val_loss: 0.1755\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1829\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1909\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1960\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2139 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0922 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0651 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1446 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0203 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1626 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1793 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0761 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.6268 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.5523 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3733 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 15ms/sample - loss: 0.0000e+00 - val_loss: 0.0771\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0746\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0687\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0706\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0670\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0667\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0508 - val_loss: 0.0000e+00\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0024\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0038\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0053\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0347\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0472\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0556\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0626\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0689\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1557 - val_loss: 0.0612\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0425 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0657 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.6399 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0342 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3070 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0308 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3527 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0153 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3355 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0868 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0112 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0444 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0038 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.5580 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1587 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2699 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1219\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1222\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1225\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1177\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1175 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.7430 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0599 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0131 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1976 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1547 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0072 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0863 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0211 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0608 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0443 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0258 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1618 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2381 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3272 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.7296 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2629 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3747 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2696\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2614\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.3572 - val_loss: 0.4381\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.4329\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.4291\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0519 - val_loss: 0.1732\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1692\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1690\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1673\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1664\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1656\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1639\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1627\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1623\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1617\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1634\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1639\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1635\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1645\n",
      "Epoch 20/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1634\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2028 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1652 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2857 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0933 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0852\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0807\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0776\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0775\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0772\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0759\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0748\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0726\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0706\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0706\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0685\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0690\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0691\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0686\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0690\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0673\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0394 - val_loss: 0.0000e+00\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0883 - val_loss: 0.0000e+00\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 20/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 21/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 22/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1048\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1101\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1137\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1185\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1213\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1231\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1892 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0372\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0349\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0367\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0397\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0377\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0396\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0413\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1371 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1526 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0543 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.5762 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0559 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 13ms/sample - loss: 0.0000e+00 - val_loss: 0.1562\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1526\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0427 - val_loss: 0.1466\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1530\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1564\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1585\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1618\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1648\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3828\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3826\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3837\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3875\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3897\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3934\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3952\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0057\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0136\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0219\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 6.4691e-04 - val_loss: 0.2938\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3287\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3624\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2373 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1624 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0234 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0655 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0858 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1425 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1589 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1255 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0852\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0807\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0773\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0740\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0694\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0688\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0635\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0593\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0579\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0562\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0575\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0548\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0540\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0522\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0520\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0489\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0488\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0483\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1281 - val_loss: 0.0000e+00\n",
      "Epoch 20/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 21/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 22/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 23/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 24/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1131 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1185 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0376 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0244 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0666 - val_loss: 0.1930\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1869\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0616 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1190 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2598 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2615 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0125 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0734 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0405 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.3232 - val_loss: 0.2307\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2121\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1915\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1788\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1707\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1634\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1621\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.1554\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1516\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1492\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1486\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1474\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1469\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1456\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1448\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1445\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1445\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1427\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1418\n",
      "Epoch 20/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1405\n",
      "Epoch 21/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1413\n",
      "Epoch 22/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1406\n",
      "Epoch 23/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1414\n",
      "Epoch 24/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1406\n",
      "Epoch 25/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1405\n",
      "Epoch 26/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1420\n",
      "Epoch 27/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1423\n",
      "Epoch 28/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1422\n",
      "Epoch 29/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1399\n",
      "Epoch 30/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1401\n",
      "Epoch 31/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1397\n",
      "Epoch 32/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1395\n",
      "Epoch 33/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1400\n",
      "Epoch 34/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1401\n",
      "Epoch 35/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1403\n",
      "Epoch 36/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1410\n",
      "Epoch 37/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1407\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 2s 63ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 9ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0254\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0205\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0190\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0168\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0151\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0126\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0127\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0114\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0122\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0105\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0102\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0324 - val_loss: 0.0000e+00\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1106 - val_loss: 0.3391\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3435\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3446\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3429\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3417\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0257\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0262\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0255\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0256\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0250\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0246\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0018 - val_loss: 0.0725\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0724\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0715\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0701\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0683\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 1s 38ms/sample - loss: 0.0000e+00 - val_loss: 0.0320\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0348\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0361\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0381\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0396\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0400\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2088 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0903 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1845 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1222\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1238\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 1s 28ms/sample - loss: 0.0000e+00 - val_loss: 0.1210\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.1177\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1205\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1190\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1176\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1155\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1162\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1152\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1131\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1131\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1137\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1096\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1129\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1168\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1182\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1136\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1158\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0316 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2670 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0216 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0930\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0957\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0210 - val_loss: 0.3506\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3533\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3566\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3577\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2475 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0382 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0131 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.5350 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1163 - val_loss: 0.0920\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1054\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1138\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1136\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1125\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1090\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0527\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0611\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0647\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0677\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0708\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0740\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.1878 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3711 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.4112 - val_loss: 0.0996\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0938\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0869\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0773\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0678\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.4167 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0098 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2225 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0836 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0093\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0117\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2334 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0519 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2518 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.3325\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3277\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3221\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3188\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.3172\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3154\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3134\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3114\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3104\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3087\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3069\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3052\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3045\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.3037\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3030\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3034\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3037\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3047\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3046\n",
      "Epoch 20/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3060\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0472\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0501\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0516\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0545\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0561\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1063 - val_loss: 0.0000e+00\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0085 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1061 - val_loss: 0.0382\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0458\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0504\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0551\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0601\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0623\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3366\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3420\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3463\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3503\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3550\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3581\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.3284 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1572 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0509 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0096 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1536 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 9ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.2965\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2912\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2898\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2890\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2865\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2852\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2824\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2780\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2770\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1096 - val_loss: 0.3404\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3368\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3307\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3270\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3215\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1811 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0540 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0410 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3734\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.3627 - val_loss: 0.1306\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1580\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1793\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1951\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2015\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2075\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0799 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2833 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.4813 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0309 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0219 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0744 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3730 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 12ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0268\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0302\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0342\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0359\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0364\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0372\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0131 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0351 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1458 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.4776 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3002\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2949\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2899\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2856\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2828\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2808\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2798\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2780\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2773\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2767\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2761\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2753\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2772\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2765\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2763\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2753\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2751\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2752\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2750\n",
      "Epoch 20/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2741\n",
      "Epoch 21/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2752\n",
      "Epoch 22/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2749\n",
      "Epoch 23/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2747\n",
      "Epoch 24/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2741\n",
      "Epoch 25/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2733\n",
      "Epoch 26/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2721\n",
      "Epoch 27/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2727\n",
      "Epoch 28/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2730\n",
      "Epoch 29/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2733\n",
      "Epoch 30/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2743\n",
      "Epoch 31/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2750\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0712 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0561 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.3378 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1133 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.5004 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3385 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1753 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1930 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0624\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0543\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0169 - val_loss: 0.3568\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3497\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3454\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3441\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3432\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1596 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0236 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0594 - val_loss: 0.0804\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.4096 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2309 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0113 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1797 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1165\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1151\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1131\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1118\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1117\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1105\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1103\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1094\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1103\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1102\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1106\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1108\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1104\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0921 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0950\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0987\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1023\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1055\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1083\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1123\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0801 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 12ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0107 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2159 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3385\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3381\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3366\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3360\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3350\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3350\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3379\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3387\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3370\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3413\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1642 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0862 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3482\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0784 - val_loss: 0.2676\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3030\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3254\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3577\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3832\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3939\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0302 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1810\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1848\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1882\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2136 - val_loss: 0.1415\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1439\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1474\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1497\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0407 - val_loss: 0.2031\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2011\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1653 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0241 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0239\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0228\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0205\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0206\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0212\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0205\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0216\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0469 - val_loss: 0.0274\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0303\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0309\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0302\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3372\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3354\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3342\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3294\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3343\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3389\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3347\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3343\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3325\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2229\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2105\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2017\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1958\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1915\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1867\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1840\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1799\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1765\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1769\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1743\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.1731\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1742\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1726\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1738\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1734\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1749\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1729\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1728\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1877 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 10ms/sample - loss: 0.0000e+00 - val_loss: 0.0066\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0089\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1897 - val_loss: 0.0352\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0380\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0391\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0383\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3033 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0020\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0055\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0098\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0123\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3402 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 1s 29ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2191 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1105 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1739\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1735\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1728\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1727\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1744\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1763\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1765\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1762\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1741\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3993 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0410 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2337 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0887 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0014\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0014\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0024\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.3727 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0340 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2432\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2418\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2424\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2476\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2522\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2593\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2576\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 9ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2440 - val_loss: 0.0932\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1038\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1142\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1219\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0064\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0050\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0021\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 5.5524e-04\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2149 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2230 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0555 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1751\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1763\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1767\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1750\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1749\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1732\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.1754\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1760\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1752\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1742\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1764\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 1s 37ms/sample - loss: 0.0000e+00 - val_loss: 0.0280\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0285\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0283\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0284\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0289\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0285\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0334 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0360 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0997 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 11ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2322\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2335\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2357\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2363\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2382\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2384\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2956 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1913 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0960 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0694 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2307 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2115 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0142\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0247\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0338\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0405\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0059 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0021\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0029\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0040\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0029\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0024\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0502 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.4352 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0072 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0194 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1815 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0460 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0629 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0440 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.7168\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.7196\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.7242\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.7260\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.7282\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.7270\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0225\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0132 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0213 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 3s 101ms/sample - loss: 0.0197 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.4743 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0281 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.1684 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1994 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2922 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0143\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0162\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0164\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0178\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0189\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0185\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1657 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0130\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0147\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0158\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0176\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0178\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0190\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0549 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3728 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1672 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2624\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2583\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2555\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2129 - val_loss: 0.4113\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.4058\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3987\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.3954\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3909\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0893\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0884\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0891\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0891\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0867\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0854\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0850\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0828\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0846\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0809\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0797\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0810\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0836\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0995 - val_loss: 0.4063\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.4164\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.4242\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1769 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1289 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0707 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1519 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0656 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1729 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1035 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.4244 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.1297 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0479 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3453 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0891 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0263 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2580 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0064 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1256 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2222\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2105\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2030\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1979\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1947\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1898\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1870\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1862\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1850\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1854\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1833\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1824\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1804\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1809\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1791\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1772\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1771\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1780\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1776\n",
      "Epoch 20/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1787\n",
      "Epoch 21/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1789\n",
      "Epoch 22/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1768\n",
      "Epoch 23/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1750\n",
      "Epoch 24/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1761\n",
      "Epoch 25/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1766\n",
      "Epoch 26/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1770\n",
      "Epoch 27/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1763\n",
      "Epoch 28/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1760\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1439 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3428 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1165 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 6.7037e-04 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 2s 68ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 13ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1579 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1201 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0575 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.4913 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0553 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0182 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0496\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0276 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0222 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1502 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0528 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2081\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2124\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2159\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2172\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.2203\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.2222\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1781 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0803 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0395 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0332 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2494 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 3.3459e-04 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0417\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.4047 - val_loss: 0.0433\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0330\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0226\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0121\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0031\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0552 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2919 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1327 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2906 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0759 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0476 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.2525 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0666 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0497 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0892 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1379 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0589 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 1s 32ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1681 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1783\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1759\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1779\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1755\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1760\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1758\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1785\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0555 - val_loss: 0.0000e+00\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0249 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 3s 86ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1157 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.1745 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1022 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1518 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.7418 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 1s 40ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.2219 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0888 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0011 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1261 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0275 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0045 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0603 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1332\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1323\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1307\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1288\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1270\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1279\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1276\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1284\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1285\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1283\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0836 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1163 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1624 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0505 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1131 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1674 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0653\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0670\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0660\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0657\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0659\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0663\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.2446 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 4s 124ms/sample - loss: 0.2201 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 10ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.3369 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0856 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3302 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0036 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1874 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 1s 26ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0515 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0525\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0525\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0525\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0529\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0528\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0530\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2512 - val_loss: 0.0000e+00\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1812 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0499 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 4s 125ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 3s 97ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 2s 74ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0578 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0744 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0946 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0109 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1545\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1532\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1554\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1530\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1557\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1592\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1564\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.1585\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1537\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0633 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.6201 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1665 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 1s 25ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1091 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 3.3882e-04 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0729\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0750\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0750\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0751\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0766\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0757\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0889 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0212 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0241 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1169 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1175 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0156 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0650 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0727 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1437 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1598 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0908 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1102 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0222 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.3105 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.1153 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0789 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0481 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0842 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0139 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0429 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.4043\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.4053\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.4069\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.4076\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.4075\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.4096\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2582 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1555 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0267\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0289\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0297\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0300\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0293\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0302\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1582 - val_loss: 0.0900\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0893\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0907\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1223 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0069\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0064\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0066\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0065\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0071\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0086\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0089\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1176 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0802 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0261 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.4507 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0093\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0119\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0131\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0140\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0149\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0153\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.3341 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.3156 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 11ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0531 - val_loss: 0.0140\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.4909 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.3800\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3829\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3842\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3902\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3936\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.3956\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1768 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1405 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0221\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0249\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0262\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0274\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0286\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0300\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 1s 26ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0981\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0968\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0949\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0937\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0933\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0955\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0933\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0913\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0900\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0917\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0912\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0898\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0898\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0896\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0868\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0873\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0860\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0843\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0843\n",
      "Epoch 20/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0867\n",
      "Epoch 21/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0884\n",
      "Epoch 22/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0880\n",
      "Epoch 23/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0894\n",
      "Epoch 24/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0887\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0186 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 9ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1123 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.1650\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.1640\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1627\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1625\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1627\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1624\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.1609\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1609\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1611\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.1629\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1607\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1606\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.1599\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.1583\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1578\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0755 - val_loss: 0.0320\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0319\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0320\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0315\n",
      "Epoch 20/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0321\n",
      "Epoch 21/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0310\n",
      "Epoch 22/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0321\n",
      "Epoch 23/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.2223 - val_loss: 0.0811\n",
      "Epoch 24/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0839\n",
      "Epoch 25/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0866\n",
      "Epoch 26/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0895\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0805\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0765\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0739\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0715\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0696\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0685\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0668\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0648\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0637\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0650\n",
      "Epoch 11/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0641\n",
      "Epoch 12/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0634\n",
      "Epoch 13/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0628\n",
      "Epoch 14/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0632\n",
      "Epoch 15/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0626\n",
      "Epoch 16/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0623\n",
      "Epoch 17/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0522 - val_loss: 0.0511\n",
      "Epoch 18/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0530\n",
      "Epoch 19/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0491\n",
      "Epoch 20/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0444\n",
      "Epoch 21/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0408\n",
      "Epoch 22/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0381\n",
      "Epoch 23/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0369\n",
      "Epoch 24/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0360\n",
      "Epoch 25/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0352\n",
      "Epoch 26/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0341\n",
      "Epoch 27/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0340\n",
      "Epoch 28/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0331\n",
      "Epoch 29/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0322\n",
      "Epoch 30/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0320\n",
      "Epoch 31/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0313\n",
      "Epoch 32/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0314\n",
      "Epoch 33/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0312\n",
      "Epoch 34/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0308\n",
      "Epoch 35/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0304\n",
      "Epoch 36/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0300\n",
      "Epoch 37/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0299\n",
      "Epoch 38/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0308\n",
      "Epoch 39/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0306\n",
      "Epoch 40/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0305\n",
      "Epoch 41/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0325\n",
      "Epoch 42/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0321\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.3456\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3435\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.3452\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3447\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3427\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.3442\n",
      "Epoch 7/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.3431\n",
      "Epoch 8/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.3439\n",
      "Epoch 9/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.3440\n",
      "Epoch 10/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.3454\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.3195 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0164 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0051 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0131 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0058 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0386 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 10ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2590 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 2s 74ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 2s 63ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 15ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1292\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1303+0\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1314\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1331\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.1364\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.1373\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0581\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0589\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0593\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0588\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0591\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0587\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0444 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0495 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.3019 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.3923 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.2420 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0157 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.1873 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0576 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 7ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 8ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 10ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0180 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0850 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.1207 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0160 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.3173 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.7814 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 5ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Train on 32 samples, validate on 32 samples\n",
      "Epoch 1/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/1000000\n",
      "32/32 [==============================] - 0s 6ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/1000000\n",
      "32/32 [==============================] - 0s 3ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/1000000\n",
      "32/32 [==============================] - 0s 4ms/sample - loss: 0.0000e+00 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3f8546649308>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                          verbose=0, restore_best_weights=True)\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0minp_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcreate_triplets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-36a5968630f6>\u001b[0m in \u001b[0;36mcreate_triplets\u001b[0;34m(num_batches, batch_size)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mgrp_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrps_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mimg_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mgrp_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mgrp_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_n\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "y_true = np.array([[0.0 for _ in range(64)] for _ in range(batch_size)])\n",
    "\n",
    "\n",
    "early_stopping =  tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, min_delta=0,\n",
    "                                                         verbose=0, restore_best_weights=True)\n",
    "\n",
    "for inp_ in create_triplets(3000, batch_size):\n",
    "    model.fit(inp_ , y_true, batch_size=5, epochs=1000000, callbacks=[early_stopping], shuffle=True, validation_split=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show TSNE After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "embs = embs_model.predict(x_train[:512])\n",
    "labels = y_train[:512]\n",
    "embs_2d = TSNE().fit_transform(embs)\n",
    "scatter(embs_2d, labels, subtitle=\"After-training3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments With Real Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tripplet_data import *\n",
    "\n",
    "def map_person_to_filepaths(folder='treino'):\n",
    "    path = 'datasets/airport-alunos/' + folder + '/'\n",
    "    images_per_person = {}\n",
    "    \n",
    "    for i in range(2):\n",
    "        for (person, person_path) in map_person_files(path + str(i) +'/').items():\n",
    "            for pp in person_path:\n",
    "                if person not in images_per_person:\n",
    "                    images_per_person[person] = []\n",
    "\n",
    "                for img in list_person_files(pp):\n",
    "                    images_per_person[person].append(pp + img)\n",
    "            \n",
    "    return images_per_person \n",
    "\n",
    "def create_embeddings(map_files, embs_model, debbug=False):\n",
    "    embeddings_per_person = {}\n",
    "    images_per_person = {}\n",
    "\n",
    "    total = len(map_files)\n",
    "    count = 1\n",
    "    for (person, images_path) in map_files.items():\n",
    "        np_images = []\n",
    "        for ip in images_path:\n",
    "            np_image = img_to_array(load_img(ip))\n",
    "            np_images.append(np_image)\n",
    "        \n",
    "        if debbug:\n",
    "            print(\"(\" + str(count)+ \"/\" + str(total) +\") predicting to person \"+ person)\n",
    "            \n",
    "        count = count + 1\n",
    "        embs_output = embs_model.predict(np.array(np_images))\n",
    "        \n",
    "        images_per_person[person] = np_images\n",
    "        embeddings_per_person[person] = embs_output\n",
    "    \n",
    "    return embeddings_per_person, images_per_person\n",
    "\n",
    "\n",
    "def create_triplets(number_of_triples, embeddings_map, images_map):\n",
    "    while True:\n",
    "        def get_distance(emb1, emb2):\n",
    "            return np.sqrt(np.sum(np.power((emb1 - emb2), 2)))\n",
    "        persons = np.array([name for (name, _) in embeddings_map.items()])\n",
    "\n",
    "        anchors = np.zeros(shape=(0,128, 64, 3))\n",
    "        positives = np.zeros(shape=(0,128, 64, 3))\n",
    "        negatives = np.zeros(shape=(0,128, 64, 3))\n",
    "\n",
    "        for _ in range(number_of_triples):\n",
    "            anchor_person = random.choice(persons)\n",
    "            neg_person = anchor_person\n",
    "            while anchor_person == neg_person:\n",
    "                neg_person = random.choice(persons)\n",
    "\n",
    "            anchor_idx = np.random.randint(len(embeddings_map[anchor_person]))\n",
    "            anchor_emb = embeddings_map[anchor_person][anchor_idx]\n",
    "            anchor_img = images_map[anchor_person][anchor_idx]\n",
    "\n",
    "            # Select the farthest on as positive\n",
    "            positive_img = random.choice(images_map[anchor_person])\n",
    "\n",
    "            # Select the nearst on as negative\n",
    "            negative_img = random.choice(images_map[neg_person])\n",
    "\n",
    "            anchors = np.append( anchors,  np.expand_dims(anchor_img, axis=0), axis=0)\n",
    "            positives = np.append( positives,  np.expand_dims(positive_img, axis=0), axis=0)\n",
    "            negatives = np.append( negatives,  np.expand_dims(negative_img, axis=0), axis=0)\n",
    "\n",
    "        y_true = np.array([[0.0 for _ in range(64)] for _ in range(number_of_triples)])\n",
    "\n",
    "        yield [anchors, positives, negatives], y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show TSNE Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/50) predicting to person 235\n",
      "(2/50) predicting to person 207\n",
      "(3/50) predicting to person 230\n",
      "(4/50) predicting to person 237\n",
      "(5/50) predicting to person 247\n",
      "(6/50) predicting to person 228\n",
      "(7/50) predicting to person 210\n",
      "(8/50) predicting to person 222\n",
      "(9/50) predicting to person 227\n",
      "(10/50) predicting to person 206\n",
      "(11/50) predicting to person 249\n",
      "(12/50) predicting to person 244\n",
      "(13/50) predicting to person 202\n",
      "(14/50) predicting to person 205\n",
      "(15/50) predicting to person 232\n",
      "(16/50) predicting to person 239\n",
      "(17/50) predicting to person 203\n",
      "(18/50) predicting to person 214\n",
      "(19/50) predicting to person 231\n",
      "(20/50) predicting to person 240\n",
      "(21/50) predicting to person 246\n",
      "(22/50) predicting to person 213\n",
      "(23/50) predicting to person 223\n",
      "(24/50) predicting to person 234\n",
      "(25/50) predicting to person 248\n",
      "(26/50) predicting to person 229\n",
      "(27/50) predicting to person 209\n",
      "(28/50) predicting to person 221\n",
      "(29/50) predicting to person 200\n",
      "(30/50) predicting to person 242\n",
      "(31/50) predicting to person 212\n",
      "(32/50) predicting to person 201\n",
      "(33/50) predicting to person 233\n",
      "(34/50) predicting to person 204\n",
      "(35/50) predicting to person 217\n",
      "(36/50) predicting to person 224\n",
      "(37/50) predicting to person 219\n",
      "(38/50) predicting to person 226\n",
      "(39/50) predicting to person 245\n",
      "(40/50) predicting to person 241\n",
      "(41/50) predicting to person 208\n",
      "(42/50) predicting to person 243\n",
      "(43/50) predicting to person 211\n",
      "(44/50) predicting to person 236\n",
      "(45/50) predicting to person 218\n",
      "(46/50) predicting to person 225\n",
      "(47/50) predicting to person 215\n",
      "(48/50) predicting to person 220\n",
      "(49/50) predicting to person 238\n",
      "(50/50) predicting to person 216\n"
     ]
    }
   ],
   "source": [
    "embeddings, images = create_embeddings(map_person_to_filepaths('val'), s1_embs_model, debbug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_embs = np.zeros(shape=(0,64))\n",
    "labels = np.zeros(shape=(0,1))\n",
    "count = 1\n",
    "for (person, embs) in embeddings.items():\n",
    "    combined_embs = np.append( combined_embs,  embs, axis=0)\n",
    "    l = np.zeros((len(embs), 1)) + count\n",
    "    labels = np.append( labels,  l, axis=0)\n",
    "    count = count + 1\n",
    "    if count>10:\n",
    "        break\n",
    "\n",
    "labels = labels.flatten()\n",
    "embs_2d = TSNE().fit_transform(combined_embs)\n",
    "scatter(embs_2d, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "50/50 [==============================] - 45s 896ms/step - loss: 0.1478\n",
      "Epoch 2/1000\n",
      "50/50 [==============================] - 42s 839ms/step - loss: 0.1166\n",
      "Epoch 3/1000\n",
      "50/50 [==============================] - 43s 861ms/step - loss: 0.0862\n",
      "Epoch 4/1000\n",
      "50/50 [==============================] - 42s 844ms/step - loss: 0.0669\n",
      "Epoch 5/1000\n",
      "50/50 [==============================] - 42s 832ms/step - loss: 0.0570\n",
      "Epoch 6/1000\n",
      "50/50 [==============================] - 42s 846ms/step - loss: 0.0490\n",
      "Epoch 7/1000\n",
      "50/50 [==============================] - 42s 840ms/step - loss: 0.0184\n",
      "Epoch 8/1000\n",
      "50/50 [==============================] - 42s 841ms/step - loss: 0.0320\n",
      "Epoch 9/1000\n",
      "50/50 [==============================] - 42s 834ms/step - loss: 0.0178\n",
      "Epoch 10/1000\n",
      "50/50 [==============================] - 42s 838ms/step - loss: 0.0268\n",
      "Epoch 11/1000\n",
      "50/50 [==============================] - 42s 841ms/step - loss: 0.0206\n",
      "Epoch 12/1000\n",
      "50/50 [==============================] - 41s 827ms/step - loss: 0.0147\n",
      "Epoch 13/1000\n",
      "50/50 [==============================] - 41s 827ms/step - loss: 0.0102\n",
      "Epoch 14/1000\n",
      "50/50 [==============================] - 43s 855ms/step - loss: 0.0120\n",
      "Epoch 15/1000\n",
      "50/50 [==============================] - 41s 819ms/step - loss: 0.0146\n",
      "Epoch 16/1000\n",
      "50/50 [==============================] - 42s 838ms/step - loss: 0.0088\n",
      "Epoch 17/1000\n",
      "50/50 [==============================] - 41s 828ms/step - loss: 0.0086\n",
      "Epoch 18/1000\n",
      "50/50 [==============================] - 42s 833ms/step - loss: 0.0016\n",
      "Epoch 19/1000\n",
      "50/50 [==============================] - 42s 832ms/step - loss: 0.0085\n",
      "Epoch 20/1000\n",
      "50/50 [==============================] - 41s 822ms/step - loss: 0.0080\n",
      "Epoch 21/1000\n",
      "50/50 [==============================] - 41s 830ms/step - loss: 0.0148\n",
      "Epoch 22/1000\n",
      "50/50 [==============================] - 42s 832ms/step - loss: 0.0082\n",
      "Epoch 23/1000\n",
      "50/50 [==============================] - 42s 836ms/step - loss: 0.0061\n",
      "Epoch 24/1000\n",
      "50/50 [==============================] - 41s 823ms/step - loss: 0.0089\n",
      "Epoch 25/1000\n",
      "50/50 [==============================] - 43s 864ms/step - loss: 2.1653e-04\n",
      "Epoch 26/1000\n",
      "50/50 [==============================] - 41s 824ms/step - loss: 0.0026\n",
      "Epoch 27/1000\n",
      "50/50 [==============================] - 42s 845ms/step - loss: 0.0015\n",
      "Epoch 28/1000\n",
      "50/50 [==============================] - 42s 833ms/step - loss: 0.0045\n",
      "Epoch 29/1000\n",
      "50/50 [==============================] - 43s 854ms/step - loss: 0.0024\n",
      "Epoch 30/1000\n",
      "50/50 [==============================] - 42s 835ms/step - loss: 7.4466e-04\n",
      "Epoch 31/1000\n",
      "50/50 [==============================] - 42s 846ms/step - loss: 0.0015\n",
      "Epoch 32/1000\n",
      "50/50 [==============================] - 41s 829ms/step - loss: 0.0033\n",
      "Epoch 33/1000\n",
      "50/50 [==============================] - 42s 843ms/step - loss: 0.0012\n",
      "Epoch 34/1000\n",
      "50/50 [==============================] - 43s 851ms/step - loss: 0.0020\n",
      "Epoch 35/1000\n",
      "50/50 [==============================] - 42s 845ms/step - loss: 0.0013\n",
      "Epoch 36/1000\n",
      "50/50 [==============================] - 42s 833ms/step - loss: 0.0000e+00\n",
      "Epoch 37/1000\n",
      "50/50 [==============================] - 43s 852ms/step - loss: 0.0060\n",
      "Epoch 38/1000\n",
      "50/50 [==============================] - 42s 845ms/step - loss: 0.0036\n",
      "Epoch 39/1000\n",
      "50/50 [==============================] - 42s 839ms/step - loss: 0.0014\n",
      "Epoch 40/1000\n",
      "50/50 [==============================] - 42s 846ms/step - loss: 0.0010\n",
      "Epoch 41/1000\n",
      "50/50 [==============================] - 43s 850ms/step - loss: 0.0019\n",
      "Epoch 42/1000\n",
      "50/50 [==============================] - 42s 847ms/step - loss: 0.0017\n",
      "Epoch 43/1000\n",
      "50/50 [==============================] - 42s 849ms/step - loss: 0.0024\n",
      "Epoch 44/1000\n",
      "50/50 [==============================] - 42s 848ms/step - loss: 1.9857e-04\n",
      "Epoch 45/1000\n",
      "50/50 [==============================] - 42s 846ms/step - loss: 0.0025\n",
      "Epoch 46/1000\n",
      "50/50 [==============================] - 42s 842ms/step - loss: 0.0015\n",
      "Epoch 47/1000\n",
      "50/50 [==============================] - 43s 853ms/step - loss: 5.9094e-05\n",
      "Epoch 48/1000\n",
      "50/50 [==============================] - 42s 845ms/step - loss: 0.0022\n",
      "Epoch 49/1000\n",
      "50/50 [==============================] - 42s 846ms/step - loss: 0.0035\n",
      "Epoch 50/1000\n",
      "50/50 [==============================] - 42s 843ms/step - loss: 0.0028\n",
      "Epoch 51/1000\n",
      "50/50 [==============================] - 42s 843ms/step - loss: 0.0018\n",
      "Epoch 52/1000\n",
      "50/50 [==============================] - 43s 864ms/step - loss: 0.0037\n",
      "Epoch 53/1000\n",
      "50/50 [==============================] - 42s 836ms/step - loss: 0.0014\n",
      "Epoch 54/1000\n",
      "50/50 [==============================] - 42s 841ms/step - loss: 0.0000e+00\n",
      "Epoch 55/1000\n",
      "50/50 [==============================] - 42s 839ms/step - loss: 6.0276e-04\n",
      "Epoch 56/1000\n",
      "50/50 [==============================] - 42s 844ms/step - loss: 0.0000e+00\n",
      "Epoch 57/1000\n",
      "50/50 [==============================] - 42s 836ms/step - loss: 0.0000e+00\n",
      "Epoch 58/1000\n",
      "50/50 [==============================] - 42s 833ms/step - loss: 9.8317e-04\n",
      "Epoch 59/1000\n",
      "50/50 [==============================] - 43s 853ms/step - loss: 1.8743e-04\n",
      "Epoch 60/1000\n",
      "50/50 [==============================] - 42s 846ms/step - loss: 2.0823e-04\n",
      "Epoch 61/1000\n",
      "50/50 [==============================] - 41s 829ms/step - loss: 0.0000e+00\n",
      "Epoch 62/1000\n",
      "50/50 [==============================] - 42s 844ms/step - loss: 5.9202e-04\n",
      "Epoch 63/1000\n",
      "50/50 [==============================] - 42s 843ms/step - loss: 0.0013\n",
      "Epoch 64/1000\n",
      "50/50 [==============================] - 42s 830ms/step - loss: 0.0000e+00\n",
      "Epoch 65/1000\n",
      "50/50 [==============================] - 41s 826ms/step - loss: 2.5003e-04\n",
      "Epoch 66/1000\n",
      "50/50 [==============================] - 43s 853ms/step - loss: 0.0000e+00\n",
      "Epoch 67/1000\n",
      "50/50 [==============================] - 42s 834ms/step - loss: 7.9246e-04\n",
      "Epoch 68/1000\n",
      "50/50 [==============================] - 42s 837ms/step - loss: 0.0000e+00\n",
      "Epoch 69/1000\n",
      "50/50 [==============================] - 43s 851ms/step - loss: 0.0014\n",
      "Epoch 70/1000\n",
      "50/50 [==============================] - 42s 839ms/step - loss: 4.4427e-04\n",
      "Epoch 71/1000\n",
      "50/50 [==============================] - 42s 837ms/step - loss: 3.3712e-04\n",
      "Epoch 72/1000\n",
      "50/50 [==============================] - 42s 847ms/step - loss: 0.0000e+00\n",
      "Epoch 73/1000\n",
      "50/50 [==============================] - 43s 858ms/step - loss: 0.0013\n",
      "Epoch 74/1000\n",
      "50/50 [==============================] - 43s 860ms/step - loss: 4.8783e-04\n",
      "Epoch 75/1000\n",
      "50/50 [==============================] - 42s 834ms/step - loss: 0.0000e+00\n",
      "Epoch 76/1000\n",
      "50/50 [==============================] - 42s 848ms/step - loss: 0.0000e+00\n",
      "Epoch 77/1000\n",
      "50/50 [==============================] - 43s 867ms/step - loss: 3.8215e-04\n",
      "Epoch 78/1000\n",
      "50/50 [==============================] - 42s 842ms/step - loss: 4.7975e-05\n",
      "Epoch 79/1000\n",
      "50/50 [==============================] - 42s 845ms/step - loss: 0.0013\n",
      "Epoch 80/1000\n",
      "50/50 [==============================] - 42s 839ms/step - loss: 0.0011\n",
      "Epoch 81/1000\n",
      "50/50 [==============================] - 42s 838ms/step - loss: 0.0000e+00\n",
      "Epoch 82/1000\n",
      "50/50 [==============================] - 43s 850ms/step - loss: 0.0000e+00\n",
      "Epoch 83/1000\n",
      "50/50 [==============================] - 42s 834ms/step - loss: 3.7823e-04\n",
      "Epoch 84/1000\n",
      "50/50 [==============================] - 42s 849ms/step - loss: 5.7104e-04\n",
      "Epoch 85/1000\n",
      "50/50 [==============================] - 42s 841ms/step - loss: 0.0000e+00\n",
      "Epoch 86/1000\n",
      "50/50 [==============================] - 42s 833ms/step - loss: 0.0000e+00\n",
      "Epoch 87/1000\n",
      "50/50 [==============================] - 42s 841ms/step - loss: 0.0000e+00\n",
      "Epoch 88/1000\n",
      "50/50 [==============================] - 43s 870ms/step - loss: 1.9095e-04\n",
      "Epoch 89/1000\n",
      "50/50 [==============================] - 44s 871ms/step - loss: 0.0000e+00\n",
      "Epoch 90/1000\n",
      "50/50 [==============================] - 44s 870ms/step - loss: 8.7605e-04\n",
      "Epoch 91/1000\n",
      "50/50 [==============================] - 42s 844ms/step - loss: 0.0000e+00\n",
      "Epoch 92/1000\n",
      "50/50 [==============================] - 43s 858ms/step - loss: 0.0000e+00\n",
      "Epoch 93/1000\n",
      "50/50 [==============================] - 42s 839ms/step - loss: 3.8820e-04\n",
      "Epoch 94/1000\n",
      "50/50 [==============================] - 43s 861ms/step - loss: 2.8627e-04\n",
      "Epoch 95/1000\n",
      "50/50 [==============================] - 43s 868ms/step - loss: 0.0000e+00\n",
      "Epoch 96/1000\n",
      "50/50 [==============================] - 42s 845ms/step - loss: 0.0019\n",
      "Epoch 97/1000\n",
      "50/50 [==============================] - 43s 853ms/step - loss: 2.3015e-04\n",
      "Epoch 98/1000\n",
      "50/50 [==============================] - 42s 849ms/step - loss: 0.0000e+00\n",
      "Epoch 99/1000\n",
      "50/50 [==============================] - 42s 834ms/step - loss: 0.0025\n",
      "Epoch 100/1000\n",
      "50/50 [==============================] - 43s 856ms/step - loss: 3.0409e-04\n",
      "Epoch 101/1000\n",
      "50/50 [==============================] - 42s 844ms/step - loss: 0.0000e+00\n",
      "Epoch 102/1000\n",
      "50/50 [==============================] - 43s 856ms/step - loss: 5.4592e-04\n",
      "Epoch 103/1000\n",
      "50/50 [==============================] - 42s 836ms/step - loss: 0.0000e+00\n",
      "Epoch 104/1000\n",
      "50/50 [==============================] - 42s 842ms/step - loss: 0.0000e+00\n",
      "Epoch 105/1000\n",
      "50/50 [==============================] - 43s 851ms/step - loss: 1.9432e-05\n",
      "Epoch 106/1000\n",
      "50/50 [==============================] - 43s 859ms/step - loss: 0.0024\n",
      "Epoch 107/1000\n",
      "50/50 [==============================] - 42s 840ms/step - loss: 0.0000e+00\n",
      "Epoch 108/1000\n",
      "50/50 [==============================] - 43s 853ms/step - loss: 0.0000e+00\n",
      "Epoch 109/1000\n",
      "50/50 [==============================] - 42s 846ms/step - loss: 0.0000e+00\n",
      "Epoch 110/1000\n",
      "50/50 [==============================] - 42s 842ms/step - loss: 4.8000e-04\n",
      "Epoch 111/1000\n",
      "50/50 [==============================] - 42s 848ms/step - loss: 6.1853e-04\n",
      "Epoch 112/1000\n",
      "50/50 [==============================] - 43s 863ms/step - loss: 0.0011\n",
      "Epoch 113/1000\n",
      "50/50 [==============================] - 42s 843ms/step - loss: 6.3794e-05\n",
      "Epoch 114/1000\n",
      "50/50 [==============================] - 42s 837ms/step - loss: 0.0000e+00\n",
      "Epoch 115/1000\n",
      "50/50 [==============================] - 43s 861ms/step - loss: 0.0016\n",
      "Epoch 116/1000\n",
      "50/50 [==============================] - 42s 835ms/step - loss: 0.0000e+00\n",
      "Epoch 117/1000\n",
      "50/50 [==============================] - 42s 849ms/step - loss: 0.0000e+00\n",
      "Epoch 118/1000\n",
      "50/50 [==============================] - 42s 839ms/step - loss: 0.0000e+00\n",
      "Epoch 119/1000\n",
      "50/50 [==============================] - 43s 868ms/step - loss: 0.0000e+00\n",
      "Epoch 120/1000\n",
      "50/50 [==============================] - 42s 849ms/step - loss: 0.0000e+00\n",
      "Epoch 121/1000\n",
      "50/50 [==============================] - 42s 847ms/step - loss: 0.0018\n",
      "Epoch 122/1000\n",
      "50/50 [==============================] - 43s 855ms/step - loss: 0.0000e+00\n",
      "Epoch 123/1000\n",
      "50/50 [==============================] - 42s 849ms/step - loss: 7.1852e-04\n",
      "Epoch 124/1000\n",
      "50/50 [==============================] - 43s 853ms/step - loss: 0.0000e+00\n",
      "Epoch 125/1000\n",
      "50/50 [==============================] - 43s 860ms/step - loss: 0.0000e+00\n",
      "Epoch 126/1000\n",
      "50/50 [==============================] - 43s 859ms/step - loss: 1.1880e-04\n",
      "Epoch 127/1000\n",
      "50/50 [==============================] - 42s 841ms/step - loss: 5.3457e-04\n",
      "Epoch 128/1000\n",
      "50/50 [==============================] - 43s 864ms/step - loss: 0.0000e+00\n",
      "Epoch 129/1000\n",
      "50/50 [==============================] - 42s 848ms/step - loss: 0.0000e+00\n",
      "Epoch 130/1000\n",
      "50/50 [==============================] - 42s 837ms/step - loss: 0.0000e+00\n",
      "Epoch 131/1000\n",
      "50/50 [==============================] - 43s 867ms/step - loss: 0.0000e+00\n",
      "Epoch 132/1000\n",
      "50/50 [==============================] - 42s 844ms/step - loss: 0.0000e+00\n",
      "Epoch 133/1000\n",
      "50/50 [==============================] - 43s 861ms/step - loss: 0.0000e+00\n",
      "Epoch 134/1000\n",
      "50/50 [==============================] - 42s 839ms/step - loss: 2.8983e-04\n",
      "Epoch 135/1000\n",
      "50/50 [==============================] - 42s 839ms/step - loss: 0.0000e+00\n",
      "Epoch 136/1000\n",
      "50/50 [==============================] - 43s 857ms/step - loss: 0.0000e+00\n",
      "Epoch 137/1000\n",
      "50/50 [==============================] - 42s 848ms/step - loss: 0.0000e+00\n",
      "Epoch 138/1000\n",
      "50/50 [==============================] - 43s 859ms/step - loss: 0.0000e+00\n",
      "Epoch 139/1000\n",
      "50/50 [==============================] - 42s 849ms/step - loss: 0.0000e+00\n",
      "Epoch 140/1000\n",
      "50/50 [==============================] - 43s 861ms/step - loss: 0.0000e+00\n",
      "Epoch 141/1000\n",
      "50/50 [==============================] - 43s 850ms/step - loss: 0.0000e+00\n",
      "Epoch 142/1000\n",
      "50/50 [==============================] - 43s 854ms/step - loss: 0.0000e+00\n",
      "Epoch 143/1000\n",
      "50/50 [==============================] - 44s 879ms/step - loss: 0.0000e+00\n",
      "Epoch 144/1000\n",
      "50/50 [==============================] - 42s 842ms/step - loss: 0.0000e+00\n",
      "Epoch 145/1000\n",
      "50/50 [==============================] - 42s 847ms/step - loss: 0.0000e+00\n",
      "Epoch 146/1000\n",
      "50/50 [==============================] - 43s 861ms/step - loss: 6.0145e-04\n",
      "Epoch 147/1000\n",
      "50/50 [==============================] - 43s 854ms/step - loss: 0.0000e+00\n",
      "Epoch 148/1000\n",
      "50/50 [==============================] - 43s 868ms/step - loss: 0.0000e+00\n",
      "Epoch 149/1000\n",
      "50/50 [==============================] - 43s 864ms/step - loss: 0.0000e+00\n",
      "Epoch 150/1000\n",
      "50/50 [==============================] - 42s 843ms/step - loss: 0.0000e+00\n",
      "Epoch 151/1000\n",
      "50/50 [==============================] - 43s 862ms/step - loss: 7.8570e-04\n",
      "Epoch 152/1000\n",
      "50/50 [==============================] - 43s 860ms/step - loss: 0.0000e+00\n",
      "Epoch 153/1000\n",
      "50/50 [==============================] - 43s 852ms/step - loss: 0.0000e+00\n",
      "Epoch 154/1000\n",
      "50/50 [==============================] - 42s 845ms/step - loss: 2.2747e-04\n",
      "Epoch 155/1000\n",
      "50/50 [==============================] - 43s 855ms/step - loss: 0.0000e+00\n",
      "Epoch 156/1000\n",
      "50/50 [==============================] - 42s 849ms/step - loss: 0.0000e+00\n",
      "Epoch 157/1000\n",
      "50/50 [==============================] - 43s 856ms/step - loss: 0.0000e+00\n",
      "Epoch 158/1000\n",
      "50/50 [==============================] - 42s 850ms/step - loss: 0.0000e+00\n",
      "Epoch 159/1000\n",
      "50/50 [==============================] - 42s 844ms/step - loss: 0.0000e+00\n",
      "Epoch 160/1000\n",
      "50/50 [==============================] - 43s 855ms/step - loss: 0.0000e+00\n",
      "Epoch 161/1000\n",
      "50/50 [==============================] - 42s 846ms/step - loss: 0.0000e+00\n",
      "Epoch 162/1000\n",
      "50/50 [==============================] - 44s 870ms/step - loss: 0.0000e+00\n",
      "Epoch 163/1000\n",
      "50/50 [==============================] - 44s 871ms/step - loss: 5.2832e-04\n",
      "Epoch 164/1000\n",
      "50/50 [==============================] - 43s 854ms/step - loss: 0.0000e+00\n",
      "Epoch 165/1000\n",
      "50/50 [==============================] - 43s 857ms/step - loss: 2.8413e-05\n",
      "Epoch 166/1000\n",
      "50/50 [==============================] - 43s 856ms/step - loss: 0.0000e+00\n",
      "Epoch 167/1000\n",
      "50/50 [==============================] - 42s 844ms/step - loss: 0.0000e+00\n",
      "Epoch 168/1000\n",
      "50/50 [==============================] - 42s 847ms/step - loss: 0.0000e+00\n",
      "Epoch 169/1000\n",
      "50/50 [==============================] - 42s 847ms/step - loss: 0.0000e+00\n",
      "Epoch 170/1000\n",
      "50/50 [==============================] - 42s 840ms/step - loss: 0.0000e+00\n",
      "Epoch 171/1000\n",
      "50/50 [==============================] - 43s 856ms/step - loss: 0.0000e+00\n",
      "Epoch 172/1000\n",
      "50/50 [==============================] - 43s 858ms/step - loss: 0.0000e+00\n",
      "Epoch 173/1000\n",
      "50/50 [==============================] - 42s 837ms/step - loss: 0.0000e+00\n",
      "Epoch 174/1000\n",
      "50/50 [==============================] - 43s 853ms/step - loss: 0.0000e+00\n",
      "Epoch 175/1000\n",
      "50/50 [==============================] - 42s 850ms/step - loss: 0.0000e+00\n",
      "Epoch 176/1000\n",
      "50/50 [==============================] - 42s 849ms/step - loss: 6.2149e-04\n",
      "Epoch 177/1000\n",
      "50/50 [==============================] - 42s 842ms/step - loss: 0.0000e+00\n",
      "Epoch 178/1000\n",
      "50/50 [==============================] - 43s 864ms/step - loss: 0.0000e+00\n",
      "Epoch 179/1000\n",
      "50/50 [==============================] - 42s 843ms/step - loss: 4.9326e-04\n",
      "Epoch 180/1000\n",
      "50/50 [==============================] - 42s 850ms/step - loss: 0.0000e+00\n",
      "Epoch 181/1000\n",
      "50/50 [==============================] - 42s 839ms/step - loss: 0.0000e+00\n",
      "Epoch 182/1000\n",
      "50/50 [==============================] - 43s 861ms/step - loss: 0.0000e+00\n",
      "Epoch 183/1000\n",
      "50/50 [==============================] - 42s 838ms/step - loss: 0.0000e+00\n",
      "Epoch 184/1000\n",
      "50/50 [==============================] - 43s 863ms/step - loss: 0.0000e+00\n",
      "Epoch 185/1000\n",
      "50/50 [==============================] - 42s 841ms/step - loss: 0.0000e+00\n",
      "Epoch 186/1000\n",
      "50/50 [==============================] - 43s 859ms/step - loss: 0.0000e+00\n",
      "Epoch 187/1000\n",
      "50/50 [==============================] - 43s 861ms/step - loss: 0.0000e+00\n",
      "Epoch 188/1000\n",
      "50/50 [==============================] - 42s 849ms/step - loss: 0.0000e+00\n",
      "Epoch 189/1000\n",
      "50/50 [==============================] - 43s 866ms/step - loss: 0.0000e+00\n",
      "Epoch 190/1000\n",
      "50/50 [==============================] - 42s 843ms/step - loss: 0.0000e+00\n",
      "Epoch 191/1000\n",
      "50/50 [==============================] - 42s 850ms/step - loss: 0.0000e+00\n",
      "Epoch 192/1000\n",
      "50/50 [==============================] - 43s 856ms/step - loss: 0.0000e+00\n",
      "Epoch 193/1000\n",
      "50/50 [==============================] - 43s 854ms/step - loss: 0.0000e+00\n",
      "Epoch 194/1000\n",
      "50/50 [==============================] - 43s 858ms/step - loss: 0.0000e+00\n",
      "Epoch 195/1000\n",
      "50/50 [==============================] - 43s 861ms/step - loss: 0.0000e+00\n",
      "Epoch 196/1000\n",
      "50/50 [==============================] - 43s 861ms/step - loss: 0.0012\n",
      "Epoch 197/1000\n",
      "50/50 [==============================] - 42s 846ms/step - loss: 0.0000e+00\n",
      "Epoch 198/1000\n",
      "50/50 [==============================] - 43s 858ms/step - loss: 0.0000e+00\n",
      "Epoch 199/1000\n",
      "50/50 [==============================] - 42s 840ms/step - loss: 1.7192e-04\n",
      "Epoch 200/1000\n",
      "50/50 [==============================] - 43s 852ms/step - loss: 0.0000e+00\n",
      "Epoch 201/1000\n",
      "50/50 [==============================] - 43s 856ms/step - loss: 0.0000e+00\n",
      "Epoch 202/1000\n",
      "50/50 [==============================] - 43s 856ms/step - loss: 0.0000e+00\n",
      "Epoch 203/1000\n",
      "50/50 [==============================] - 42s 845ms/step - loss: 0.0000e+00\n",
      "Epoch 204/1000\n",
      "50/50 [==============================] - 43s 855ms/step - loss: 0.0000e+00\n",
      "Epoch 205/1000\n",
      "50/50 [==============================] - 42s 849ms/step - loss: 0.0000e+00\n",
      "Epoch 206/1000\n",
      "50/50 [==============================] - 42s 849ms/step - loss: 0.0000e+00\n",
      "Epoch 207/1000\n",
      "50/50 [==============================] - 43s 855ms/step - loss: 9.4320e-05\n",
      "Epoch 208/1000\n",
      "50/50 [==============================] - 43s 860ms/step - loss: 0.0000e+00\n",
      "Epoch 209/1000\n",
      "50/50 [==============================] - 42s 847ms/step - loss: 0.0000e+00\n",
      "Epoch 210/1000\n",
      "50/50 [==============================] - 43s 861ms/step - loss: 0.0000e+00\n",
      "Epoch 211/1000\n",
      "50/50 [==============================] - 43s 852ms/step - loss: 0.0000e+00\n",
      "Epoch 212/1000\n",
      "50/50 [==============================] - 43s 852ms/step - loss: 0.0000e+00\n",
      "Epoch 213/1000\n",
      "50/50 [==============================] - 43s 855ms/step - loss: 0.0000e+00\n",
      "Epoch 214/1000\n",
      "50/50 [==============================] - 43s 854ms/step - loss: 0.0000e+00\n",
      "Epoch 215/1000\n",
      "50/50 [==============================] - 43s 854ms/step - loss: 2.6868e-04\n",
      "Epoch 216/1000\n",
      "50/50 [==============================] - 43s 853ms/step - loss: 0.0000e+00\n",
      "Epoch 217/1000\n",
      "50/50 [==============================] - 43s 858ms/step - loss: 0.0000e+00\n",
      "Epoch 218/1000\n",
      "50/50 [==============================] - 43s 853ms/step - loss: 0.0000e+00\n",
      "Epoch 219/1000\n",
      "50/50 [==============================] - 43s 855ms/step - loss: 0.0000e+00\n",
      "Epoch 220/1000\n",
      "50/50 [==============================] - 43s 863ms/step - loss: 0.0000e+00\n",
      "Epoch 221/1000\n",
      "50/50 [==============================] - 43s 867ms/step - loss: 0.0000e+00\n",
      "Epoch 222/1000\n",
      "50/50 [==============================] - 43s 862ms/step - loss: 0.0000e+00\n",
      "Epoch 223/1000\n",
      "50/50 [==============================] - 43s 866ms/step - loss: 0.0000e+00\n",
      "Epoch 224/1000\n",
      "50/50 [==============================] - 42s 845ms/step - loss: 0.0000e+00\n",
      "Epoch 225/1000\n",
      "50/50 [==============================] - 43s 855ms/step - loss: 0.0000e+00\n",
      "Epoch 226/1000\n",
      "50/50 [==============================] - 42s 846ms/step - loss: 0.0000e+00\n",
      "Epoch 227/1000\n",
      "50/50 [==============================] - 42s 840ms/step - loss: 0.0000e+00\n",
      "Epoch 228/1000\n",
      "50/50 [==============================] - 44s 877ms/step - loss: 0.0000e+00\n",
      "Epoch 229/1000\n",
      "50/50 [==============================] - 43s 860ms/step - loss: 0.0000e+00\n",
      "Epoch 230/1000\n",
      "50/50 [==============================] - 43s 852ms/step - loss: 0.0000e+00\n",
      "Epoch 231/1000\n",
      "50/50 [==============================] - 42s 846ms/step - loss: 0.0000e+00\n",
      "Epoch 232/1000\n",
      "50/50 [==============================] - 43s 864ms/step - loss: 0.0000e+00\n",
      "Epoch 233/1000\n",
      "50/50 [==============================] - 43s 851ms/step - loss: 0.0000e+00\n",
      "Epoch 234/1000\n",
      "50/50 [==============================] - 43s 857ms/step - loss: 0.0000e+00\n",
      "Epoch 235/1000\n",
      "50/50 [==============================] - 43s 860ms/step - loss: 0.0013\n",
      "Epoch 236/1000\n",
      "50/50 [==============================] - 42s 849ms/step - loss: 0.0000e+00\n",
      "Epoch 237/1000\n",
      "50/50 [==============================] - 43s 860ms/step - loss: 0.0000e+00\n",
      "Epoch 238/1000\n",
      "50/50 [==============================] - 42s 836ms/step - loss: 0.0000e+00\n",
      "Epoch 239/1000\n",
      "50/50 [==============================] - 44s 873ms/step - loss: 0.0000e+00\n",
      "Epoch 240/1000\n",
      "50/50 [==============================] - 42s 847ms/step - loss: 0.0000e+00\n",
      "Epoch 241/1000\n",
      "50/50 [==============================] - 43s 850ms/step - loss: 0.0000e+00\n",
      "Epoch 242/1000\n",
      "50/50 [==============================] - 43s 855ms/step - loss: 0.0000e+00\n",
      "Epoch 243/1000\n",
      "50/50 [==============================] - 43s 850ms/step - loss: 0.0000e+00\n",
      "Epoch 244/1000\n",
      "50/50 [==============================] - 43s 859ms/step - loss: 1.8711e-04\n",
      "Epoch 245/1000\n",
      "50/50 [==============================] - 42s 846ms/step - loss: 0.0000e+00\n",
      "Epoch 246/1000\n",
      "50/50 [==============================] - 43s 858ms/step - loss: 0.0000e+00\n",
      "Epoch 247/1000\n",
      "50/50 [==============================] - 43s 853ms/step - loss: 0.0000e+00\n",
      "Epoch 248/1000\n",
      "50/50 [==============================] - 44s 875ms/step - loss: 0.0000e+00\n",
      "Epoch 249/1000\n",
      "50/50 [==============================] - 43s 861ms/step - loss: 0.0000e+00\n",
      "Epoch 250/1000\n",
      "50/50 [==============================] - 43s 854ms/step - loss: 0.0000e+00\n",
      "Epoch 251/1000\n",
      "50/50 [==============================] - 43s 870ms/step - loss: 0.0000e+00\n",
      "Epoch 252/1000\n",
      "50/50 [==============================] - 42s 844ms/step - loss: 7.9791e-04\n",
      "Epoch 253/1000\n",
      "50/50 [==============================] - 43s 851ms/step - loss: 0.0000e+00\n",
      "Epoch 254/1000\n",
      "50/50 [==============================] - 43s 858ms/step - loss: 0.0000e+00\n",
      "Epoch 255/1000\n",
      "50/50 [==============================] - 43s 857ms/step - loss: 0.0000e+00\n",
      "Epoch 256/1000\n",
      "50/50 [==============================] - 43s 851ms/step - loss: 0.0000e+00\n",
      "Epoch 257/1000\n",
      "50/50 [==============================] - 43s 859ms/step - loss: 0.0000e+00\n",
      "Epoch 258/1000\n",
      "50/50 [==============================] - 43s 865ms/step - loss: 4.4632e-04\n",
      "Epoch 259/1000\n",
      "50/50 [==============================] - 43s 858ms/step - loss: 1.1968e-04\n",
      "Epoch 260/1000\n",
      "50/50 [==============================] - 42s 850ms/step - loss: 0.0000e+00\n",
      "Epoch 261/1000\n",
      "50/50 [==============================] - 42s 840ms/step - loss: 0.0000e+00\n",
      "Epoch 262/1000\n",
      "50/50 [==============================] - 43s 866ms/step - loss: 0.0000e+00\n",
      "Epoch 263/1000\n",
      "50/50 [==============================] - 43s 854ms/step - loss: 0.0000e+00\n",
      "Epoch 264/1000\n",
      "50/50 [==============================] - 43s 860ms/step - loss: 0.0000e+00\n",
      "Epoch 265/1000\n",
      "50/50 [==============================] - 42s 848ms/step - loss: 0.0000e+00\n",
      "Epoch 266/1000\n",
      "50/50 [==============================] - 42s 848ms/step - loss: 0.0000e+00\n",
      "Epoch 267/1000\n",
      "50/50 [==============================] - 43s 861ms/step - loss: 0.0000e+00\n",
      "Epoch 268/1000\n",
      "50/50 [==============================] - 43s 851ms/step - loss: 0.0000e+00\n",
      "Epoch 269/1000\n",
      "50/50 [==============================] - 42s 846ms/step - loss: 0.0000e+00\n",
      "Epoch 270/1000\n",
      "50/50 [==============================] - 44s 872ms/step - loss: 0.0000e+00\n",
      "Epoch 271/1000\n",
      "50/50 [==============================] - 43s 853ms/step - loss: 0.0000e+00\n",
      "Epoch 272/1000\n",
      "50/50 [==============================] - 42s 847ms/step - loss: 0.0000e+00\n",
      "Epoch 273/1000\n",
      "50/50 [==============================] - 43s 856ms/step - loss: 0.0000e+00\n",
      "Epoch 274/1000\n",
      "50/50 [==============================] - 43s 853ms/step - loss: 0.0000e+00\n",
      "Epoch 275/1000\n",
      "50/50 [==============================] - 43s 854ms/step - loss: 0.0000e+00\n",
      "Epoch 276/1000\n",
      "50/50 [==============================] - 42s 849ms/step - loss: 0.0000e+00\n",
      "Epoch 277/1000\n",
      "50/50 [==============================] - 43s 863ms/step - loss: 0.0000e+00\n",
      "Epoch 278/1000\n",
      "50/50 [==============================] - 43s 853ms/step - loss: 0.0000e+00\n",
      "Epoch 279/1000\n",
      "50/50 [==============================] - 43s 865ms/step - loss: 0.0000e+00\n",
      "Epoch 280/1000\n",
      "50/50 [==============================] - 43s 858ms/step - loss: 0.0000e+00\n",
      "Epoch 281/1000\n",
      "50/50 [==============================] - 42s 848ms/step - loss: 0.0000e+00\n",
      "Epoch 282/1000\n",
      "50/50 [==============================] - 42s 849ms/step - loss: 0.0000e+00\n",
      "Epoch 283/1000\n",
      "50/50 [==============================] - 43s 850ms/step - loss: 0.0000e+00\n",
      "Epoch 284/1000\n",
      "50/50 [==============================] - 43s 852ms/step - loss: 0.0000e+00\n",
      "Epoch 285/1000\n",
      "50/50 [==============================] - 42s 847ms/step - loss: 0.0000e+00\n",
      "Epoch 286/1000\n",
      "50/50 [==============================] - 42s 845ms/step - loss: 0.0000e+00\n",
      "Epoch 287/1000\n",
      "50/50 [==============================] - 42s 846ms/step - loss: 0.0000e+00\n",
      "Epoch 288/1000\n",
      "50/50 [==============================] - 42s 846ms/step - loss: 0.0000e+00\n",
      "Epoch 289/1000\n",
      "50/50 [==============================] - 43s 851ms/step - loss: 0.0000e+00\n",
      "Epoch 290/1000\n",
      "50/50 [==============================] - 43s 853ms/step - loss: 0.0000e+00\n",
      "Epoch 291/1000\n",
      "50/50 [==============================] - 43s 864ms/step - loss: 0.0000e+00\n",
      "Epoch 292/1000\n",
      "50/50 [==============================] - 42s 850ms/step - loss: 0.0000e+00\n",
      "Epoch 293/1000\n",
      "50/50 [==============================] - 43s 854ms/step - loss: 0.0000e+00\n",
      "Epoch 294/1000\n",
      "50/50 [==============================] - 43s 855ms/step - loss: 0.0000e+00\n",
      "Epoch 295/1000\n",
      "50/50 [==============================] - 43s 853ms/step - loss: 0.0000e+00\n",
      "Epoch 296/1000\n",
      "50/50 [==============================] - 42s 843ms/step - loss: 0.0000e+00\n",
      "Epoch 297/1000\n",
      "50/50 [==============================] - 42s 849ms/step - loss: 0.0000e+00\n",
      "Epoch 298/1000\n",
      "50/50 [==============================] - 43s 858ms/step - loss: 0.0000e+00\n",
      "Epoch 299/1000\n",
      "50/50 [==============================] - 43s 852ms/step - loss: 0.0000e+00\n",
      "Epoch 300/1000\n",
      "50/50 [==============================] - 43s 867ms/step - loss: 0.0000e+00\n",
      "Epoch 301/1000\n",
      "50/50 [==============================] - 43s 862ms/step - loss: 0.0000e+00\n",
      "Epoch 302/1000\n",
      "50/50 [==============================] - 43s 854ms/step - loss: 0.0000e+00\n",
      "Epoch 303/1000\n",
      "50/50 [==============================] - 43s 854ms/step - loss: 0.0000e+00\n",
      "Epoch 304/1000\n",
      "50/50 [==============================] - 43s 854ms/step - loss: 0.0000e+00\n",
      "Epoch 305/1000\n",
      "50/50 [==============================] - 43s 859ms/step - loss: 0.0000e+00\n",
      "Epoch 306/1000\n",
      "50/50 [==============================] - 42s 848ms/step - loss: 0.0000e+00\n",
      "Epoch 307/1000\n",
      "50/50 [==============================] - 43s 860ms/step - loss: 0.0000e+00\n",
      "Epoch 308/1000\n",
      "50/50 [==============================] - 43s 854ms/step - loss: 0.0000e+00\n",
      "Epoch 309/1000\n",
      "50/50 [==============================] - 43s 851ms/step - loss: 0.0000e+00\n",
      "Epoch 310/1000\n",
      "50/50 [==============================] - 42s 847ms/step - loss: 0.0000e+00\n",
      "Epoch 311/1000\n",
      "50/50 [==============================] - 43s 854ms/step - loss: 0.0000e+00\n",
      "Epoch 312/1000\n",
      "50/50 [==============================] - 43s 867ms/step - loss: 0.0000e+00\n",
      "Epoch 313/1000\n",
      "50/50 [==============================] - 43s 853ms/step - loss: 0.0000e+00\n",
      "Epoch 314/1000\n",
      "50/50 [==============================] - 43s 852ms/step - loss: 0.0000e+00\n",
      "Epoch 315/1000\n",
      "50/50 [==============================] - 43s 854ms/step - loss: 0.0000e+00\n",
      "Epoch 316/1000\n",
      "50/50 [==============================] - 43s 856ms/step - loss: 0.0000e+00\n",
      "Epoch 317/1000\n",
      "50/50 [==============================] - 43s 854ms/step - loss: 0.0000e+00\n",
      "Epoch 318/1000\n",
      "50/50 [==============================] - 43s 864ms/step - loss: 7.0853e-05\n",
      "Epoch 319/1000\n",
      "50/50 [==============================] - 44s 872ms/step - loss: 0.0000e+00\n",
      "Epoch 320/1000\n",
      "50/50 [==============================] - 43s 860ms/step - loss: 0.0000e+00\n",
      "Epoch 321/1000\n",
      "50/50 [==============================] - 43s 860ms/step - loss: 0.0000e+00\n",
      "Epoch 322/1000\n",
      "50/50 [==============================] - 43s 860ms/step - loss: 0.0000e+00\n",
      "Epoch 323/1000\n",
      "50/50 [==============================] - 43s 861ms/step - loss: 0.0000e+00\n",
      "Epoch 324/1000\n",
      "50/50 [==============================] - 43s 862ms/step - loss: 0.0000e+00\n",
      "Epoch 325/1000\n",
      "50/50 [==============================] - 43s 855ms/step - loss: 0.0000e+00\n",
      "Epoch 326/1000\n",
      "50/50 [==============================] - 43s 868ms/step - loss: 0.0000e+00\n",
      "Epoch 327/1000\n",
      "50/50 [==============================] - 43s 858ms/step - loss: 0.0000e+00\n",
      "Epoch 328/1000\n",
      "50/50 [==============================] - 43s 865ms/step - loss: 0.0000e+00\n",
      "Epoch 329/1000\n",
      "50/50 [==============================] - 44s 889ms/step - loss: 0.0000e+00\n",
      "Epoch 330/1000\n",
      "50/50 [==============================] - 44s 886ms/step - loss: 0.0000e+00\n",
      "Epoch 331/1000\n",
      "50/50 [==============================] - 43s 861ms/step - loss: 0.0000e+00\n",
      "Epoch 332/1000\n",
      "50/50 [==============================] - 43s 865ms/step - loss: 0.0000e+00\n",
      "Epoch 333/1000\n",
      "50/50 [==============================] - 43s 868ms/step - loss: 0.0000e+00\n",
      "Epoch 334/1000\n",
      "50/50 [==============================] - 43s 857ms/step - loss: 0.0000e+00\n",
      "Epoch 335/1000\n",
      "50/50 [==============================] - 43s 859ms/step - loss: 0.0000e+00\n",
      "Epoch 336/1000\n",
      "50/50 [==============================] - 43s 860ms/step - loss: 0.0000e+00\n",
      "Epoch 337/1000\n",
      "50/50 [==============================] - 43s 860ms/step - loss: 0.0000e+00\n",
      "Epoch 338/1000\n",
      "50/50 [==============================] - 44s 870ms/step - loss: 0.0000e+00\n",
      "Epoch 339/1000\n",
      "50/50 [==============================] - 43s 867ms/step - loss: 0.0000e+00\n",
      "Epoch 340/1000\n",
      "50/50 [==============================] - 43s 864ms/step - loss: 0.0000e+00\n",
      "Epoch 341/1000\n",
      "50/50 [==============================] - 43s 856ms/step - loss: 0.0000e+00\n",
      "Epoch 342/1000\n",
      "50/50 [==============================] - 43s 856ms/step - loss: 0.0000e+00\n",
      "Epoch 343/1000\n",
      "50/50 [==============================] - 43s 855ms/step - loss: 0.0000e+00\n",
      "Epoch 344/1000\n",
      "50/50 [==============================] - 44s 873ms/step - loss: 0.0000e+00\n",
      "Epoch 345/1000\n",
      "50/50 [==============================] - 43s 861ms/step - loss: 0.0000e+00\n",
      "Epoch 346/1000\n",
      "50/50 [==============================] - 43s 859ms/step - loss: 0.0000e+00\n",
      "Epoch 347/1000\n",
      "50/50 [==============================] - 43s 866ms/step - loss: 0.0015\n",
      "Epoch 348/1000\n",
      "50/50 [==============================] - 43s 868ms/step - loss: 0.0000e+00\n",
      "Epoch 349/1000\n",
      "50/50 [==============================] - 43s 864ms/step - loss: 0.0000e+00\n",
      "Epoch 350/1000\n",
      "50/50 [==============================] - 43s 863ms/step - loss: 0.0000e+00\n",
      "Epoch 351/1000\n",
      "50/50 [==============================] - 43s 855ms/step - loss: 3.9553e-04\n",
      "Epoch 352/1000\n",
      "50/50 [==============================] - 43s 863ms/step - loss: 0.0000e+00\n",
      "Epoch 353/1000\n",
      "50/50 [==============================] - 43s 859ms/step - loss: 0.0000e+00\n",
      "Epoch 354/1000\n",
      "50/50 [==============================] - 44s 875ms/step - loss: 0.0000e+00\n",
      "Epoch 355/1000\n",
      "50/50 [==============================] - 43s 867ms/step - loss: 0.0000e+00\n",
      "Epoch 356/1000\n",
      "50/50 [==============================] - 43s 863ms/step - loss: 0.0000e+00\n",
      "Epoch 357/1000\n",
      "50/50 [==============================] - 43s 862ms/step - loss: 0.0000e+00\n",
      "Epoch 358/1000\n",
      "50/50 [==============================] - 43s 866ms/step - loss: 0.0000e+00\n",
      "Epoch 359/1000\n",
      "50/50 [==============================] - 43s 858ms/step - loss: 0.0000e+00\n",
      "Epoch 360/1000\n",
      "50/50 [==============================] - 43s 857ms/step - loss: 0.0000e+00\n",
      "Epoch 361/1000\n",
      "50/50 [==============================] - 43s 866ms/step - loss: 0.0000e+00\n",
      "Epoch 362/1000\n",
      "50/50 [==============================] - 43s 857ms/step - loss: 0.0000e+00\n",
      "Epoch 363/1000\n",
      "50/50 [==============================] - 43s 857ms/step - loss: 0.0000e+00\n",
      "Epoch 364/1000\n",
      "50/50 [==============================] - 43s 857ms/step - loss: 0.0000e+00\n",
      "Epoch 365/1000\n",
      "50/50 [==============================] - 43s 858ms/step - loss: 0.0000e+00\n",
      "Epoch 366/1000\n",
      "50/50 [==============================] - 43s 864ms/step - loss: 0.0000e+00\n",
      "Epoch 367/1000\n",
      "50/50 [==============================] - 44s 875ms/step - loss: 0.0000e+00\n",
      "Epoch 368/1000\n",
      "50/50 [==============================] - 44s 874ms/step - loss: 0.0000e+00\n",
      "Epoch 369/1000\n",
      "50/50 [==============================] - 43s 854ms/step - loss: 0.0000e+00\n",
      "Epoch 370/1000\n",
      "50/50 [==============================] - 43s 866ms/step - loss: 0.0000e+00\n",
      "Epoch 371/1000\n",
      "50/50 [==============================] - 43s 870ms/step - loss: 0.0000e+00\n",
      "Epoch 372/1000\n",
      "50/50 [==============================] - 43s 862ms/step - loss: 0.0000e+00\n",
      "Epoch 373/1000\n",
      "50/50 [==============================] - 44s 872ms/step - loss: 0.0000e+00\n",
      "Epoch 374/1000\n",
      "50/50 [==============================] - 43s 858ms/step - loss: 0.0000e+00\n",
      "Epoch 375/1000\n",
      "50/50 [==============================] - 44s 882ms/step - loss: 0.0000e+00\n",
      "Epoch 376/1000\n",
      "50/50 [==============================] - 43s 864ms/step - loss: 0.0000e+00\n",
      "Epoch 377/1000\n",
      "50/50 [==============================] - 44s 875ms/step - loss: 0.0000e+00\n",
      "Epoch 378/1000\n",
      "50/50 [==============================] - 43s 863ms/step - loss: 0.0000e+00\n",
      "Epoch 379/1000\n",
      "50/50 [==============================] - 44s 873ms/step - loss: 0.0000e+00\n",
      "Epoch 380/1000\n",
      "50/50 [==============================] - 43s 869ms/step - loss: 0.0000e+00\n",
      "Epoch 381/1000\n",
      "50/50 [==============================] - 43s 854ms/step - loss: 0.0000e+00\n",
      "Epoch 382/1000\n",
      "50/50 [==============================] - 43s 861ms/step - loss: 0.0000e+00\n",
      "Epoch 383/1000\n",
      "50/50 [==============================] - 44s 873ms/step - loss: 0.0000e+00\n",
      "Epoch 384/1000\n",
      "50/50 [==============================] - 44s 880ms/step - loss: 0.0000e+00\n",
      "Epoch 385/1000\n",
      "50/50 [==============================] - 44s 870ms/step - loss: 0.0000e+00\n",
      "Epoch 386/1000\n",
      "50/50 [==============================] - 43s 865ms/step - loss: 0.0000e+00\n",
      "Epoch 387/1000\n",
      "50/50 [==============================] - 44s 871ms/step - loss: 0.0000e+00\n",
      "Epoch 388/1000\n",
      "50/50 [==============================] - 44s 871ms/step - loss: 0.0000e+00\n",
      "Epoch 389/1000\n",
      "50/50 [==============================] - 43s 861ms/step - loss: 4.0665e-05\n",
      "Epoch 390/1000\n",
      "50/50 [==============================] - 44s 880ms/step - loss: 0.0000e+00\n",
      "Epoch 391/1000\n",
      "50/50 [==============================] - 43s 860ms/step - loss: 0.0000e+00\n",
      "Epoch 392/1000\n",
      "50/50 [==============================] - 43s 869ms/step - loss: 0.0000e+00\n",
      "Epoch 393/1000\n",
      "50/50 [==============================] - 44s 878ms/step - loss: 0.0000e+00\n",
      "Epoch 394/1000\n",
      "50/50 [==============================] - 43s 856ms/step - loss: 0.0000e+00\n",
      "Epoch 395/1000\n",
      "50/50 [==============================] - 44s 881ms/step - loss: 0.0000e+00\n",
      "Epoch 396/1000\n",
      "50/50 [==============================] - 43s 864ms/step - loss: 0.0000e+00\n",
      "Epoch 397/1000\n",
      "50/50 [==============================] - 43s 859ms/step - loss: 0.0000e+00\n",
      "Epoch 398/1000\n",
      "50/50 [==============================] - 44s 882ms/step - loss: 0.0000e+00\n",
      "Epoch 399/1000\n",
      "50/50 [==============================] - 43s 858ms/step - loss: 0.0000e+00\n",
      "Epoch 400/1000\n",
      "50/50 [==============================] - 43s 859ms/step - loss: 0.0000e+00\n",
      "Epoch 401/1000\n",
      "50/50 [==============================] - 43s 868ms/step - loss: 0.0000e+00\n",
      "Epoch 402/1000\n",
      "50/50 [==============================] - 43s 862ms/step - loss: 0.0000e+00\n",
      "Epoch 403/1000\n",
      "50/50 [==============================] - 44s 880ms/step - loss: 0.0000e+00\n",
      "Epoch 404/1000\n",
      "50/50 [==============================] - 43s 860ms/step - loss: 0.0000e+00\n",
      "Epoch 405/1000\n",
      "50/50 [==============================] - 43s 851ms/step - loss: 0.0000e+00\n",
      "Epoch 406/1000\n",
      "50/50 [==============================] - 44s 870ms/step - loss: 0.0000e+00\n",
      "Epoch 407/1000\n",
      "50/50 [==============================] - 43s 861ms/step - loss: 0.0000e+00\n",
      "Epoch 408/1000\n",
      "50/50 [==============================] - 44s 877ms/step - loss: 0.0000e+00\n",
      "Epoch 409/1000\n",
      "50/50 [==============================] - 44s 871ms/step - loss: 0.0000e+00\n",
      "Epoch 410/1000\n",
      "50/50 [==============================] - 43s 868ms/step - loss: 7.3536e-04\n",
      "Epoch 411/1000\n",
      "50/50 [==============================] - 43s 859ms/step - loss: 0.0000e+00\n",
      "Epoch 412/1000\n",
      "50/50 [==============================] - 44s 872ms/step - loss: 0.0000e+00\n",
      "Epoch 413/1000\n",
      "50/50 [==============================] - 44s 879ms/step - loss: 0.0000e+00\n",
      "Epoch 414/1000\n",
      "50/50 [==============================] - 44s 875ms/step - loss: 0.0000e+00\n",
      "Epoch 415/1000\n",
      "50/50 [==============================] - 44s 886ms/step - loss: 0.0000e+00\n",
      "Epoch 416/1000\n",
      "50/50 [==============================] - 43s 867ms/step - loss: 0.0000e+00\n",
      "Epoch 417/1000\n",
      "50/50 [==============================] - 43s 868ms/step - loss: 0.0000e+00\n",
      "Epoch 418/1000\n",
      "50/50 [==============================] - 44s 877ms/step - loss: 0.0000e+00\n",
      "Epoch 419/1000\n",
      "50/50 [==============================] - 43s 862ms/step - loss: 0.0000e+00\n",
      "Epoch 420/1000\n",
      "50/50 [==============================] - 44s 875ms/step - loss: 0.0000e+00\n",
      "Epoch 421/1000\n",
      "50/50 [==============================] - 45s 891ms/step - loss: 0.0000e+00\n",
      "Epoch 422/1000\n",
      "50/50 [==============================] - 43s 866ms/step - loss: 0.0000e+00\n",
      "Epoch 423/1000\n",
      "50/50 [==============================] - 44s 880ms/step - loss: 0.0000e+00\n",
      "Epoch 424/1000\n",
      "50/50 [==============================] - 44s 879ms/step - loss: 0.0000e+00\n",
      "Epoch 425/1000\n",
      "50/50 [==============================] - 43s 866ms/step - loss: 0.0000e+00\n",
      "Epoch 426/1000\n",
      "50/50 [==============================] - 43s 865ms/step - loss: 0.0000e+00\n",
      "Epoch 427/1000\n",
      "50/50 [==============================] - 44s 873ms/step - loss: 0.0000e+00\n",
      "Epoch 428/1000\n",
      "50/50 [==============================] - 43s 859ms/step - loss: 0.0000e+00\n",
      "Epoch 429/1000\n",
      "50/50 [==============================] - 44s 877ms/step - loss: 0.0000e+00\n",
      "Epoch 430/1000\n",
      "50/50 [==============================] - 43s 859ms/step - loss: 0.0000e+00\n",
      "Epoch 431/1000\n",
      "50/50 [==============================] - 44s 870ms/step - loss: 0.0000e+00\n",
      "Epoch 432/1000\n",
      "50/50 [==============================] - 44s 876ms/step - loss: 0.0000e+00\n",
      "Epoch 433/1000\n",
      "50/50 [==============================] - 43s 870ms/step - loss: 0.0000e+00\n",
      "Epoch 434/1000\n",
      "50/50 [==============================] - 44s 887ms/step - loss: 0.0000e+00\n",
      "Epoch 435/1000\n",
      "50/50 [==============================] - 44s 885ms/step - loss: 0.0000e+00\n",
      "Epoch 436/1000\n",
      "50/50 [==============================] - 44s 880ms/step - loss: 0.0000e+00\n",
      "Epoch 437/1000\n",
      "50/50 [==============================] - 45s 894ms/step - loss: 0.0000e+00\n",
      "Epoch 438/1000\n",
      "50/50 [==============================] - 44s 874ms/step - loss: 0.0000e+00\n",
      "Epoch 439/1000\n",
      "50/50 [==============================] - 44s 877ms/step - loss: 0.0000e+00\n",
      "Epoch 440/1000\n",
      "50/50 [==============================] - 44s 876ms/step - loss: 0.0000e+00\n",
      "Epoch 441/1000\n",
      "50/50 [==============================] - 44s 880ms/step - loss: 0.0000e+00\n",
      "Epoch 442/1000\n",
      "50/50 [==============================] - 44s 871ms/step - loss: 0.0000e+00\n",
      "Epoch 443/1000\n",
      "50/50 [==============================] - 44s 874ms/step - loss: 0.0000e+00\n",
      "Epoch 444/1000\n",
      "50/50 [==============================] - 43s 868ms/step - loss: 0.0000e+00\n",
      "Epoch 445/1000\n",
      "50/50 [==============================] - 43s 859ms/step - loss: 0.0000e+00\n",
      "Epoch 446/1000\n",
      "50/50 [==============================] - 44s 878ms/step - loss: 0.0000e+00\n",
      "Epoch 447/1000\n",
      "50/50 [==============================] - 43s 867ms/step - loss: 0.0000e+00\n",
      "Epoch 448/1000\n",
      "50/50 [==============================] - 44s 870ms/step - loss: 0.0000e+00\n",
      "Epoch 449/1000\n",
      "50/50 [==============================] - 42s 849ms/step - loss: 0.0000e+00\n",
      "Epoch 450/1000\n",
      "50/50 [==============================] - 44s 882ms/step - loss: 0.0015\n",
      "Epoch 451/1000\n",
      "50/50 [==============================] - 44s 871ms/step - loss: 0.0000e+00\n",
      "Epoch 452/1000\n",
      "50/50 [==============================] - 44s 872ms/step - loss: 0.0000e+00\n",
      "Epoch 453/1000\n",
      "50/50 [==============================] - 43s 855ms/step - loss: 0.0000e+00\n",
      "Epoch 454/1000\n",
      "50/50 [==============================] - 44s 879ms/step - loss: 0.0000e+00\n",
      "Epoch 455/1000\n",
      "50/50 [==============================] - 44s 889ms/step - loss: 0.0000e+00\n",
      "Epoch 456/1000\n",
      "50/50 [==============================] - 43s 865ms/step - loss: 0.0000e+00\n",
      "Epoch 457/1000\n",
      "50/50 [==============================] - 44s 874ms/step - loss: 0.0000e+00\n",
      "Epoch 458/1000\n",
      "50/50 [==============================] - 44s 876ms/step - loss: 0.0000e+00\n",
      "Epoch 459/1000\n",
      "50/50 [==============================] - 45s 893ms/step - loss: 0.0000e+00\n",
      "Epoch 460/1000\n",
      "50/50 [==============================] - 44s 879ms/step - loss: 0.0000e+00\n",
      "Epoch 461/1000\n",
      "50/50 [==============================] - 44s 877ms/step - loss: 0.0000e+00\n",
      "Epoch 462/1000\n",
      "50/50 [==============================] - 44s 882ms/step - loss: 0.0000e+00\n",
      "Epoch 463/1000\n",
      "50/50 [==============================] - 43s 858ms/step - loss: 0.0000e+00\n",
      "Epoch 464/1000\n",
      "50/50 [==============================] - 43s 866ms/step - loss: 2.0786e-05\n",
      "Epoch 465/1000\n",
      "50/50 [==============================] - 44s 871ms/step - loss: 0.0000e+00\n",
      "Epoch 466/1000\n",
      "50/50 [==============================] - 44s 884ms/step - loss: 0.0000e+00\n",
      "Epoch 467/1000\n",
      "50/50 [==============================] - 43s 868ms/step - loss: 0.0000e+00\n",
      "Epoch 468/1000\n",
      "50/50 [==============================] - 44s 875ms/step - loss: 0.0000e+00\n",
      "Epoch 469/1000\n",
      "50/50 [==============================] - 44s 884ms/step - loss: 0.0000e+00\n",
      "Epoch 470/1000\n",
      "50/50 [==============================] - 43s 858ms/step - loss: 0.0000e+00\n",
      "Epoch 471/1000\n",
      "50/50 [==============================] - 43s 861ms/step - loss: 0.0000e+00\n",
      "Epoch 472/1000\n",
      "50/50 [==============================] - 44s 872ms/step - loss: 0.0000e+00\n",
      "Epoch 473/1000\n",
      "50/50 [==============================] - 44s 888ms/step - loss: 0.0000e+00\n",
      "Epoch 474/1000\n",
      "50/50 [==============================] - 43s 860ms/step - loss: 0.0000e+00\n",
      "Epoch 475/1000\n",
      "50/50 [==============================] - 47s 934ms/step - loss: 7.2985e-05\n",
      "Epoch 476/1000\n",
      "50/50 [==============================] - 43s 852ms/step - loss: 0.0000e+00\n",
      "Epoch 477/1000\n",
      "50/50 [==============================] - 44s 877ms/step - loss: 0.0000e+00\n",
      "Epoch 478/1000\n",
      "50/50 [==============================] - 44s 874ms/step - loss: 0.0000e+00\n",
      "Epoch 479/1000\n",
      "50/50 [==============================] - 44s 890ms/step - loss: 0.0000e+00\n",
      "Epoch 480/1000\n",
      "50/50 [==============================] - 43s 857ms/step - loss: 0.0000e+00\n",
      "Epoch 481/1000\n",
      "50/50 [==============================] - 43s 867ms/step - loss: 0.0000e+00\n",
      "Epoch 482/1000\n",
      "50/50 [==============================] - 43s 862ms/step - loss: 0.0000e+00\n",
      "Epoch 483/1000\n",
      "50/50 [==============================] - 43s 868ms/step - loss: 0.0000e+00\n",
      "Epoch 484/1000\n",
      "50/50 [==============================] - 44s 872ms/step - loss: 0.0000e+00\n",
      "Epoch 485/1000\n",
      "50/50 [==============================] - 44s 875ms/step - loss: 0.0000e+00\n",
      "Epoch 486/1000\n",
      "50/50 [==============================] - 45s 895ms/step - loss: 0.0000e+00\n",
      "Epoch 487/1000\n",
      "50/50 [==============================] - 43s 868ms/step - loss: 0.0000e+00\n",
      "Epoch 488/1000\n",
      "50/50 [==============================] - 44s 873ms/step - loss: 0.0000e+00\n",
      "Epoch 489/1000\n",
      "50/50 [==============================] - 44s 877ms/step - loss: 0.0000e+00\n",
      "Epoch 490/1000\n",
      "50/50 [==============================] - 44s 871ms/step - loss: 0.0000e+00\n",
      "Epoch 491/1000\n",
      "50/50 [==============================] - 44s 888ms/step - loss: 0.0000e+00\n",
      "Epoch 492/1000\n",
      "50/50 [==============================] - 44s 882ms/step - loss: 0.0000e+00\n",
      "Epoch 493/1000\n",
      "50/50 [==============================] - 44s 877ms/step - loss: 0.0000e+00\n",
      "Epoch 494/1000\n",
      "50/50 [==============================] - 44s 887ms/step - loss: 0.0000e+00\n",
      "Epoch 495/1000\n",
      "50/50 [==============================] - 44s 870ms/step - loss: 0.0000e+00\n",
      "Epoch 496/1000\n",
      "50/50 [==============================] - 44s 885ms/step - loss: 0.0000e+00\n",
      "Epoch 497/1000\n",
      "50/50 [==============================] - 43s 865ms/step - loss: 0.0000e+00\n",
      "Epoch 498/1000\n",
      "50/50 [==============================] - 44s 884ms/step - loss: 0.0000e+00\n",
      "Epoch 499/1000\n",
      "50/50 [==============================] - 44s 878ms/step - loss: 0.0000e+00\n",
      "Epoch 500/1000\n",
      "50/50 [==============================] - 43s 865ms/step - loss: 0.0000e+00\n",
      "Epoch 501/1000\n",
      "50/50 [==============================] - 44s 881ms/step - loss: 0.0000e+00\n",
      "Epoch 502/1000\n",
      "50/50 [==============================] - 43s 859ms/step - loss: 0.0000e+00\n",
      "Epoch 503/1000\n",
      "50/50 [==============================] - 43s 860ms/step - loss: 0.0000e+00\n",
      "Epoch 504/1000\n",
      "50/50 [==============================] - 43s 867ms/step - loss: 0.0000e+00\n",
      "Epoch 505/1000\n",
      "50/50 [==============================] - 44s 876ms/step - loss: 0.0000e+00\n",
      "Epoch 506/1000\n",
      "50/50 [==============================] - 44s 883ms/step - loss: 0.0000e+00\n",
      "Epoch 507/1000\n",
      "50/50 [==============================] - 43s 865ms/step - loss: 0.0000e+00\n",
      "Epoch 508/1000\n",
      "50/50 [==============================] - 45s 892ms/step - loss: 0.0000e+00\n",
      "Epoch 509/1000\n",
      "50/50 [==============================] - 44s 886ms/step - loss: 0.0000e+00\n",
      "Epoch 510/1000\n",
      "50/50 [==============================] - 42s 849ms/step - loss: 0.0000e+00\n",
      "Epoch 511/1000\n",
      "50/50 [==============================] - 43s 869ms/step - loss: 0.0000e+00\n",
      "Epoch 512/1000\n",
      "50/50 [==============================] - 44s 883ms/step - loss: 0.0000e+00\n",
      "Epoch 513/1000\n",
      "50/50 [==============================] - 44s 876ms/step - loss: 0.0000e+00\n",
      "Epoch 514/1000\n",
      "50/50 [==============================] - 45s 900ms/step - loss: 0.0000e+00\n",
      "Epoch 515/1000\n",
      "50/50 [==============================] - 44s 874ms/step - loss: 0.0000e+00\n",
      "Epoch 516/1000\n",
      "50/50 [==============================] - 44s 888ms/step - loss: 0.0000e+00\n",
      "Epoch 517/1000\n",
      "50/50 [==============================] - 43s 855ms/step - loss: 0.0000e+00\n",
      "Epoch 518/1000\n",
      "50/50 [==============================] - 43s 870ms/step - loss: 0.0000e+00\n",
      "Epoch 519/1000\n",
      "50/50 [==============================] - 44s 887ms/step - loss: 0.0000e+00\n",
      "Epoch 520/1000\n",
      "50/50 [==============================] - 43s 862ms/step - loss: 0.0000e+00\n",
      "Epoch 521/1000\n",
      "50/50 [==============================] - 44s 889ms/step - loss: 0.0000e+00\n",
      "Epoch 522/1000\n",
      "50/50 [==============================] - 43s 870ms/step - loss: 0.0000e+00\n",
      "Epoch 523/1000\n",
      "50/50 [==============================] - 44s 874ms/step - loss: 0.0000e+00\n",
      "Epoch 524/1000\n",
      "50/50 [==============================] - 44s 872ms/step - loss: 0.0000e+00\n",
      "Epoch 525/1000\n",
      "50/50 [==============================] - 44s 888ms/step - loss: 0.0000e+00\n",
      "Epoch 526/1000\n",
      "50/50 [==============================] - 44s 888ms/step - loss: 0.0000e+00\n",
      "Epoch 527/1000\n",
      "50/50 [==============================] - 44s 882ms/step - loss: 0.0000e+00\n",
      "Epoch 528/1000\n",
      "50/50 [==============================] - 44s 886ms/step - loss: 0.0000e+00\n",
      "Epoch 529/1000\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.0000e+00\n",
      "Epoch 530/1000\n",
      "50/50 [==============================] - 46s 926ms/step - loss: 0.0000e+00\n",
      "Epoch 531/1000\n",
      "50/50 [==============================] - 44s 883ms/step - loss: 0.0000e+00\n",
      "Epoch 532/1000\n",
      "50/50 [==============================] - 43s 866ms/step - loss: 0.0000e+00\n",
      "Epoch 533/1000\n",
      "50/50 [==============================] - 44s 886ms/step - loss: 0.0000e+00\n",
      "Epoch 534/1000\n",
      "50/50 [==============================] - 43s 870ms/step - loss: 0.0000e+00\n",
      "Epoch 535/1000\n",
      "50/50 [==============================] - 44s 879ms/step - loss: 0.0000e+00\n",
      "Epoch 536/1000\n",
      "50/50 [==============================] - 44s 884ms/step - loss: 0.0000e+00\n",
      "Epoch 537/1000\n",
      "50/50 [==============================] - 44s 887ms/step - loss: 0.0000e+00\n",
      "Epoch 538/1000\n",
      "50/50 [==============================] - 44s 876ms/step - loss: 0.0000e+00\n",
      "Epoch 539/1000\n",
      "50/50 [==============================] - 45s 891ms/step - loss: 0.0000e+00\n",
      "Epoch 540/1000\n",
      "50/50 [==============================] - 44s 880ms/step - loss: 0.0000e+00\n",
      "Epoch 541/1000\n",
      "50/50 [==============================] - 44s 883ms/step - loss: 0.0000e+00\n",
      "Epoch 542/1000\n",
      "50/50 [==============================] - 44s 880ms/step - loss: 0.0000e+00\n",
      "Epoch 543/1000\n",
      "50/50 [==============================] - 45s 891ms/step - loss: 0.0000e+00\n",
      "Epoch 544/1000\n",
      "50/50 [==============================] - 45s 894ms/step - loss: 0.0000e+00\n",
      "Epoch 545/1000\n",
      "50/50 [==============================] - 43s 869ms/step - loss: 0.0000e+00\n",
      "Epoch 546/1000\n",
      "50/50 [==============================] - 44s 882ms/step - loss: 0.0000e+00\n",
      "Epoch 547/1000\n",
      "50/50 [==============================] - 44s 872ms/step - loss: 0.0000e+00\n",
      "Epoch 548/1000\n",
      "50/50 [==============================] - 45s 896ms/step - loss: 0.0000e+00\n",
      "Epoch 549/1000\n",
      "50/50 [==============================] - 44s 871ms/step - loss: 0.0000e+00\n",
      "Epoch 550/1000\n",
      "50/50 [==============================] - 44s 880ms/step - loss: 0.0000e+00\n",
      "Epoch 551/1000\n",
      "50/50 [==============================] - 43s 863ms/step - loss: 0.0000e+00\n",
      "Epoch 552/1000\n",
      "50/50 [==============================] - 44s 875ms/step - loss: 0.0000e+00\n",
      "Epoch 553/1000\n",
      "50/50 [==============================] - 44s 881ms/step - loss: 0.0000e+00\n",
      "Epoch 554/1000\n",
      "50/50 [==============================] - 44s 883ms/step - loss: 0.0000e+00\n",
      "Epoch 555/1000\n",
      "50/50 [==============================] - 44s 888ms/step - loss: 0.0000e+00\n",
      "Epoch 556/1000\n",
      "50/50 [==============================] - 44s 890ms/step - loss: 0.0000e+00\n",
      "Epoch 557/1000\n",
      "50/50 [==============================] - 43s 860ms/step - loss: 0.0000e+00\n",
      "Epoch 558/1000\n",
      "50/50 [==============================] - 43s 866ms/step - loss: 0.0000e+00\n",
      "Epoch 559/1000\n",
      "50/50 [==============================] - 44s 882ms/step - loss: 0.0000e+00\n",
      "Epoch 560/1000\n",
      "50/50 [==============================] - 45s 897ms/step - loss: 0.0000e+00\n",
      "Epoch 561/1000\n",
      "50/50 [==============================] - 44s 880ms/step - loss: 0.0000e+00\n",
      "Epoch 562/1000\n",
      "50/50 [==============================] - 43s 865ms/step - loss: 0.0000e+00\n",
      "Epoch 563/1000\n",
      "50/50 [==============================] - 47s 940ms/step - loss: 0.0000e+00\n",
      "Epoch 564/1000\n",
      " 3/50 [>.............................] - ETA: 40s - loss: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-abf9ce4b8ca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_triplets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ammd/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/ammd/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ammd/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m~/anaconda3/envs/ammd/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ammd/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ammd/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    266\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backwards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m           \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m           if isinstance(model.optimizer,\n\u001b[1;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n",
      "\u001b[0;32m~/anaconda3/envs/ammd/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ammd/lib/python3.6/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ammd/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ammd/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    604\u001b[0m           \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m           data_format=data_format)\n\u001b[0m\u001b[1;32m    607\u001b[0m   ]\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ammd/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_filter\u001b[0;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0mfilter_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_backprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m         explicit_paddings, \"data_format\", data_format, \"dilations\", dilations)\n\u001b[0m\u001b[1;32m   1188\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "s1.fit_generator(create_triplets(50, embeddings, images), epochs=1000, steps_per_epoch=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show TSNE After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ec7JVXihGCxZ"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_embs = np.zeros(shape=(0,64))\n",
    "labels = np.zeros(shape=(0,1))\n",
    "count = 1\n",
    "for (person, embs) in embeddings.items():\n",
    "    combined_embs = np.append( combined_embs,  embs, axis=0)\n",
    "    l = np.zeros((len(embs), 1)) + count\n",
    "    labels = np.append( labels,  l, axis=0)\n",
    "    count = count + 1\n",
    "#     if count>10:\n",
    "#         break\n",
    "\n",
    "labels = labels.flatten()\n",
    "embs_2d = TSNE().fit_transform(combined_embs)\n",
    "scatter(embs_2d, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t83rwHU-GCxd"
   },
   "source": [
    "## Evaluation of model\n",
    "\n",
    "* Get Embeddings\n",
    "* Create a shallow neural network\n",
    "* Train this network to decide if two embs is from the same person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_anchor_val = embs_model.predict(X_val[0])\n",
    "embs_pos_val = embs_model.predict(X_val[1])\n",
    "embs_neg_val = embs_model.predict(X_val[2])\n",
    "\n",
    "embs_anchor_train = embs_model.predict(X_train[0])\n",
    "embs_pos_train = embs_model.predict(X_train[1])\n",
    "embs_neg_train = embs_model.predict(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128)          0           input_11[0][0]                   \n",
      "                                                                 input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           8256        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           2080        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            33          dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 10,369\n",
      "Trainable params: 10,369\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pred_model_inp_a = Input(shape=(64,))\n",
    "pred_model_inp_b = Input(shape=(64,))\n",
    "\n",
    "pred_model = Dense(64, activation='relu')(tf.keras.layers.concatenate([pred_model_inp_a, pred_model_inp_b]))\n",
    "pred_model = Dense(32, activation='relu')(pred_model)\n",
    "pred_model_output = Dense(1, activation='sigmoid')(pred_model)\n",
    "\n",
    "pred_model = Model(inputs=[pred_model_inp_a, pred_model_inp_b], outputs=pred_model_output)\n",
    "\n",
    "pred_model.compile(loss='binary_crossentropy')\n",
    "pred_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000 samples\n",
      "Epoch 1/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4496\n",
      "Epoch 2/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4410\n",
      "Epoch 3/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4366\n",
      "Epoch 4/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4307\n",
      "Epoch 5/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4283\n",
      "Epoch 6/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.4245\n",
      "Epoch 7/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.4216\n",
      "Epoch 8/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4188\n",
      "Epoch 9/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4162\n",
      "Epoch 10/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4131\n",
      "Epoch 11/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.4106\n",
      "Epoch 12/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4080\n",
      "Epoch 13/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4059\n",
      "Epoch 14/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4053\n",
      "Epoch 15/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.4024\n",
      "Epoch 16/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3992\n",
      "Epoch 17/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3965\n",
      "Epoch 18/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3948\n",
      "Epoch 19/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3937\n",
      "Epoch 20/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3922\n",
      "Epoch 21/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3901\n",
      "Epoch 22/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3900\n",
      "Epoch 23/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3872\n",
      "Epoch 24/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3857\n",
      "Epoch 25/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3839\n",
      "Epoch 26/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3835\n",
      "Epoch 27/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3837\n",
      "Epoch 28/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3828\n",
      "Epoch 29/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3813\n",
      "Epoch 30/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3802\n",
      "Epoch 31/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3786\n",
      "Epoch 32/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3772\n",
      "Epoch 33/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3767\n",
      "Epoch 34/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3765\n",
      "Epoch 35/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3744\n",
      "Epoch 36/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3741\n",
      "Epoch 37/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3726\n",
      "Epoch 38/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3727\n",
      "Epoch 39/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3719\n",
      "Epoch 40/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3710\n",
      "Epoch 41/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3705\n",
      "Epoch 42/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3690\n",
      "Epoch 43/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3690\n",
      "Epoch 44/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3687\n",
      "Epoch 45/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3676\n",
      "Epoch 46/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3680\n",
      "Epoch 47/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3662\n",
      "Epoch 48/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3671\n",
      "Epoch 49/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3655\n",
      "Epoch 50/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3651\n",
      "Epoch 51/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3643\n",
      "Epoch 52/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3644\n",
      "Epoch 53/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3635\n",
      "Epoch 54/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3622\n",
      "Epoch 55/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3624\n",
      "Epoch 56/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3612\n",
      "Epoch 57/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3614\n",
      "Epoch 58/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3611\n",
      "Epoch 59/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3615\n",
      "Epoch 60/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3612\n",
      "Epoch 61/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3590\n",
      "Epoch 62/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3595\n",
      "Epoch 63/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3589\n",
      "Epoch 64/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3584\n",
      "Epoch 65/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3580\n",
      "Epoch 66/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3579\n",
      "Epoch 67/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3578\n",
      "Epoch 68/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3564\n",
      "Epoch 69/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3565\n",
      "Epoch 70/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3567\n",
      "Epoch 71/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3566\n",
      "Epoch 72/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3568\n",
      "Epoch 73/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3550\n",
      "Epoch 74/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3559\n",
      "Epoch 75/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3549\n",
      "Epoch 76/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3537\n",
      "Epoch 77/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3536\n",
      "Epoch 78/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3540\n",
      "Epoch 79/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3547\n",
      "Epoch 80/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3545\n",
      "Epoch 81/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3543\n",
      "Epoch 82/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3519\n",
      "Epoch 83/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3537\n",
      "Epoch 84/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3529\n",
      "Epoch 85/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3523\n",
      "Epoch 86/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3527\n",
      "Epoch 87/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3521\n",
      "Epoch 00087: early stopping\n",
      "Train on 100000 samples\n",
      "Epoch 1/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4177\n",
      "Epoch 2/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.4079\n",
      "Epoch 3/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4011\n",
      "Epoch 4/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3987\n",
      "Epoch 5/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3954\n",
      "Epoch 6/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3919\n",
      "Epoch 7/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3915\n",
      "Epoch 8/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3895\n",
      "Epoch 9/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3868\n",
      "Epoch 10/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3860\n",
      "Epoch 11/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3858\n",
      "Epoch 12/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3834\n",
      "Epoch 13/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3830\n",
      "Epoch 14/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3803\n",
      "Epoch 15/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3804\n",
      "Epoch 16/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3788\n",
      "Epoch 17/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3789\n",
      "Epoch 18/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3770\n",
      "Epoch 19/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3766\n",
      "Epoch 20/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3762\n",
      "Epoch 21/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3742\n",
      "Epoch 22/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3742\n",
      "Epoch 23/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3736\n",
      "Epoch 24/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3733\n",
      "Epoch 25/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3729\n",
      "Epoch 26/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3714\n",
      "Epoch 27/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3723\n",
      "Epoch 28/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3694\n",
      "Epoch 29/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3707\n",
      "Epoch 30/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3686\n",
      "Epoch 31/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3684\n",
      "Epoch 32/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3681\n",
      "Epoch 33/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3679\n",
      "Epoch 34/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3669\n",
      "Epoch 35/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3664\n",
      "Epoch 36/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3651\n",
      "Epoch 37/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3654\n",
      "Epoch 38/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3657\n",
      "Epoch 39/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3650\n",
      "Epoch 40/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3643\n",
      "Epoch 41/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3650\n",
      "Epoch 42/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3636\n",
      "Epoch 43/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3634\n",
      "Epoch 44/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3647\n",
      "Epoch 45/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3639\n",
      "Epoch 46/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3628\n",
      "Epoch 47/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3627\n",
      "Epoch 48/5000\n",
      "100000/100000 [==============================] - 9s 95us/sample - loss: 0.3615\n",
      "Epoch 49/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3604\n",
      "Epoch 50/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3611\n",
      "Epoch 51/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3612\n",
      "Epoch 52/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3604\n",
      "Epoch 53/5000\n",
      "100000/100000 [==============================] - 10s 99us/sample - loss: 0.3606\n",
      "Epoch 54/5000\n",
      "100000/100000 [==============================] - 10s 96us/sample - loss: 0.3593\n",
      "Epoch 55/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3596\n",
      "Epoch 56/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3591\n",
      "Epoch 57/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3590\n",
      "Epoch 58/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3578\n",
      "Epoch 59/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3579\n",
      "Epoch 60/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3590\n",
      "Epoch 61/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3575\n",
      "Epoch 62/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3563\n",
      "Epoch 63/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3570\n",
      "Epoch 64/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3567\n",
      "Epoch 65/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3578\n",
      "Epoch 66/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3573\n",
      "Epoch 67/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3569\n",
      "Epoch 00067: early stopping\n",
      "Train on 100000 samples\n",
      "Epoch 1/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4150\n",
      "Epoch 2/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4050\n",
      "Epoch 3/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.4009\n",
      "Epoch 4/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3955\n",
      "Epoch 5/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3934\n",
      "Epoch 6/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3914\n",
      "Epoch 7/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3903\n",
      "Epoch 8/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3881\n",
      "Epoch 9/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3861\n",
      "Epoch 10/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3839\n",
      "Epoch 11/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3843\n",
      "Epoch 12/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3824\n",
      "Epoch 13/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3799\n",
      "Epoch 14/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3806\n",
      "Epoch 15/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3785\n",
      "Epoch 16/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3782\n",
      "Epoch 17/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3763\n",
      "Epoch 18/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3776\n",
      "Epoch 19/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3748\n",
      "Epoch 20/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3745\n",
      "Epoch 21/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3736\n",
      "Epoch 22/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3735\n",
      "Epoch 23/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3724\n",
      "Epoch 24/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3713\n",
      "Epoch 25/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3717\n",
      "Epoch 26/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3716\n",
      "Epoch 27/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3704\n",
      "Epoch 28/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3705\n",
      "Epoch 29/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3697\n",
      "Epoch 30/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3697\n",
      "Epoch 31/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3688\n",
      "Epoch 32/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3680\n",
      "Epoch 33/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3669\n",
      "Epoch 34/5000\n",
      "100000/100000 [==============================] - 9s 95us/sample - loss: 0.3681\n",
      "Epoch 35/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3675\n",
      "Epoch 36/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3656\n",
      "Epoch 37/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3651\n",
      "Epoch 38/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3651\n",
      "Epoch 39/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3647\n",
      "Epoch 40/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3652\n",
      "Epoch 41/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3641\n",
      "Epoch 42/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3639\n",
      "Epoch 43/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3636\n",
      "Epoch 44/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3634\n",
      "Epoch 45/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3637\n",
      "Epoch 46/5000\n",
      "100000/100000 [==============================] - 9s 95us/sample - loss: 0.3627\n",
      "Epoch 47/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3623\n",
      "Epoch 48/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3633\n",
      "Epoch 49/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3618\n",
      "Epoch 50/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3616\n",
      "Epoch 51/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3625\n",
      "Epoch 52/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3605\n",
      "Epoch 53/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3606\n",
      "Epoch 54/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3602\n",
      "Epoch 55/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3609\n",
      "Epoch 56/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3603\n",
      "Epoch 57/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3601\n",
      "Epoch 58/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3601\n",
      "Epoch 59/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3599\n",
      "Epoch 60/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3583\n",
      "Epoch 61/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3592\n",
      "Epoch 62/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3592\n",
      "Epoch 63/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3603\n",
      "Epoch 64/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3574\n",
      "Epoch 65/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3576\n",
      "Epoch 66/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3572\n",
      "Epoch 67/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3575\n",
      "Epoch 68/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3571\n",
      "Epoch 69/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3569\n",
      "Epoch 70/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3568\n",
      "Epoch 71/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3558\n",
      "Epoch 72/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3563\n",
      "Epoch 73/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3569\n",
      "Epoch 74/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3565\n",
      "Epoch 75/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3576\n",
      "Epoch 76/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3550\n",
      "Epoch 77/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3568\n",
      "Epoch 78/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3563\n",
      "Epoch 79/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3551\n",
      "Epoch 80/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3556\n",
      "Epoch 81/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3568\n",
      "Epoch 00081: early stopping\n",
      "Train on 100000 samples\n",
      "Epoch 1/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.4220\n",
      "Epoch 2/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.4109\n",
      "Epoch 3/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4072\n",
      "Epoch 4/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4019\n",
      "Epoch 5/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3973\n",
      "Epoch 6/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3947\n",
      "Epoch 7/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3940\n",
      "Epoch 8/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3921\n",
      "Epoch 9/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3907\n",
      "Epoch 10/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3884\n",
      "Epoch 11/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3873\n",
      "Epoch 12/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3862\n",
      "Epoch 13/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3838\n",
      "Epoch 14/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3850\n",
      "Epoch 15/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3822\n",
      "Epoch 16/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3824\n",
      "Epoch 17/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3802\n",
      "Epoch 18/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3805\n",
      "Epoch 19/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3800\n",
      "Epoch 20/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3790\n",
      "Epoch 21/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3789\n",
      "Epoch 22/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3781\n",
      "Epoch 23/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3774\n",
      "Epoch 24/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3773\n",
      "Epoch 25/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3749\n",
      "Epoch 26/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3755\n",
      "Epoch 27/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3741\n",
      "Epoch 28/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3740\n",
      "Epoch 29/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3729\n",
      "Epoch 30/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3727\n",
      "Epoch 31/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3729\n",
      "Epoch 32/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3746\n",
      "Epoch 33/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3713\n",
      "Epoch 34/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3721\n",
      "Epoch 35/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3715\n",
      "Epoch 36/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3712\n",
      "Epoch 37/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3696\n",
      "Epoch 38/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3709\n",
      "Epoch 39/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3691\n",
      "Epoch 40/5000\n",
      "100000/100000 [==============================] - 9s 89us/sample - loss: 0.3696\n",
      "Epoch 41/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3684\n",
      "Epoch 42/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3684\n",
      "Epoch 43/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3690\n",
      "Epoch 44/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3683\n",
      "Epoch 45/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3670\n",
      "Epoch 46/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3670\n",
      "Epoch 47/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3675\n",
      "Epoch 48/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3663\n",
      "Epoch 49/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3643\n",
      "Epoch 50/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3668\n",
      "Epoch 51/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3647\n",
      "Epoch 52/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3653\n",
      "Epoch 53/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3639\n",
      "Epoch 54/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3635\n",
      "Epoch 55/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3647\n",
      "Epoch 56/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3636\n",
      "Epoch 57/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3636\n",
      "Epoch 58/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3647\n",
      "Epoch 59/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3635\n",
      "Epoch 60/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3634\n",
      "Epoch 61/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3629\n",
      "Epoch 62/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3632\n",
      "Epoch 63/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3628\n",
      "Epoch 64/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3633\n",
      "Epoch 65/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3628\n",
      "Epoch 66/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3629\n",
      "Epoch 67/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3617\n",
      "Epoch 68/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3611\n",
      "Epoch 69/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3619\n",
      "Epoch 70/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3632\n",
      "Epoch 71/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3598\n",
      "Epoch 72/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3619\n",
      "Epoch 73/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3617\n",
      "Epoch 74/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3610\n",
      "Epoch 75/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3608\n",
      "Epoch 76/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3607\n",
      "Epoch 00076: early stopping\n",
      "Train on 100000 samples\n",
      "Epoch 1/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.4182\n",
      "Epoch 2/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.4105\n",
      "Epoch 3/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4054\n",
      "Epoch 4/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.4014\n",
      "Epoch 5/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3975\n",
      "Epoch 6/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3959\n",
      "Epoch 7/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3927\n",
      "Epoch 8/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3908\n",
      "Epoch 9/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3896\n",
      "Epoch 10/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3886\n",
      "Epoch 11/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3876\n",
      "Epoch 12/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3857\n",
      "Epoch 13/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3848\n",
      "Epoch 14/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3825\n",
      "Epoch 15/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3830\n",
      "Epoch 16/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3817\n",
      "Epoch 17/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3801\n",
      "Epoch 18/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3790\n",
      "Epoch 19/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3787\n",
      "Epoch 20/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3784\n",
      "Epoch 21/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3761\n",
      "Epoch 22/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3779\n",
      "Epoch 23/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3764\n",
      "Epoch 24/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3738\n",
      "Epoch 25/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3745\n",
      "Epoch 26/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3749\n",
      "Epoch 27/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3729\n",
      "Epoch 28/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3722\n",
      "Epoch 29/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3725\n",
      "Epoch 30/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3729\n",
      "Epoch 31/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3724\n",
      "Epoch 32/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3725\n",
      "Epoch 33/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3710\n",
      "Epoch 34/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3710\n",
      "Epoch 35/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3702\n",
      "Epoch 36/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3710\n",
      "Epoch 37/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3704\n",
      "Epoch 38/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3701\n",
      "Epoch 39/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3700\n",
      "Epoch 40/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3696\n",
      "Epoch 41/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3691\n",
      "Epoch 42/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3691\n",
      "Epoch 43/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3685\n",
      "Epoch 44/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3674\n",
      "Epoch 45/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3666\n",
      "Epoch 46/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3666\n",
      "Epoch 47/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3668\n",
      "Epoch 48/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3660\n",
      "Epoch 49/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3659\n",
      "Epoch 50/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3646\n",
      "Epoch 51/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3653\n",
      "Epoch 52/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3652\n",
      "Epoch 53/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3654\n",
      "Epoch 54/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3647\n",
      "Epoch 55/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3654\n",
      "Epoch 00055: early stopping\n",
      "Train on 100000 samples\n",
      "Epoch 1/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.4153\n",
      "Epoch 2/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4100\n",
      "Epoch 3/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4050\n",
      "Epoch 4/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4030\n",
      "Epoch 5/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3992\n",
      "Epoch 6/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3957\n",
      "Epoch 7/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3967\n",
      "Epoch 8/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3925\n",
      "Epoch 9/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3938\n",
      "Epoch 10/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3913\n",
      "Epoch 11/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3914\n",
      "Epoch 12/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3869\n",
      "Epoch 13/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3859\n",
      "Epoch 14/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3864\n",
      "Epoch 15/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3856\n",
      "Epoch 16/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3830\n",
      "Epoch 17/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3835\n",
      "Epoch 18/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3828\n",
      "Epoch 19/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3834\n",
      "Epoch 20/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3803\n",
      "Epoch 21/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3810\n",
      "Epoch 22/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3794\n",
      "Epoch 23/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3776\n",
      "Epoch 24/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3785\n",
      "Epoch 25/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3774\n",
      "Epoch 26/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3770\n",
      "Epoch 27/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3785\n",
      "Epoch 28/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3756\n",
      "Epoch 29/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3749\n",
      "Epoch 30/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3754\n",
      "Epoch 31/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3747\n",
      "Epoch 32/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3740\n",
      "Epoch 33/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3736\n",
      "Epoch 34/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3734\n",
      "Epoch 35/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3730\n",
      "Epoch 36/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3728\n",
      "Epoch 37/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3739\n",
      "Epoch 38/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3703\n",
      "Epoch 39/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3704\n",
      "Epoch 40/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3725\n",
      "Epoch 41/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3728\n",
      "Epoch 42/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3711\n",
      "Epoch 43/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3699\n",
      "Epoch 44/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3717\n",
      "Epoch 45/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3710\n",
      "Epoch 46/5000\n",
      "100000/100000 [==============================] - 10s 95us/sample - loss: 0.3699\n",
      "Epoch 47/5000\n",
      "100000/100000 [==============================] - 10s 96us/sample - loss: 0.3694\n",
      "Epoch 48/5000\n",
      "100000/100000 [==============================] - 10s 96us/sample - loss: 0.3691\n",
      "Epoch 49/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3680\n",
      "Epoch 50/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3687\n",
      "Epoch 51/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3690\n",
      "Epoch 52/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3701\n",
      "Epoch 53/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3668\n",
      "Epoch 54/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3678\n",
      "Epoch 55/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3664\n",
      "Epoch 56/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3662\n",
      "Epoch 57/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3653\n",
      "Epoch 58/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3648\n",
      "Epoch 59/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3673\n",
      "Epoch 60/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3641\n",
      "Epoch 61/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3642\n",
      "Epoch 62/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3650\n",
      "Epoch 63/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3663\n",
      "Epoch 64/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3654\n",
      "Epoch 65/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3654\n",
      "Epoch 00065: early stopping\n",
      "Train on 100000 samples\n",
      "Epoch 1/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.4236\n",
      "Epoch 2/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4150\n",
      "Epoch 3/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4103\n",
      "Epoch 4/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4084\n",
      "Epoch 5/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.4019\n",
      "Epoch 6/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4005\n",
      "Epoch 7/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3970\n",
      "Epoch 8/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3959\n",
      "Epoch 9/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3957\n",
      "Epoch 10/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3921\n",
      "Epoch 11/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3907\n",
      "Epoch 12/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3895\n",
      "Epoch 13/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3906\n",
      "Epoch 14/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3887\n",
      "Epoch 15/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3891\n",
      "Epoch 16/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3912\n",
      "Epoch 17/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3832\n",
      "Epoch 18/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3872\n",
      "Epoch 19/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3840\n",
      "Epoch 20/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3841\n",
      "Epoch 21/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3838\n",
      "Epoch 22/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3824\n",
      "Epoch 23/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3828\n",
      "Epoch 24/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3803\n",
      "Epoch 25/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3830\n",
      "Epoch 26/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3781\n",
      "Epoch 27/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3804\n",
      "Epoch 28/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3835\n",
      "Epoch 29/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3794\n",
      "Epoch 30/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3801\n",
      "Epoch 31/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3766\n",
      "Epoch 32/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3783\n",
      "Epoch 33/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3786\n",
      "Epoch 34/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3757\n",
      "Epoch 35/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3759\n",
      "Epoch 36/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3778\n",
      "Epoch 37/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3741\n",
      "Epoch 38/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3764\n",
      "Epoch 39/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3762\n",
      "Epoch 40/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3780\n",
      "Epoch 41/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3771\n",
      "Epoch 42/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3753\n",
      "Epoch 00042: early stopping\n",
      "Train on 100000 samples\n",
      "Epoch 1/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4175\n",
      "Epoch 2/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4118\n",
      "Epoch 3/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4064\n",
      "Epoch 4/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4058\n",
      "Epoch 5/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4017\n",
      "Epoch 6/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.4041\n",
      "Epoch 7/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3977\n",
      "Epoch 8/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3960\n",
      "Epoch 9/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3947\n",
      "Epoch 10/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3935\n",
      "Epoch 11/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3942\n",
      "Epoch 12/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3920\n",
      "Epoch 13/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3931\n",
      "Epoch 14/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3917\n",
      "Epoch 15/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3884\n",
      "Epoch 16/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3896\n",
      "Epoch 17/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3854\n",
      "Epoch 18/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3862\n",
      "Epoch 19/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3883\n",
      "Epoch 20/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3833\n",
      "Epoch 21/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3863\n",
      "Epoch 22/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3823\n",
      "Epoch 23/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3824\n",
      "Epoch 24/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3839\n",
      "Epoch 25/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3861\n",
      "Epoch 26/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3814\n",
      "Epoch 27/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3824\n",
      "Epoch 28/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3842\n",
      "Epoch 29/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3829\n",
      "Epoch 30/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3797\n",
      "Epoch 31/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3826\n",
      "Epoch 32/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3805\n",
      "Epoch 33/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3814\n",
      "Epoch 34/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3791\n",
      "Epoch 35/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3795\n",
      "Epoch 36/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3787\n",
      "Epoch 37/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3794\n",
      "Epoch 38/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3771\n",
      "Epoch 39/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3767\n",
      "Epoch 40/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3765\n",
      "Epoch 41/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3763\n",
      "Epoch 42/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3759\n",
      "Epoch 43/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3780\n",
      "Epoch 44/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3770\n",
      "Epoch 45/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3733\n",
      "Epoch 46/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3792\n",
      "Epoch 47/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3771\n",
      "Epoch 48/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3775\n",
      "Epoch 49/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3772\n",
      "Epoch 50/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3779\n",
      "Epoch 00050: early stopping\n",
      "Train on 100000 samples\n",
      "Epoch 1/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.4193\n",
      "Epoch 2/5000\n",
      "100000/100000 [==============================] - 10s 95us/sample - loss: 0.4113\n",
      "Epoch 3/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.4076\n",
      "Epoch 4/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4053\n",
      "Epoch 5/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3988\n",
      "Epoch 6/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3983\n",
      "Epoch 7/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3963\n",
      "Epoch 8/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3962\n",
      "Epoch 9/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3932\n",
      "Epoch 10/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3959\n",
      "Epoch 11/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3925\n",
      "Epoch 12/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3891\n",
      "Epoch 13/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3892\n",
      "Epoch 14/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3894\n",
      "Epoch 15/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3852\n",
      "Epoch 16/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3870\n",
      "Epoch 17/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3844\n",
      "Epoch 18/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3878\n",
      "Epoch 19/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3857\n",
      "Epoch 20/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.3835\n",
      "Epoch 21/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3868\n",
      "Epoch 22/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3806\n",
      "Epoch 23/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3880\n",
      "Epoch 24/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3868\n",
      "Epoch 25/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3852\n",
      "Epoch 26/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3789\n",
      "Epoch 27/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3825\n",
      "Epoch 28/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3789\n",
      "Epoch 29/5000\n",
      "100000/100000 [==============================] - 9s 90us/sample - loss: 0.3778\n",
      "Epoch 30/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3797\n",
      "Epoch 31/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3779\n",
      "Epoch 32/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3760\n",
      "Epoch 33/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3801\n",
      "Epoch 34/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3786\n",
      "Epoch 35/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3781\n",
      "Epoch 36/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3786\n",
      "Epoch 37/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3780\n",
      "Epoch 00037: early stopping\n",
      "Train on 100000 samples\n",
      "Epoch 1/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4307\n",
      "Epoch 2/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4296\n",
      "Epoch 3/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4196\n",
      "Epoch 4/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4169\n",
      "Epoch 5/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.4171\n",
      "Epoch 6/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4116\n",
      "Epoch 7/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.4072\n",
      "Epoch 8/5000\n",
      "100000/100000 [==============================] - 9s 94us/sample - loss: 0.4109\n",
      "Epoch 9/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.4060\n",
      "Epoch 10/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4030\n",
      "Epoch 11/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4027\n",
      "Epoch 12/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4026\n",
      "Epoch 13/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3979\n",
      "Epoch 14/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.4026\n",
      "Epoch 15/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3977\n",
      "Epoch 16/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3986\n",
      "Epoch 17/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3955\n",
      "Epoch 18/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3955\n",
      "Epoch 19/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3972\n",
      "Epoch 20/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3937\n",
      "Epoch 21/5000\n",
      "100000/100000 [==============================] - 9s 93us/sample - loss: 0.3907\n",
      "Epoch 22/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3922\n",
      "Epoch 23/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3965\n",
      "Epoch 24/5000\n",
      "100000/100000 [==============================] - 9s 91us/sample - loss: 0.3931\n",
      "Epoch 25/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3918\n",
      "Epoch 26/5000\n",
      "100000/100000 [==============================] - 9s 92us/sample - loss: 0.3923\n",
      "Epoch 00026: early stopping\n"
     ]
    }
   ],
   "source": [
    "early_stopping =  tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5, min_delta=0,\n",
    "                                                         verbose=1)\n",
    "for _ in range(10):\n",
    "    person_1 = []\n",
    "    person_2 = []\n",
    "    y_true = []\n",
    "    for i in range(100000):\n",
    "        person_idx = np.random.randint(embs_anchor_train.shape[0])\n",
    "        person_1.append(embs_anchor_train[person_idx])\n",
    "        \n",
    "        if random.random()>.5: # same person\n",
    "            person_2.append(embs_pos_train[person_idx])\n",
    "            y_true.append(1)\n",
    "        else: # different person\n",
    "            person_2.append(embs_neg_train[person_idx])\n",
    "            y_true.append(0)\n",
    "\n",
    "    pred_model.fit([np.array(person_1), np.array(person_2)], np.array(y_true), \n",
    "                   epochs=5000, callbacks=[early_stopping])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.38\n"
     ]
    }
   ],
   "source": [
    "person_1 = []\n",
    "person_2 = []\n",
    "y_true = []\n",
    "for i in range(10000):\n",
    "    person_idx = np.random.randint(embs_anchor_val.shape[0])\n",
    "    person_1.append(embs_anchor_val[person_idx])\n",
    "\n",
    "    if random.random()>.5: # same person\n",
    "        person_2.append(embs_pos_val[person_idx])\n",
    "        y_true.append(1)\n",
    "    else: # different person\n",
    "        person_2.append(embs_neg_val[person_idx])\n",
    "        y_true.append(0)\n",
    "\n",
    "y_pred = (pred_model.predict([np.array(person_1), np.array(person_2)]) > .5).flatten()\n",
    "y_true = np.array(y_true) > .5\n",
    "accuracy = np.sum(y_pred==y_true)/len(y_true)*100\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model.save('pred_model.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "AMMD2 - Siamesas 01.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
