{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm==4.28.1\n",
      "  Using cached https://files.pythonhosted.org/packages/91/55/8cb23a97301b177e9c8e3226dba45bb454411de2cbd25746763267f226c2/tqdm-4.28.1-py2.py3-none-any.whl\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.28.1\n",
      "Requirement already up-to-date: gast==0.2.2 in /opt/anaconda3/envs/siamesas/lib/python3.7/site-packages (0.2.2)\n",
      "Collecting gdown\n",
      "  Using cached https://files.pythonhosted.org/packages/b0/b4/a8e9d0b02bca6aa53087001abf064cc9992bda11bd6840875b8098d93573/gdown-3.8.3.tar.gz\n",
      "Collecting filelock\n",
      "  Using cached https://files.pythonhosted.org/packages/93/83/71a2ee6158bb9f39a90c0dea1637f81d5eef866e188e1971a1b1ab01a35a/filelock-3.0.12-py3-none-any.whl\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/siamesas/lib/python3.7/site-packages (from gdown) (2.22.0)\n",
      "Requirement already satisfied: six in /opt/anaconda3/envs/siamesas/lib/python3.7/site-packages (from gdown) (1.12.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/siamesas/lib/python3.7/site-packages (from gdown) (4.28.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/anaconda3/envs/siamesas/lib/python3.7/site-packages (from requests->gdown) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/envs/siamesas/lib/python3.7/site-packages (from requests->gdown) (1.25.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/siamesas/lib/python3.7/site-packages (from requests->gdown) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/anaconda3/envs/siamesas/lib/python3.7/site-packages (from requests->gdown) (2.8)\n",
      "Building wheels for collected packages: gdown\n",
      "  Building wheel for gdown (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gdown: filename=gdown-3.8.3-cp37-none-any.whl size=8852 sha256=e0d144f37ddd3acac0953840f5851a2236a72447abff4dbe929c5947a6324d07\n",
      "  Stored in directory: /home/joao/.cache/pip/wheels/a7/9d/16/9e0bda9a327ff2cddaee8de48a27553fb1efce73133593d066\n",
      "Successfully built gdown\n",
      "Installing collected packages: filelock, gdown\n",
      "Successfully installed filelock-3.0.12 gdown-3.8.3\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=14CB3Vw4jPf-8-DAriB9XDq4mfbs4o747\n",
      "To: /home/joao/Documents/Doutorado/ammd2-siamesas/airport-alunos.tgz\n",
      "533MB [02:28, 3.30MB/s] \n",
      "mkdir: cannot create directory ‘datasets’: File exists\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm==4.28.1\n",
    "!pip install -U gast==0.2.2\n",
    "!pip install gdown\n",
    "\n",
    "!gdown https://drive.google.com/uc?id=14CB3Vw4jPf-8-DAriB9XDq4mfbs4o747\n",
    "!mkdir datasets\n",
    "!tar -C datasets -xzf airport-alunos.tgz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "USM43pOIGCw2",
    "outputId": "0c9ddb6e-2d96-4ae8-a360-cdd3ccd5c200"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "4.28.1\n"
     ]
    }
   ],
   "source": [
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf; print(tf.__version__)\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_sample_image;\n",
    "\n",
    "import numpy as np\n",
    "import tqdm; print(tqdm.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "oeSbaC8eGCw9",
    "outputId": "d0544b8b-1e33-4c06-8327-36bc58211ca6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v3b_n2GaP-3H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hc66zI_QGCxB"
   },
   "outputs": [],
   "source": [
    "def base_model(input_shape):\n",
    "    \"\"\"\n",
    "        Model architecture\n",
    "    \"\"\"\n",
    "    \n",
    "    input_layer = Input(shape = input_shape)\n",
    "    \n",
    "    seq_model = Conv2D(8, (3, 3), activation = 'relu')(input_layer)\n",
    "    seq_model = BatchNormalization()(seq_model)\n",
    "    seq_model = Activation('relu')(seq_model)\n",
    "    seq_model = MaxPooling2D((2, 2), padding = 'same')(seq_model)\n",
    "    \n",
    "    seq_model = Conv2D(16, (3, 3), strides = (2, 2), padding = 'same')(seq_model)\n",
    "    seq_model = BatchNormalization()(seq_model)\n",
    "    seq_model = Activation('relu')(seq_model)\n",
    "    seq_model = MaxPooling2D((2, 2), padding = 'same')(seq_model)\n",
    "    \n",
    "    seq_model = Conv2D(32, (3, 3), strides = (2, 2), padding = 'same')(seq_model)\n",
    "    seq_model = BatchNormalization()(seq_model)\n",
    "    seq_model = Activation('relu')(seq_model)\n",
    "    seq_model = MaxPooling2D((2, 2), padding = 'same')(seq_model)\n",
    "    \n",
    "    seq_model = Conv2D(64, (3, 3), strides = (2, 2), padding = 'same')(seq_model)\n",
    "    seq_model = BatchNormalization()(seq_model)\n",
    "    seq_model = Activation('relu')(seq_model)\n",
    "    seq_model = MaxPooling2D((2, 2), padding = 'same')(seq_model)\n",
    "    \n",
    "    seq_model = Flatten()(seq_model)\n",
    "    seq_model = Dense(64)(seq_model)\n",
    "    \n",
    "    seq_model = Model(inputs=input_layer, outputs=seq_model)\n",
    "    \n",
    "    return seq_model\n",
    "  \n",
    "def siamise_model(input_shape):\n",
    "    \n",
    "    seq_model = base_model(input_shape)\n",
    "    \n",
    "    left_input = Input(shape = input_shape)\n",
    "    right_input = Input(shape = input_shape)\n",
    "    \n",
    "    left_encod = seq_model(left_input)\n",
    "    right_encod = seq_model(right_input)\n",
    "\n",
    "    lambda_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    lambda_distance  = lambda_layer([left_encod, right_encod])\n",
    "    \n",
    "    return Model(inputs=[left_input,right_input], outputs=lambda_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "DijeWsmwGCxF",
    "outputId": "b729d3cc-a32d-46f1-c24a-a51899ade55d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['datasets/airport-alunos/treino/0/000/000.png', 'datasets/airport-alunos/treino/0/000/001.png']\n",
      "['datasets/airport-alunos/val/0/200/000.png', 'datasets/airport-alunos/val/0/200/001.png']\n"
     ]
    }
   ],
   "source": [
    "file_names_treino = !find datasets/airport-alunos/treino -name '???.png' | sort\n",
    "file_names_val = !find datasets/airport-alunos/val -name '???.png' | sort\n",
    "\n",
    "print(file_names_treino[:2])\n",
    "print(file_names_val[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0zrwkBKwGCxJ"
   },
   "outputs": [],
   "source": [
    "#load_sample_image('datasets/airport-alunos/treino/0/094/051.png')\n",
    "\n",
    "#tf.image.decode_image(tf.io.read_file('datasets/airport-alunos/treino/0/094/051.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "6RhxRqtQGCxM",
    "outputId": "77d37dd7-a5f7-472c-c6fb-bf8baa89c370"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 374/2824 [00:00<00:01, 1631.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images in cam1 = 2824, cam2 = 3648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2824/2824 [00:01<00:00, 1698.64it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "def load_img(image_file):\n",
    "    return tf.io.read_file(image_file)\n",
    "\n",
    "def img_to_array(image_raw):\n",
    "    return tf.image.decode_image(image_raw)\n",
    "\n",
    "def person_to_img(file_names):\n",
    "    cam_path_to_img = {}\n",
    "    pids = [[], []]\n",
    "    img_counts = [0, 0]\n",
    "    for f in list(file_names):\n",
    "        cid = int(f.split('/')[-3])\n",
    "        pid = int(f.split('/')[-2])\n",
    "        iid = int(f.split('/')[-1][:3])\n",
    "        pids[cid].append((pid, iid))\n",
    "        cam_path_to_img[cid, pid, iid] = img_to_array(load_img(f))\n",
    "        img_counts[cid] += 1\n",
    "    print('Images in cam1 = %d, cam2 = %d'%(img_counts[0], img_counts[1]))\n",
    "    # dic person_to_img e person ids em cada camera\n",
    "    return cam_path_to_img, list(set(pids[0])), list(set(pids[1]))\n",
    "\n",
    "def filter_possible(pid1, pids2, same=True):\n",
    "    person_number = pid1[0]\n",
    "    if same is True:\n",
    "        possible_ids2 = [pid2 for pid2 in pids2 if pid2[0] == person_number]\n",
    "    else:\n",
    "        possible_ids2 = [pid2 for pid2 in pids2 if pid2[0] != person_number]\n",
    "    return possible_ids2\n",
    "\n",
    "def combine_cam_files(pids1, pids2):\n",
    "    i = 0\n",
    "    d = {}\n",
    "    for pid1 in tqdm(pids1):\n",
    "        if i % 2 == 0:\n",
    "            d[pid1] = filter_possible(pid1, pids2, same=True)\n",
    "        else:\n",
    "            d[pid1] = filter_possible(pid1, pids2, same=False)\n",
    "        i += 1\n",
    "    return d\n",
    "\n",
    "def get_batch(d_combination, cam_img_dict):\n",
    "    pairs_labels = []\n",
    "    i = 0\n",
    "    for key, value in d_combination.items():\n",
    "        if i % 2 == 0:\n",
    "            t = ((0, *key), (1, *random.choice(value)), 1.)\n",
    "        else:\n",
    "            t = ((0, *key), (1, *random.choice(value)), 0.)\n",
    "        i += 1\n",
    "        pairs_labels.append(t)\n",
    "    train_data = pairs_labels\n",
    "    X_a_train = np.array([cam_img_dict[x[0]] for x in train_data], dtype = np.float32)\n",
    "    X_b_train = np.array([cam_img_dict[x[1]] for x in train_data], dtype = np.float32)\n",
    "    y_train = np.array([x[2] for x in train_data], dtype = np.float32)\n",
    "    return X_a_train, X_b_train, y_train\n",
    "\n",
    "# carrega imagens para memória\n",
    "cam_img_dict_val, pids1_val, pids2_val = person_to_img(file_names_val)\n",
    "\n",
    "# gera listas de similares e dissimilares na memória\n",
    "d_combination_val = combine_cam_files(pids1_val, pids2_val)\n",
    "\n",
    "# obtem pares de batches apartir das imagens em memória\n",
    "X_a_val, X_b_val, y_val = get_batch(d_combination_val, cam_img_dict_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jh93gdL9GCxQ"
   },
   "outputs": [],
   "source": [
    "# plot pics side by side\n",
    "def show_side_by_side(figs, titles = None, limit = 10, figsize=(20, 4), cmap = 'gray', grid = False):\n",
    "    minval = min(limit, figs.shape[0])\n",
    "    plt.figure(figsize = figsize)\n",
    "    for i in range(minval):\n",
    "        subplot = plt.subplot(1, limit, i + 1)\n",
    "        extent = (0, figs[i].shape[1], figs[i].shape[0], 0)\n",
    "        subplot.imshow(figs[i], cmap = cmap, extent = extent)\n",
    "        if titles:\n",
    "            subplot.set_title(titles[i])\n",
    "        if grid:\n",
    "            subplot.grid(color='gray', linestyle='-', linewidth=1)\n",
    "        else:\n",
    "            subplot.get_xaxis().set_visible(False)\n",
    "            subplot.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_sample(cam1, cam2, val):\n",
    "    rindices = np.random.choice(np.array(range(cam1.shape[0])), 10, replace=False)\n",
    "    show_side_by_side(cam1[rindices], titles = [('DIF' if n == 0 else 'IGUAL') for n in val[rindices]])\n",
    "    show_side_by_side(cam2[rindices])\n",
    "    plot_sample(X_a_val/255, X_b_val/255, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CUuvQ_zDGCxT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0KWHWRVCGCxW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ec7JVXihGCxZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t83rwHU-GCxd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "AMMD2 - Siamesas 01.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
